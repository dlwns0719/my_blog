---
title: "LLM 에이전트로 코드 메타데이터 추출하기: 시행착오와 설계 원칙"
subtitle: "152개 Python 파일에서 2,499개 메타데이터를 추출하기까지"
description: |
  Claude Code의 분산 에이전트로 대규모 코드베이스(AutoMSA, 152 Python 파일)의 메타데이터를 전수 추출한 실전 경험입니다.
  단일 에이전트 실패, 형식 불일치, 원자적 디테일 소실까지 -- 4번의 시행착오에서 도출한 설계 원칙을 정리합니다.
categories:
  - Agent
  - Code_Analysis
  - Prompt_Engineering
author: Junhyun Lee
date: 02/13/2026
format:
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: False
---

# LLM 에이전트로 코드 메타데이터 추출하기

## 왜 코드베이스 메타데이터가 필요한가

인실리코(in-silico) 알고리즘 코드를 분석하는 **코드 설명 Agent**를 구축하려면, Agent가 코드를 이해하기 위한 구조화된 메타데이터가 필요합니다.

여기서 말하는 메타데이터란:

- 모든 클래스/함수/변수의 **물리명, 논리명, 데이터 타입, 기본값, 의미**
- 모듈 간 **입출력 연결 관계**
- 파이프라인 **단계 간 의존성**
- 중간 산출물의 **파일 스키마** (구분자, 인코딩, 컬럼 정의)
- 알고리즘 **파라미터, 임계값, 허용 범위**
- **암묵적 규칙** (코드에 명시되지 않은 관계, 상태 전이 조건)

이 메타데이터를 14개 카테고리로 분류하여 `METADATA_INVESTIGATION.md`라는 단일 문서로 생성하는 것이 목표입니다.

---

## 대상: AutoMSA 파이프라인

| 항목 | 값 |
|------|-----|
| 레포지토리 | `insilico-core-automsa` |
| Python 파일 수 | 152개 |
| 총 코드 줄 수 | ~29,178줄 |
| 파이프라인 단계 | 9개 서비스 (5 Step) |
| 역할 | 유전자/단백질 키워드 기반 서열 수집, BLAST 확장, 대표 서열 선정, 다중 서열 정렬(MSA) 자동화 |

파이프라인 구조:

```
AutoMSA -> DRS -> monoom -> multiom -> multiom-output -> multitom -> multiplex-excel
```

이 규모의 코드베이스에서 원자적 수준의 메타데이터를 추출하면 **2,500개 이상의 항목**이 나옵니다.

---

## 1차 시도: 단일 에이전트 (실패)

### 접근

하나의 Claude Code 에이전트에게 전체 152개 파일을 분석하라고 요청했습니다.

### 결과

**Context window 한계에 도달.** 약 50개 파일을 읽은 시점에서 컨텍스트가 부족해져, 나머지 100개 파일은 조사되지 않았습니다.

### 교훈

> **대규모 코드베이스는 단일 에이전트로 처리할 수 없다.** Context window는 유한하고, 152개 파일 x 평균 192줄 = ~29K줄의 코드를 한 번에 읽고 분석하는 것은 불가능합니다.

---

## 2차 시도: 3개 분산 에이전트

### 접근

14개 카테고리를 3개 그룹으로 나누어 병렬 실행:

- Agent A: Cat 1-3 (파이프라인 구조, 중간 산출물)
- Agent B: Cat 4-7 (입력/파라미터, DB, 품질)
- Agent C: Cat 8-14 (라이브러리, 환경, 인프라, 로깅, 기타)

### 결과

3개 에이전트 모두 완료. 그러나 **산출물의 형식이 프롬프트와 불일치**:

| 문제 | 상세 |
|------|------|
| N.1-N.4 구조 누락 | 각 카테고리에 "추출 가능 이유", "조사 대상 파일", "해석 메타데이터" 섹션이 없음 |
| 테이블 헤더 영문 | 한국어 8열 헤더 대신 영어 헤더 사용 |
| 통계표 누락 | 최종 카테고리별 항목 수 집계표 없음 |
| 품질 체크리스트 누락 | 12개 항목 체크리스트 없음 |

### 교훈

> **LLM은 추상적 규칙보다 구체적 예시를 훨씬 잘 따른다.** 프롬프트에 "N.1, N.2, N.3, N.4 구조로 작성하세요"라고 써도, 실제 완성된 예시가 없으면 에이전트가 자의적으로 해석합니다.

---

## 3차 시도: "읽기→요약→합성" 방식의 실패

2차 시도에서 형식 문제를 경험한 후, 32개 레포지토리를 효율적으로 대량 처리하기 위해 **다른 접근법**을 시도했습니다. 이 시도에서 발견한 실패 모드는 앞의 시도들과는 질적으로 다른 문제였습니다.

### 접근: 읽기 에이전트 + 합성

```
Phase 1: 5개 백그라운드 에이전트가 파일 그룹별로 전체 코드를 읽음
         (core, enum/dto, entity, common modules, pipeline steps)
         ↓
Phase 2: 각 에이전트가 읽은 내용의 "요약"을 반환
         ↓
Phase 3: 메인 에이전트가 요약을 기반으로 METADATA_INVESTIGATION.md 합성
```

이 접근법은 합리적으로 보였습니다. 152개 파일을 5개로 나눠 병렬 읽기, 요약, 합성. 그러나 **결과는 참담했습니다.**

### 결과: Cat 3이 16개 항목으로 축소

| 지표 | 4차 시도 (12개 추출 에이전트) | 3차: 5개 읽기 에이전트 + 합성 |
|------|-------------------------------|-------------------------------|
| 총 항목 수 | **2,499+** | **436** |
| Cat 3 항목 수 | **325+** | **16** |
| Cat 3 파일 스키마 | **35개** | **0** |
| DTO 필드 추출 | **개별 행으로 전수** | **완전 누락** |

Cat 3에 들어갔어야 할 항목들이 대량 누락되었습니다:

| 누락된 항목 유형 | 예상 규모 | 실제 추출 |
|------------------|----------|----------|
| DTO 클래스 전체 필드 (SeqInfo 859줄, MatchSeqInfo 1273줄 등) | 200+ 필드 | 0 |
| Entity Enum 필드 (25개 파일) | 300+ 필드 | 0 |
| 중간 파일 스키마 (컬럼 정의) | 수십 개 | 0 |
| 단계 간 반환값 | 30+ 항목 | 0 |

### 근본 원인 분석

**원인 1: 2단계 간접 처리에서 정보 소실**

읽기 에이전트가 `MatchSeqInfo` 클래스(1,273줄)를 읽으면, 요약에는 이렇게 돌아옵니다:

```
MatchSeqInfo: 매칭 서열 정보를 나타내는 포괄적 클래스.
1273줄. 여러 헤더 형식, 정렬 상세, 어셈블리/분류 정보 포함.
다수의 getter/setter 메서드.
```

이 요약으로는 `score`, `gene`, `product`, `pct_id`, `coverage` 같은 **개별 필드**를 원자적 행으로 추출할 수 없습니다. **요약은 구조를 전달하지만, 원자적 항목을 전달하지 못합니다.**

**원인 2: 컨텍스트 압박에 의한 카테고리 범위 축소**

합성 에이전트는 14개 카테고리를 모두 작성해야 합니다. 요약 기반으로 남은 컨텍스트가 빠듯하면 **초기 카테고리를 빨리 끝내고 넘어가려는 경향**이 생깁니다. Cat 3이 첫 번째 쓰기 배치에 포함되어 있었고, 뒤에 11개 카테고리가 남아있다는 압박에 요약 모드로 전환되었습니다.

**원인 3: 카테고리 범위를 좁게 재해석**

프롬프트는 Cat 3에 "모델 클래스의 모든 필드", "메서드 반환값", "메모리 상 상태 변수"를 명시적으로 요구합니다. 그러나 합성 에이전트는 **"중간 산출물 = 디스크에 기록되는 파일"**로 좁게 해석하여, DTO 필드/Entity Enum/반환값을 전부 누락시켰습니다.

**원인 4: 카테고리 간 중복 회피 과잉 적용**

프롬프트는 "주 카테고리에 배치하고 비고에 관련 카테고리를 표기"라고 명시합니다. 그러나 합성 에이전트는 DTO 필드를 Cat 5(파라미터)나 Cat 1(I/O)에 분산 배치해야 한다고 판단하여, Cat 3에서는 파일 경로만 나열했습니다.

### 교훈: "읽기 에이전트"는 "추출 에이전트"가 아니다

```
읽기 에이전트 (Reading Agent)
+---------------------------------------------+
| 입력: "이 파일들을 읽어라"                    |
| 출력: 파일 내용의 요약 (구조적, 서술적)        |
| 한계: 원자적 항목 추출을 하지 않음             |
+---------------------------------------------+

추출 에이전트 (Extraction Agent)
+---------------------------------------------+
| 입력: "이 파일에서 Cat N의 메타데이터를 추출하라" |
| 출력: 구조화된 테이블 (행 = 원자적 항목)        |
| 강점: 목적이 명확하므로 원자적 디테일 유지      |
+---------------------------------------------+
```

| 비교 항목 | 읽기 + 합성 (3차) | 직접 추출 (4차) |
|-----------|-------------------|----------------|
| 에이전트 역할 | "파일을 읽고 요약하라" | "Cat N의 메타데이터를 추출하라" |
| 정보 흐름 | 코드 -> 요약 -> 테이블 (2단계) | 코드 -> 테이블 (1단계) |
| 원자적 디테일 | 요약에서 소실 | 직접 보존 |
| Cat 3 결과 | 16개 항목 | **325개** |
| 총 항목 수 | 436개 | **2,499개** |
| 실패 지점 | 요약 <-> 합성 사이의 간극 | 없음 (단일 변환) |

> **에이전트에게 "읽어라"와 "추출하라"는 전혀 다른 지시입니다.** 메타데이터 추출에서는 에이전트가 카테고리를 인식한 상태에서 직접 원자적 항목을 추출해야 합니다. 읽기 에이전트의 요약을 합성하는 것은 "전화 게임(Chinese whispers)"과 같아서, 단계마다 정보가 소실됩니다.

---

## 4차 시도: 12개 추출 에이전트 (성공)

1~3차의 실패에서 도출한 교훈을 모두 반영한 최종 시도입니다.

### 접근: 카테고리 기반 분산 추출

1~3차 시행착오에서 배운 핵심을 적용했습니다:

- **원칙 7 적용**: "읽기" 에이전트가 아닌 "추출" 에이전트 사용
- **원칙 8 적용**: Cat 3은 3개 서브 에이전트로 분할
- **원칙 2 적용**: 카테고리별 대상 파일을 사전 매핑

```
8+1 카테고리 에이전트 (Phase 1: 병렬 실행)
──────────────────────────────────────────
  Agent 1: Cat 1 (모듈 간 I/O)
  Agent 2: Cat 2 (파이프라인 의존성)
  Agent 3: Cat 3 (중간 산출물) -- 단독 → 토큰 초과로 실패
  Agent 4: Cat 4-5 (입력/파라미터)
  Agent 5: Cat 6-7 (DB/품질규칙)
  Agent 6: Cat 8-9 (라이브러리/환경변수)
  Agent 7: Cat 10-11 (병렬처리/실행모드)
  Agent 8: Cat 12-14 (인프라/로깅/기타)
  Agent 9: Cat 3 파일 스키마 전용

Cat 3 재시도 (Phase 2: 3개 서브 에이전트 병렬)
──────────────────────────────────────────
  Agent 3a: SeqInfo DTO 필드 (53개)
  Agent 3b: MatchSeqInfo + 기타 DTO/Enum (272개)
  Agent 3c: Entity 필드 + 상태변수 + N.1/N.2/N.4

병합 (Phase 3)
──────────────────────────────────────────
  Python 스크립트로 12개 산출물 → METADATA_INVESTIGATION.md
```

### 에이전트별 프롬프트 설계

각 에이전트에게 다음을 명시적으로 제공했습니다:

1. **담당 카테고리**: "당신은 Cat 6-7 (DB 스키마/품질 규칙)만 담당합니다"
2. **대상 파일 경로**: 읽어야 할 파일 목록을 사전 지정
3. **출력 형식**: 8열 테이블 + N.1~N.4 구조
4. **출력 위치**: `/tmp/automsa_metadata/cat_06_07.md`
5. **원자적 완전성 강조**: "모든 필드를 개별 행으로, 축약 없이"

### Cat 3 토큰 제한 사고와 해결

Cat 3 단독 에이전트가 **출력 토큰 제한(32K)을 초과**하여 실패했습니다. Cat 3은 DTO 클래스(SeqInfo 859줄, MatchSeqInfo 1,273줄)의 수백 개 필드를 개별 행으로 추출해야 하므로, 단일 에이전트로는 출력량이 부족합니다.

해결: Cat 3을 3개 서브 에이전트로 분할하여 재시도했습니다.

| 서브 에이전트 | 담당 | 추출 결과 |
|--------------|------|----------|
| Cat 3a | SeqInfo DTO 필드 | 53개 |
| Cat 3b | MatchSeqInfo + 10개 DTO + 12개 Enum | 272개 |
| Cat 3c | Entity 필드 + 상태변수 + N.1/N.2/N.4 | Entity 14개 클래스 + State 44개 |

### 결과

| 항목 | 수치 |
|------|------|
| **총 항목 수** | **2,499+** |
| 산출물 크기 | 594KB, 6,063줄 |
| 사용 에이전트 | 12개 (9 + 3 재시도) |
| Wall clock 시간 | ~36분 (병렬 실행) |
| 병목 에이전트 | Cat 6-7 (~33분, DB 스키마가 가장 복잡) |

카테고리별 집계:

| 카테고리 | 항목 수 | 비고 |
|----------|---------|------|
| 1. 모듈 간 I/O | 286 | 파일 경로, 포맷, CLI 인자 |
| 2. 파이프라인 의존성 | 247 | 실행 순서, 상태 전이 |
| 3. 중간 산출물 | 325+ | DTO/Entity/State + 35 파일 스키마 |
| 4. 입력 JSON/UI | 206 | Input 클래스 필드 |
| 5. 알고리즘 파라미터 | 138 | Constants, 임계값 |
| 6. DB 스키마/쿼리 | 297 | 13개 테이블, 175개 Entity Enum 컬럼 |
| 7. 품질 규칙 | 111 | 7단계 EX 필터, 검증 로직 |
| 8. 라이브러리/API | 205 | pyproject.toml 의존성, 외부 API |
| 9. 환경 변수 | 183 | Config, 경로 구성 |
| 10. 병렬 처리 | 49 | 외부 도구 스레딩 (VSEARCH/MAFFT) |
| 11. 실행 모드 | 113 | DesignType별 분기 |
| 12. 인프라 | 150 | CI/CD, ACR, Nexus |
| 13. 로깅 | 79 | 모듈별 로거 |
| 14. 기타 | 110 | 유틸리티, 헬퍼 |

### 4번의 시도 비교

| 시도 | 에이전트 구성 | 항목 수 | 시간 | 실패 원인 |
|------|-------------|---------|------|----------|
| 1차 | 단일 1개 | 259 | ~50분 | Context window 한계 |
| 2차 | 3개 분산 | (형식 불일치) | ~30분 | 형식 불일치, 예시 부재 |
| 3차 | 5 읽기 + 합성 | 436 | ~40분 | 요약에서 원자적 디테일 소실 |
| **4차** | **12개 추출** | **2,499+** | **~36분** | - |

3차 대비 **5.7배**, 1차 대비 **9.6배** 증가. 시간은 병렬 실행 덕분에 오히려 단축되었습니다.

### 교훈

> **에이전트 역할 설계가 결과 품질의 핵심이다.** 같은 코드를 같은 LLM이 보더라도, "읽기 에이전트"에게 시키면 436개, "추출 에이전트"에게 시키면 2,499개가 나옵니다. 프롬프트보다 에이전트 역할 설계가 더 큰 영향을 미칩니다.

> **대용량 카테고리는 출력 토큰 제한을 고려해 분할해야 한다.** Cat 3처럼 200개 이상의 행을 개별 추출해야 하는 경우, 단일 에이전트의 출력 토큰 한계(32K)를 초과할 수 있습니다. 클래스 단위로 서브 에이전트를 분할하면 해결됩니다.

---

## 설계 원칙 정리

4번의 시행착오에서 도출한 원칙들을 종합합니다.

### 프롬프트 설계 원칙 (6가지)

#### 원칙 1: 분산 실행 프로토콜을 프롬프트에 명시하라

단일 에이전트 전제의 프롬프트를 여러 에이전트에게 나눠주면 실패합니다. **어떻게 나누고, 어떻게 합칠 것인지**를 프롬프트 자체에 포함해야 합니다.

```markdown
## 분산 실행 프로토콜

### 분할 단위
- Agent A: Cat 1-2 (파이프라인 구조)
- Agent B: Cat 3 (중간 산출물) -- 단독
- Agent C: Cat 4-5 (입력/파라미터)
...

### 에이전트별 산출물 규칙
- 파일명: `/tmp/{repo}_metadata/cat_{NN}.md`
- 자기 완결적 (헤더 불필요, 카테고리 내용만)
- 마지막에 `<!-- ROW_COUNT: {숫자} -->` 주석 추가
```

#### 원칙 2: 카테고리별 대상 파일을 사전 매핑하라

모든 에이전트가 152개 파일을 각자 탐색하면 토큰 낭비입니다. 파일을 미리 분류해서 에이전트 범위를 좁혀야 합니다.

#### 원칙 3: 추상적 규칙 대신 완성된 예시를 제공하라

"N.1-N.4 구조로 작성하세요"보다 **실제 완성된 카테고리 1개를 통째로** 예시로 보여주는 것이 효과적입니다.

#### 원칙 4: 중요 요구사항은 독립 섹션 + CRITICAL 표시로 분리하라

카테고리 설명 안에 묻어 놓으면 에이전트가 놓칩니다.

#### 원칙 5: 레포 규모별 자동 분할 기준을 포함하라

| Python 파일 수 | 권장 에이전트 수 |
|---------------|-----------------|
| ~30개 | 1 (단일) |
| 30~80개 | 3 |
| 80~150개 | 5~7 |
| 150개+ | 7~10 |

#### 원칙 6: 오케스트레이터용 병합 체크리스트를 명시하라

병합 단계에서 통계표 누락, 행 수 불일치가 발생합니다. 오케스트레이터가 따를 체크리스트가 필요합니다.

### 에이전트 역할 설계 원칙 (3가지)

#### 원칙 7: 에이전트에게는 "추출"을 시켜라, "읽기"를 시키지 마라

"이 파일들을 읽어라"가 아니라 "이 파일에서 Cat N의 메타데이터를 추출하라"로 지시해야 원자적 디테일이 보존됩니다.

#### 원칙 8: Cat 3은 항상 단독 에이전트에 할당하라

Cat 3 (중간 산출물)은 DTO 필드 추출 + 파일 스키마 분석이 합쳐져 **가장 분량이 큽니다** (200개 이상의 항목 + 파일 스키마). 다른 카테고리와 묶으면 context window를 초과합니다.

#### 원칙 9: 대량 처리 시 레포 크기에 따라 전략을 나눠라

```
for repo in repos:
    if repo.file_count < 30:
        single_extraction_agent(repo)
    else:
        parallel_extraction_agents(repo, categories)
```

### LLM 추출의 근본적 한계

프롬프트를 아무리 정밀하게 만들어도 해결할 수 없는 문제가 있습니다.

#### 비결정성(Non-determinism) 문제

같은 프롬프트 + 같은 코드로 두 번 실행하면:

| 문제 | 예시 |
|------|------|
| 행 수 불일치 | 이번 1,400개, 다음번 1,380개 |
| 행 순서 변동 | `uclust_pct_id`가 3번이었다가 7번 |
| 논리명 흔들림 | "UCLUST Percent Identity" vs "UCLUST Identity Threshold" |
| 누락/추가 | private 메서드 포함 여부가 달라짐 |
| 카테고리 분류 흔들림 | 같은 항목이 Cat 5에 갔다가 Cat 7에 감 |

#### 왜 이것이 문제인가

코드 설명 Agent가 메타데이터를 참조할 때, **실행마다 메타데이터가 달라지면 Agent의 응답도 불안정**해집니다. 주기적으로 메타데이터를 갱신해야 하는 운영 환경에서는 치명적입니다.

#### 재현성 한계

| 접근법 | 재현성 |
|--------|--------|
| 정밀 프롬프트만 | ~70% |
| 프롬프트 + 참조 예시 | ~80% |
| **프롬프트로는 한계** | **100%는 불가능** |

---

## 실전에서 배운 세부 교훈들

### 파일 스키마 추출은 특별 취급이 필요하다

TSV/FASTA 파일의 스키마(구분자, 컬럼 순서, 생산/소비 함수)는 코드의 **실제 write 로직** (f-string 안의 컬럼 순서, 조건부 컬럼 등)을 분석해야 합니다. 단순 추출로는 불가능하며, 전용 에이전트가 코드 흐름을 따라가야 합니다.

### 병합 단계에서 빠지기 쉬운 항목들

- 통계표의 행 수 (에이전트가 `*`로 남겨두는 경우)
- 파이프라인 구조 다이어그램
- 전체 파일 목록 (상단)
- 품질 검증 체크리스트 (하단)

이들은 **오케스트레이터(리더 에이전트 또는 스크립트)**가 자동 생성해야 합니다.

### Permission 모드 주의

`bypassPermissions` 모드로 에이전트를 실행해도 `/tmp` 디렉토리 생성에 실패하는 경우가 있었습니다. 산출물 디렉토리는 **에이전트 실행 전에 미리 생성**해 두어야 합니다.

---

## 결론

4번의 시행착오에서 배운 핵심:

1. **대규모 코드베이스는 단일 에이전트로 처리할 수 없다** -- Context window의 물리적 한계
2. **LLM은 추상적 규칙보다 구체적 예시를 따른다** -- 완성된 예시 문서가 필수
3. **"읽어라"와 "추출하라"는 근본적으로 다른 지시다** -- 요약 기반 합성은 원자적 디테일을 체계적으로 소실시킨다 (436 vs 2,499)
4. **에이전트 역할 설계가 결과 품질의 핵심이다** -- 같은 코드를 같은 LLM이 보더라도, 역할에 따라 9.6배 차이가 발생한다
5. **대용량 카테고리는 출력 토큰 한계를 고려해 분할해야 한다** -- Cat 3은 3개 서브 에이전트로 분할하여 해결
6. **순수 LLM 접근은 비결정적이다** -- 2,499개를 성공적으로 추출했지만, 동일 코드로 재실행하면 항목 수와 내용이 달라진다

한마디로: **"무엇을 추출할 것인가"는 프롬프트의 영역이지만, "에이전트에게 무엇을 시킬 것인가"는 역할 설계의 영역이다.**

4차 시도에서 순수 LLM 접근으로도 2,499+개의 고품질 메타데이터를 추출할 수 있음을 증명했습니다. 그러나 **재현성 문제**(같은 코드로 재실행해도 결과가 달라짐)는 프롬프트나 에이전트 설계만으로는 해결할 수 없는 근본적 한계입니다.

이 한계를 구조적으로 해결하기 위한 접근 -- AST 코드 파서와 LLM을 결합한 하이브리드 파이프라인 -- 은 [다음 글](./02-하이브리드_파이프라인_설계.qmd)에서 다룹니다.
