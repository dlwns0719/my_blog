---
title: "LLM 에이전트로 코드 메타데이터 추출하기: 시행착오와 설계 원칙"
subtitle: "152개 Python 파일에서 1,411개 항목을 추출하며 배운 것들"
description: |
  Claude Code의 분산 에이전트로 대규모 코드베이스(AutoMSA, 152 Python 파일)의 메타데이터를 전수 추출한 실전 경험입니다.
  단일 에이전트 실패, 형식 불일치, 원자적 디테일 소실까지 -- 각 시행착오에서 도출한 설계 원칙을 정리합니다.
categories:
  - Agent
  - Code_Analysis
  - Prompt_Engineering
author: Junhyun Lee
date: 02/13/2026
format:
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: False
---

# LLM 에이전트로 코드 메타데이터 추출하기

## 왜 코드베이스 메타데이터가 필요한가

인실리코(in-silico) 알고리즘 코드를 분석하는 **코드 설명 Agent**를 구축하려면, Agent가 코드를 이해하기 위한 구조화된 메타데이터가 필요합니다.

여기서 말하는 메타데이터란:

- 모든 클래스/함수/변수의 **물리명, 논리명, 데이터 타입, 기본값, 의미**
- 모듈 간 **입출력 연결 관계**
- 파이프라인 **단계 간 의존성**
- 중간 산출물의 **파일 스키마** (구분자, 인코딩, 컬럼 정의)
- 알고리즘 **파라미터, 임계값, 허용 범위**
- **암묵적 규칙** (코드에 명시되지 않은 관계, 상태 전이 조건)

이 메타데이터를 14개 카테고리로 분류하여 `METADATA_INVESTIGATION.md`라는 단일 문서로 생성하는 것이 목표입니다.

---

## 대상: AutoMSA 파이프라인

| 항목 | 값 |
|------|-----|
| 레포지토리 | `insilico-core-automsa` |
| Python 파일 수 | 152개 |
| 총 코드 줄 수 | ~29,178줄 |
| 파이프라인 단계 | 9개 서비스 (5 Step) |
| 역할 | 유전자/단백질 키워드 기반 서열 수집, BLAST 확장, 대표 서열 선정, 다중 서열 정렬(MSA) 자동화 |

파이프라인 구조:

```
AutoMSA -> DRS -> monoom -> multiom -> multiom-output -> multitom -> multiplex-excel
```

이 규모의 코드베이스에서 원자적 수준의 메타데이터를 추출하면 **1,400개 이상의 항목**이 나옵니다.

---

## 1차 시도: 단일 에이전트 (실패)

### 접근

하나의 Claude Code 에이전트에게 전체 152개 파일을 분석하라고 요청했습니다.

### 결과

**Context window 한계에 도달.** 약 50개 파일을 읽은 시점에서 컨텍스트가 부족해져, 나머지 100개 파일은 조사되지 않았습니다.

### 교훈

> **대규모 코드베이스는 단일 에이전트로 처리할 수 없다.** Context window는 유한하고, 152개 파일 x 평균 192줄 = ~29K줄의 코드를 한 번에 읽고 분석하는 것은 불가능합니다.

---

## 2차 시도: 3개 분산 에이전트

### 접근

14개 카테고리를 3개 그룹으로 나누어 병렬 실행:

- Agent A: Cat 1-3 (파이프라인 구조, 중간 산출물)
- Agent B: Cat 4-7 (입력/파라미터, DB, 품질)
- Agent C: Cat 8-14 (라이브러리, 환경, 인프라, 로깅, 기타)

### 결과

3개 에이전트 모두 완료. 그러나 **산출물의 형식이 프롬프트와 불일치**:

| 문제 | 상세 |
|------|------|
| N.1-N.4 구조 누락 | 각 카테고리에 "추출 가능 이유", "조사 대상 파일", "해석 메타데이터" 섹션이 없음 |
| 테이블 헤더 영문 | 한국어 8열 헤더 대신 영어 헤더 사용 |
| 통계표 누락 | 최종 카테고리별 항목 수 집계표 없음 |
| 품질 체크리스트 누락 | 12개 항목 체크리스트 없음 |

### 교훈

> **LLM은 추상적 규칙보다 구체적 예시를 훨씬 잘 따른다.** 프롬프트에 "N.1, N.2, N.3, N.4 구조로 작성하세요"라고 써도, 실제 완성된 예시가 없으면 에이전트가 자의적으로 해석합니다.

---

## 3차 시도: 7개 분산 에이전트 + 형식 교정

### 접근

- 참조 문서(multiom 레포의 METADATA_INVESTIGATION.md)를 Gold Standard로 제공
- 7개 에이전트로 더 세밀하게 분할:
  - Cat 1 / Cat 2-3 / Cat 4 / Cat 5-6 / Cat 7-8 / Cat 9-11 / Cat 12-14
- 각 에이전트에게 **구체적 형식 예시**와 **참조 문서**를 함께 전달

### 결과

| 카테고리 | 항목 수 |
|----------|---------|
| 1. 모듈 간 I/O | 213 |
| 2. 파이프라인 의존성 | 62 |
| 3. 중간 산출물 | 218 |
| 4. 입력 JSON/UI | 128 |
| 5. 알고리즘 파라미터 | 129 |
| 6. DB 스키마/쿼리 | 110 |
| 7. 품질 규칙 | 99 |
| 8. 라이브러리/API | 53 |
| 9. 환경 변수 | 35 |
| 10. 병렬 처리 | 18 |
| 11. 실행 모드 | 45 |
| 12. 인프라 | 44 |
| 13. 로깅 | 81 |
| 14. 기타 | 176 |
| **합계** | **1,411** |

형식은 올바르게 나왔으나, **Cat 3의 파일 스키마가 누락**되었습니다.

### 교훈

> **중요한 요구사항은 독립 섹션으로 분리해야 한다.** Cat 3 설명 안에 "파일 스키마를 반드시 기술하세요"라고 묻어 놓으면 에이전트가 놓칩니다. **CRITICAL** 표시와 함께 별도 섹션으로 올려야 합니다.

---

## Cat 3 파일 스키마 보강: 전용 에이전트

Cat 3의 36개 중간 산출물 파일에 대해 전용 에이전트를 추가 투입했습니다.

### 추출한 파일 스키마 속성 (9가지)

각 파일에 대해:

| 속성 | 예시 (InExCrossInfo.txt) |
|------|--------------------------|
| 구분자 | `\t` (탭) |
| 인코딩 | UTF-8 |
| 헤더 행 | 없음 |
| 행 의미 | 1행 = 1개 키-값 쌍 |
| 정렬 순서 | dict 순회 순서 |
| 생성 함수 | `get_in_ex_cross_info.py::output_default_in_ex_cross_file()` |
| 소비 함수 | `in_ex_param_info.py::InExParamInfo.__init__()` |
| 좌표 체계 | N/A |
| 컬럼 정의 | key(str) + value(str) |

### 부록으로 추가된 내용

- FASTA 헤더 타입 종합 정리 (SeqInfo 11가지 + MatchSeqInfo 4가지 헤더 형식)
- TSV 엔티티 컬럼 비교표 (IN/EX/CROSS 37개 컬럼 대조)

### 최종 산출물

- **3,782줄**의 METADATA_INVESTIGATION.md
- **1,411개** 원자적 메타데이터 항목
- **36개** 파일 스키마 상세
- 총 **8개 에이전트** 사용 (7개 카테고리 + 1개 파일 스키마)

---

## 4차 시도: "읽기→요약→합성" 방식의 실패

7개 에이전트 방식(3차 시도)이 성공한 후, 32개 레포지토리를 대량 처리하기 위해 **다른 접근법**을 시도했습니다. 이 시도에서 발견한 실패 모드는 앞의 3가지 시도와는 질적으로 다른 문제였습니다.

### 접근: 읽기 에이전트 + 합성

```
Phase 1: 5개 백그라운드 에이전트가 파일 그룹별로 전체 코드를 읽음
         (core, enum/dto, entity, common modules, pipeline steps)
         ↓
Phase 2: 각 에이전트가 읽은 내용의 "요약"을 반환
         ↓
Phase 3: 메인 에이전트가 요약을 기반으로 METADATA_INVESTIGATION.md 합성
```

이 접근법은 합리적으로 보였습니다. 152개 파일을 5개로 나눠 병렬 읽기, 요약, 합성. 그러나 **결과는 참담했습니다.**

### 결과: Cat 3이 16개 항목으로 축소

| 지표 | 7개 추출 에이전트 (3차) | 5개 읽기 에이전트 + 합성 |
|------|------------------------|------------------------|
| 총 항목 수 | 1,411 | **436** (69% 감소) |
| Cat 3 항목 수 | 218 | **16** (93% 감소) |
| Cat 3 파일 스키마 | 36개 상세 기술 | **0** |
| DTO 필드 추출 | 개별 행으로 전수 | **완전 누락** |

Cat 3에 들어갔어야 할 항목들이 대량 누락되었습니다:

| 누락된 항목 유형 | 예상 규모 | 실제 추출 |
|------------------|----------|----------|
| DTO 클래스 전체 필드 (SeqInfo 859줄, MatchSeqInfo 1273줄 등) | 200+ 필드 | 0 |
| Entity Enum 필드 (25개 파일) | 300+ 필드 | 0 |
| 중간 파일 스키마 (컬럼 정의) | 수십 개 | 0 |
| 단계 간 반환값 | 30+ 항목 | 0 |

### 근본 원인 분석

**원인 1: 2단계 간접 처리에서 정보 소실**

읽기 에이전트가 `MatchSeqInfo` 클래스(1,273줄)를 읽으면, 요약에는 이렇게 돌아옵니다:

```
MatchSeqInfo: 매칭 서열 정보를 나타내는 포괄적 클래스.
1273줄. 여러 헤더 형식, 정렬 상세, 어셈블리/분류 정보 포함.
다수의 getter/setter 메서드.
```

이 요약으로는 `score`, `gene`, `product`, `pct_id`, `coverage` 같은 **개별 필드**를 원자적 행으로 추출할 수 없습니다. **요약은 구조를 전달하지만, 원자적 항목을 전달하지 못합니다.**

**원인 2: 컨텍스트 압박에 의한 카테고리 범위 축소**

합성 에이전트는 14개 카테고리를 모두 작성해야 합니다. 요약 기반으로 남은 컨텍스트가 빠듯하면 **초기 카테고리를 빨리 끝내고 넘어가려는 경향**이 생깁니다. Cat 3이 첫 번째 쓰기 배치에 포함되어 있었고, 뒤에 11개 카테고리가 남아있다는 압박에 요약 모드로 전환되었습니다.

**원인 3: 카테고리 범위를 좁게 재해석**

프롬프트는 Cat 3에 "모델 클래스의 모든 필드", "메서드 반환값", "메모리 상 상태 변수"를 명시적으로 요구합니다. 그러나 합성 에이전트는 **"중간 산출물 = 디스크에 기록되는 파일"**로 좁게 해석하여, DTO 필드/Entity Enum/반환값을 전부 누락시켰습니다.

**원인 4: 카테고리 간 중복 회피 과잉 적용**

프롬프트는 "주 카테고리에 배치하고 비고에 관련 카테고리를 표기"라고 명시합니다. 그러나 합성 에이전트는 DTO 필드를 Cat 5(파라미터)나 Cat 1(I/O)에 분산 배치해야 한다고 판단하여, Cat 3에서는 파일 경로만 나열했습니다.

### 교훈: "읽기 에이전트"는 "추출 에이전트"가 아니다

```
읽기 에이전트 (Reading Agent)
+---------------------------------------------+
| 입력: "이 파일들을 읽어라"                    |
| 출력: 파일 내용의 요약 (구조적, 서술적)        |
| 한계: 원자적 항목 추출을 하지 않음             |
+---------------------------------------------+

추출 에이전트 (Extraction Agent)
+---------------------------------------------+
| 입력: "이 파일에서 Cat N의 메타데이터를 추출하라" |
| 출력: 구조화된 테이블 (행 = 원자적 항목)        |
| 강점: 목적이 명확하므로 원자적 디테일 유지      |
+---------------------------------------------+
```

| 비교 항목 | 읽기 + 합성 | 직접 추출 |
|-----------|------------|----------|
| 에이전트 역할 | "파일을 읽고 요약하라" | "Cat N의 메타데이터를 추출하라" |
| 정보 흐름 | 코드 -> 요약 -> 테이블 (2단계) | 코드 -> 테이블 (1단계) |
| 원자적 디테일 | 요약에서 소실 | 직접 보존 |
| Cat 3 결과 | 16개 항목 | 218개 항목 |
| 실패 지점 | 요약 <-> 합성 사이의 간극 | 없음 (단일 변환) |

> **에이전트에게 "읽어라"와 "추출하라"는 전혀 다른 지시입니다.** 메타데이터 추출에서는 에이전트가 카테고리를 인식한 상태에서 직접 원자적 항목을 추출해야 합니다. 읽기 에이전트의 요약을 합성하는 것은 "전화 게임(Chinese whispers)"과 같아서, 단계마다 정보가 소실됩니다.

---

## 설계 원칙 정리

4번의 시행착오에서 도출한 원칙들을 종합합니다.

### 프롬프트 설계 원칙 (6가지)

#### 원칙 1: 분산 실행 프로토콜을 프롬프트에 명시하라

단일 에이전트 전제의 프롬프트를 여러 에이전트에게 나눠주면 실패합니다. **어떻게 나누고, 어떻게 합칠 것인지**를 프롬프트 자체에 포함해야 합니다.

```markdown
## 분산 실행 프로토콜

### 분할 단위
- Agent A: Cat 1-2 (파이프라인 구조)
- Agent B: Cat 3 (중간 산출물) -- 단독
- Agent C: Cat 4-5 (입력/파라미터)
...

### 에이전트별 산출물 규칙
- 파일명: `/tmp/{repo}_metadata/cat_{NN}.md`
- 자기 완결적 (헤더 불필요, 카테고리 내용만)
- 마지막에 `<!-- ROW_COUNT: {숫자} -->` 주석 추가
```

#### 원칙 2: 카테고리별 대상 파일을 사전 매핑하라

모든 에이전트가 152개 파일을 각자 탐색하면 토큰 낭비입니다. 파일을 미리 분류해서 에이전트 범위를 좁혀야 합니다.

#### 원칙 3: 추상적 규칙 대신 완성된 예시를 제공하라

"N.1-N.4 구조로 작성하세요"보다 **실제 완성된 카테고리 1개를 통째로** 예시로 보여주는 것이 효과적입니다.

#### 원칙 4: 중요 요구사항은 독립 섹션 + CRITICAL 표시로 분리하라

카테고리 설명 안에 묻어 놓으면 에이전트가 놓칩니다.

#### 원칙 5: 레포 규모별 자동 분할 기준을 포함하라

| Python 파일 수 | 권장 에이전트 수 |
|---------------|-----------------|
| ~30개 | 1 (단일) |
| 30~80개 | 3 |
| 80~150개 | 5~7 |
| 150개+ | 7~10 |

#### 원칙 6: 오케스트레이터용 병합 체크리스트를 명시하라

병합 단계에서 통계표 누락, 행 수 불일치가 발생합니다. 오케스트레이터가 따를 체크리스트가 필요합니다.

### 에이전트 역할 설계 원칙 (3가지)

#### 원칙 7: 에이전트에게는 "추출"을 시켜라, "읽기"를 시키지 마라

"이 파일들을 읽어라"가 아니라 "이 파일에서 Cat N의 메타데이터를 추출하라"로 지시해야 원자적 디테일이 보존됩니다.

#### 원칙 8: Cat 3은 항상 단독 에이전트에 할당하라

Cat 3 (중간 산출물)은 DTO 필드 추출 + 파일 스키마 분석이 합쳐져 **가장 분량이 큽니다** (218개 항목 + 637줄 파일 스키마). 다른 카테고리와 묶으면 context window를 초과합니다.

#### 원칙 9: 대량 처리 시 레포 크기에 따라 전략을 나눠라

```
for repo in repos:
    if repo.file_count < 30:
        single_extraction_agent(repo)
    else:
        parallel_extraction_agents(repo, categories)
```

### LLM 추출의 근본적 한계

프롬프트를 아무리 정밀하게 만들어도 해결할 수 없는 문제가 있습니다.

#### 비결정성(Non-determinism) 문제

같은 프롬프트 + 같은 코드로 두 번 실행하면:

| 문제 | 예시 |
|------|------|
| 행 수 불일치 | 이번 1,411개, 다음번 1,380개 |
| 행 순서 변동 | `uclust_pct_id`가 3번이었다가 7번 |
| 논리명 흔들림 | "UCLUST Percent Identity" vs "UCLUST Identity Threshold" |
| 누락/추가 | private 메서드 포함 여부가 달라짐 |
| 카테고리 분류 흔들림 | 같은 항목이 Cat 5에 갔다가 Cat 7에 감 |

#### 왜 이것이 문제인가

코드 설명 Agent가 메타데이터를 참조할 때, **실행마다 메타데이터가 달라지면 Agent의 응답도 불안정**해집니다. 주기적으로 메타데이터를 갱신해야 하는 운영 환경에서는 치명적입니다.

#### 재현성 한계

| 접근법 | 재현성 |
|--------|--------|
| 정밀 프롬프트만 | ~70% |
| 프롬프트 + 참조 예시 | ~80% |
| **프롬프트로는 한계** | **100%는 불가능** |

---

## 실전에서 배운 세부 교훈들

### 파일 스키마 추출은 특별 취급이 필요하다

TSV/FASTA 파일의 스키마(구분자, 컬럼 순서, 생산/소비 함수)는 코드의 **실제 write 로직** (f-string 안의 컬럼 순서, 조건부 컬럼 등)을 분석해야 합니다. 단순 추출로는 불가능하며, 전용 에이전트가 코드 흐름을 따라가야 합니다.

### 병합 단계에서 빠지기 쉬운 항목들

- 통계표의 행 수 (에이전트가 `*`로 남겨두는 경우)
- 파이프라인 구조 다이어그램
- 전체 파일 목록 (상단)
- 품질 검증 체크리스트 (하단)

이들은 **오케스트레이터(리더 에이전트 또는 스크립트)**가 자동 생성해야 합니다.

### Permission 모드 주의

`bypassPermissions` 모드로 에이전트를 실행해도 `/tmp` 디렉토리 생성에 실패하는 경우가 있었습니다. 산출물 디렉토리는 **에이전트 실행 전에 미리 생성**해 두어야 합니다.

---

## 결론

4번의 시행착오에서 배운 핵심:

1. **대규모 코드베이스는 단일 에이전트로 처리할 수 없다** -- Context window의 물리적 한계
2. **LLM은 추상적 규칙보다 구체적 예시를 따른다** -- Gold Standard 참조 문서가 필수
3. **중요 요구사항은 독립 섹션으로 분리해야 한다** -- 프롬프트 안에 묻히면 누락됨
4. **"읽어라"와 "추출하라"는 근본적으로 다른 지시다** -- 요약 기반 합성은 원자적 디테일을 체계적으로 소실시킨다
5. **순수 LLM 접근은 비결정적이다** -- 프롬프트 개선만으로는 100% 재현성을 달성할 수 없다
6. **에이전트의 역할 설계가 결과 품질을 결정한다** -- 같은 코드를 봐도 역할에 따라 전혀 다른 출력이 나온다

한마디로: **"무엇을 추출할 것인가"는 프롬프트의 영역이지만, "에이전트에게 무엇을 시킬 것인가"는 역할 설계의 영역이다.**

이 한계를 인식한 후 설계한 해결책 -- AST 코드 파서와 LLM을 결합한 하이브리드 파이프라인 -- 은 [다음 글](./02-하이브리드_파이프라인_설계.qmd)에서 다룹니다.
