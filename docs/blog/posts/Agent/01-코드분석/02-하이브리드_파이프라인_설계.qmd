---
title: "하이브리드 메타데이터 추출 파이프라인: AST + LLM 자동화 설계"
subtitle: "코드 파서가 사실을 고정하고, LLM은 해석만 담당한다"
description: |
  순수 LLM 접근의 한계(비결정성, 높은 비용, 낮은 재현성)를 극복하기 위한
  하이브리드 파이프라인 설계입니다. Python AST로 75%를 결정적으로 추출하고,
  LLM은 논리명과 의미 해석만 담당하여 99% 재현성을 달성합니다.
categories:
  - Agent
  - Code_Analysis
  - Architecture
author: Junhyun Lee
date: 02/13/2026
format:
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: False
---

# 하이브리드 메타데이터 추출 파이프라인

## 문제 정의: 왜 순수 LLM이 안 되는가

[이전 글](./01-메타데이터_시행착오와_설계_원칙.qmd)에서 시행착오를 통해 발견한 순수 LLM 접근의 한계:

| 문제 | 영향 |
|------|------|
| **비결정성** | 같은 코드로 실행해도 항목 수, 순서, 논리명이 매번 달라짐 (재현성 ~70%) |
| **높은 비용** | 12 에이전트 x ~100K tokens, 매 실행마다 전체 재처리 |
| **느린 속도** | ~36분/레포 (32개 레포 = ~19시간) |
| **디테일 소실** | 읽기-합성 방식에서 원자적 항목의 93%가 누락될 수 있음 (추출 방식으로 해결 가능하나 비결정성 잔존) |

이 문제들은 프롬프트 개선만으로는 해결할 수 없습니다. **아키텍처 변경**이 필요합니다.

---

## 핵심 발견: 8열 테이블의 75%는 결정적으로 추출 가능하다

메타데이터 테이블의 8열을 분석하면:

```
| # | 파일 | 클래스/함수/변수 | 물리명 | 논리명 | 데이터 타입 | 값/기본값 | 의미 |
     +-------------------------------------+  +------------------+
           코드 파서로 100% 결정적 추출             LLM 해석 필요
```

| 컬럼 | 추출 방법 | 결정적? |
|------|-----------|---------|
| `#` | 자동 번호 | 100% |
| `파일` | `glob("**/*.py")` | 100% |
| `클래스/함수/변수` | Python AST | 100% |
| `물리명` | Python AST | 100% |
| **`논리명`** | **LLM** | **비결정적** |
| `데이터 타입` | AST + type hints | 95% |
| `값/기본값` | AST | 100% |
| **`의미`** | **LLM** | **비결정적** |

**8열 중 6열은 코드 파서, 2열만 LLM으로 채우면 됩니다.**

---

## 하이브리드 아키텍처

```
Phase 1: 결정적 추출 (Python AST 파서)
--------------------------------------------
  glob + ast.parse -> 모든 클래스/함수/변수/상수 추출
  |
  규칙 기반 카테고리 분류 (rules.yaml)
  |
  skeleton.json (8열 중 6열 완성, 논리명/의미는 빈 칸)

Phase 2: LLM 해석
--------------------------------------------
  skeleton.json + 소스코드 컨텍스트 -> Claude API
  |
  논리명 + 의미 + N.1/N.4 해석 메타데이터 생성
  |
  enriched.json (이전 실행 결과 참조하여 안정성 확보)

Phase 3: 렌더링
--------------------------------------------
  enriched.json + Jinja2 템플릿
  |
  METADATA_INVESTIGATION.md (항상 동일 구조)

Phase 4: Diff 검증
--------------------------------------------
  이전 버전과 비교 -> 변경 리포트
  |
  안정성 점수, 신규/삭제/변경 항목 식별
```

---

## Phase 1: AST 추출기

### 핵심 코드

Python `ast` 모듈로 코드의 **사실(fact)**을 결정적으로 추출합니다:

```python
import ast, glob, os

class PythonASTExtractor:
    def extract_all(self, repo_path: str) -> list[dict]:
        items = []
        # sorted()로 파일 순서 고정
        for py_file in sorted(glob.glob(f"{repo_path}/**/*.py", recursive=True)):
            tree = ast.parse(open(py_file).read())
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    for item in node.body:
                        if isinstance(item, ast.AnnAssign):
                            items.append({
                                # id = 파일:줄번호:물리명 (실행 간 앵커)
                                "id": f"{rel_path}:{item.lineno}:{item.target.id}",
                                "file": rel_path,
                                "line_number": item.lineno,
                                "structure": f"{node.name} field",
                                "physical_name": item.target.id,
                                "data_type": ast.unparse(item.annotation),
                                "default_value": ast.unparse(item.value) if item.value else "-",
                                "logical_name": "",   # LLM이 채움
                                "meaning": "",        # LLM이 채움
                            })
        return sorted(items, key=lambda x: (x["file"], x["line_number"]))
```

**핵심:** `id`가 `파일:줄번호:물리명`으로 구성되어, 코드가 동일하면 **항상 동일한 ID**가 생성됩니다. 이 ID가 실행 간 일관성의 앵커 역할을 합니다.

### 규칙 기반 카테고리 분류

```yaml
# rules.yaml
categories:
  - id: 3
    name: "중간 산출물"
    rules:
      - type: "file_path_match"
        file_patterns: ["*/dto/*.py"]
        structure_types: ["class_field"]
        priority: 20  # DTO 필드는 무조건 Cat 3

  - id: 6
    name: "DB 스키마 및 쿼리"
    rules:
      - type: "file_path_match"
        file_patterns: ["*/repository/*.py", "*/entity/**/*.py"]
        priority: 18

# 매칭되지 않은 항목은 Cat 14 (기타)
fallback_category: 14
```

파일 경로, 구조 유형, 물리명 패턴으로 카테고리를 **규칙 기반**으로 분류합니다. LLM이 개입하지 않으므로 **항상 동일한 분류 결과**가 나옵니다.

---

## Phase 2: LLM 해석 + 이전 결과 참조

LLM이 담당하는 `논리명`과 `의미`의 안정성을 확보하는 핵심 메커니즘:

```python
def build_prompt(self, skeleton_items, previous_items):
    prompt = """
    ## 기존 항목 검증 (변경 불필요 시 그대로 유지)

    아래 항목들은 이전 실행에서 이미 해석되었습니다.
    코드 변경으로 인해 의미가 달라진 항목만 수정하세요.
    **변경이 없으면 반드시 그대로 유지하세요.**

    ## 신규 항목 해석 (새로 작성)

    아래 항목들은 이전 실행에 없던 신규 항목입니다.
    logical_name(영문 Title Case)과 meaning(한글 1~2문장)을 작성하세요.
    """
```

이전 실행 결과를 **명시적으로 제공**하고 "변경 없으면 유지"를 지시하면, LLM이 담당하는 2열도 **95%+ 안정성**을 확보합니다.

---

## Phase 3: Jinja2 렌더링

```jinja2
{% for cat in categories %}
## {{ cat.number }}. {{ cat.name }}

### {{ cat.number }}.1 추출 가능 이유
{{ cat.rationale }}

### {{ cat.number }}.2 조사 대상 파일 목록
{% for f in cat.files %}
- `{{ f }}`
{% endfor %}

### {{ cat.number }}.3 상세 내용

| # | 파일 | 클래스/함수/변수 | 물리명 | 논리명 | 데이터 타입 | 값/기본값 | 의미 |
|---|------|------------------|--------|--------|-------------|-----------|------|
{% for item in cat.items %}
| {{ item.number }} | `{{ item.file }}` | {{ item.structure }} | `{{ item.physical_name }}` | {{ item.logical_name }} | `{{ item.data_type }}` | {{ item.default }} | {{ item.meaning }} |
{% endfor %}

### {{ cat.number }}.4 해석 메타데이터
{{ cat.interpretation }}
{% endfor %}
```

같은 JSON이 들어오면 **항상 동일한 Markdown**이 출력됩니다. 병합 과정의 ad-hoc 작업이 완전히 제거됩니다.

---

## Phase 4: Diff 검증

```
=== 메타데이터 변경 리포트 ===
이전: 1,411개 -> 현재: 1,423개 (+12)
안정성 점수: 0.9915 (99.15%)

[신규 추가] 12개:
  + automsa/common/module/new_feature.py:15:threshold  (Cat 5)
  ...

[삭제] 0개
[의미 변경] 0개
[카테고리 이동] 0개
```

---

## 비용/시간/재현성 비교

| 항목 | 순수 LLM (7 에이전트) | 하이브리드 |
|------|----------------------|-----------|
| Phase 1 (추출) | - | **30초** (AST) |
| Phase 2 (해석) | 7 에이전트 x 5분 = **35분** | 14 API 호출 x 30초 = **7분** |
| Phase 3 (렌더링) | 수동 병합 **10분** | **1초** (Jinja2) |
| Phase 4 (검증) | 수동 확인 | **1초** (자동) |
| **총 시간** | **~50분** | **~8분** |
| **토큰 비용** | ~500K tokens | ~80K tokens (1/6) |
| **재현성** | ~70% | **~99%** |
| **코드 변경 시** | 전체 재실행 | 변경분만 재실행 |

---

## 점진적 도입 경로

한 번에 전체를 구축할 필요 없습니다:

### Step 1: AST Skeleton만 생성 (즉시 효과)

```bash
python extractor.py phase1 /path/to/repo --output skeleton.json
```

이것만으로도 **행 수, 행 순서, 카테고리 분류가 100% 고정**됩니다. skeleton.json을 에이전트에게 전달하면, 에이전트는 빈 칸(논리명, 의미)만 채우면 됩니다.

> Step 1만으로 가장 큰 문제(비결정성)의 80%가 해결됩니다.

### Step 2: LLM API 자동화 + 이전 결과 참조

Claude API로 논리명/의미를 자동 채우고, previous.json 참조 메커니즘을 추가합니다.

### Step 3: 템플릿 + Diff 리포트 + CI/CD 통합

Jinja2 렌더링, Diff 검증을 완성하고, 코드 변경 시 자동 실행되도록 CI/CD에 통합합니다.

---

## AST만으로는 부족한 영역

하이브리드 파이프라인에서도 LLM이 여전히 필수적인 영역이 있습니다:

### 파일 스키마 추출

TSV/FASTA 파일의 스키마(구분자, 컬럼 순서, 생산/소비 함수)는 AST로 **함수 시그니처**는 추출할 수 있지만, **실제 write 로직** (f-string 안의 컬럼 순서, 조건부 컬럼 등)은 코드 흐름 분석이 필요합니다.

### 해석 메타데이터 (N.4 섹션)

항목 간 관계, 암묵적 규칙, 상태 전이 조건 등은 코드의 **의미론적 이해**가 필요하며, AST의 구문론적 분석만으로는 도출할 수 없습니다.

### 카테고리 경계의 애매한 항목

규칙 기반 분류로 90%는 해결되지만, 여러 카테고리에 걸치는 항목의 "주 카테고리" 결정은 LLM의 판단이 필요합니다.

---

## 결론

대규모 코드베이스의 메타데이터를 주기적으로 추출해야 하는 상황에서:

1. **코드 파서(AST)가 사실을 고정하고, LLM은 해석만 담당하는 하이브리드가 정답이다**
2. **이전 실행 결과를 참조**하면 LLM 해석의 안정성도 95%+로 올릴 수 있다
3. **Jinja2 템플릿**으로 렌더링하면 출력 형식이 100% 결정적이다
4. **Diff 검증**으로 변경을 추적하면 운영 환경에서의 안정성이 보장된다
5. **Step 1(AST Skeleton)만으로도** 비결정성 문제의 80%가 즉시 해결된다

한마디로: **"무엇을 추출할 것인가"는 프롬프트의 영역이지만, "어떻게 안정적으로 반복할 것인가"는 아키텍처의 영역이다.**
