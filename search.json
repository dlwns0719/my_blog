[
  {
    "objectID": "about.html#enthusiastic-data-scientist",
    "href": "about.html#enthusiastic-data-scientist",
    "title": "Kwangmin Kim",
    "section": "2 Enthusiastic Data Scientist",
    "text": "2 Enthusiastic Data Scientist\n\n2.1 Interests\nData Modeling, Statistics, Machine Learning, Deep Learning, Optimization"
  },
  {
    "objectID": "docs/blog/index.html",
    "href": "docs/blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n01-Data Lake Storage\n\n\n\n\n\n\nAzure Cloud\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpenAI 외 도구 호출 에이전트(Tool Calling Agent)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n도구 (Tools)\n\n\n\n\n\n\nAI\n\nLangChain\n\nPrompt_Engineering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIteration 기능과 사람 개입(Human-in-the-loop)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM 에 도구 바인딩(Binding Tools)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n도구 호출 에이전트(Tool Calling Agent)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n문맥 압축 검색기(ContextualCompressionRetriever)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n앙상블 검색기(Ensemble Retriever)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParent Document Retriever\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiQueryRetriever\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsemble Retriever Convex Combination(CC) 추가\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n셀프 쿼리(Self-querying)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n한글 단어 리트리버 튜닝\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n시간 가중 벡터저장소 리트리버(TimeWeightedVectorStoreRetriever)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n벡터스토어 기반 검색기(VectorStore-backed Retriever)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n긴 문맥 재정렬(LongContextReorder)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n다중 벡터저장소 검색기(MultiVectorRetriever)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart 2 — 프롬프트 구조와 기능 탐구\n\n\n\n\n\n\nAI\n\nLangChain\n\nPrompt_Engineering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart 1 — 프롬프트 구조와 기능 탐구\n\n\n\n\n\n\nAI\n\nLangChain\n\nPrompt_Engineering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart 1 — 프롬프트 분석의 필요성과 가치\n\n\n\n\n\n\nAI\n\nLangChain\n\nPrompt_Engineering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart 2 — 사용자 언어 읽기(프롬프트 구조와 유형)\n\n\n\n\n\n\nAI\n\nPrompt_Engineering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart 3 — 대화 분석(사용자-AI 상호작용 매커니즘)\n\n\n\n\n\n\nAI\n\nPrompt_Engineering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAzure Cloud\n\n\nAzure Cloud Content List\n\n\n\nAzure Cloud\n\n\n\n\n\n\n\n\n\nNov 1, 2025\n\n\nJunhyun Lee\n\n\n\n\n\n\n\n\n\n\n\n\nRAG\n\n\nRAG Content List\n\n\n\nAI\n\nLangChain\n\nRAG\n\n\n\nRetrieval-Augmented Generation (RAG) 기술의 전체 구현 과정을 다루는 종합 가이드. LangChain을 활용한 RAG 시스템 구축, 문서 로딩, 임베딩, 벡터 저장소, 검색기, 그리고 고급 RAG 기법까지 단계별로 학습할 수 있는 실습 중심의 블로그 모음입니다.\n\n\n\n\n\nNov 1, 2025\n\n\nJunhyun Lee\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt_Engineering\n\n\nPrompt_Engineering Content List\n\n\n\nAI\n\nLangChain\n\nRAG\n\n\n\n\n\n\n\n\n\nNov 1, 2025\n\n\nJunhyun Lee\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Blog",
      "Blog Posts"
    ]
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html",
    "title": "Part 3 — 대화 분석(사용자-AI 상호작용 매커니즘)",
    "section": "",
    "text": "이 장을 통해 다음을 학습할 수 있습니다:\n사용자-AI 간에 대화를 분석하는 이유는 다음과 같습니다:\n\n사용자의 의도를 정확하게 알기 위해 그들의 언어 표현을 이해한다: 사용자가 프롬프트에서 표현하는 언어를 분석하여 정확한 의도를 파악합니다.\n그 뒷턴에서 어떻게 상호작용을 하고 있고, 어떤 반응을 보이고 그 반응의 의미가 무엇인지 확인: AI 응답을 받은 사용자가 어떻게 상호작용하는지, 어떤 반응을 보이는지, 그리고 그 반응의 의미를 분석합니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html#turn-턴",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html#turn-턴",
    "title": "Part 3 — 대화 분석(사용자-AI 상호작용 매커니즘)",
    "section": "2.1 Turn (턴)",
    "text": "2.1 Turn (턴)\nTurn은 대화에서 한 사람이 말을 시작하고 끝내는 한 단위의 발화를 의미합니다. 대화는 이러한 턴들의 연속으로 구성됩니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html#structure-구조",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html#structure-구조",
    "title": "Part 3 — 대화 분석(사용자-AI 상호작용 매커니즘)",
    "section": "2.2 Structure (구조)",
    "text": "2.2 Structure (구조)\nStructure는 대화의 전반적인 조직 방식을 의미합니다.\n\n핵심 개념: 턴이 확장되면 스트럭처(Structure)가 됩니다.\n\n개별 턴들이 모여서 대화의 전반적인 구조를 형성하며, 여기에는 다음이 포함됩니다:\n\n턴의 교환 규칙: 누가 언제 말할 수 있는지에 대한 규칙\n대화의 순서: 턴들이 어떤 순서로 배치되는지\n주제 전환: 대화 주제가 어떻게 변화하는지\n대화 참여자 간의 상호작용 패턴: 사용자와 AI가 어떻게 상호작용하는지에 대한 패턴\n\nStructure는 개별 턴들의 단순한 나열이 아니라, 턴들이 어떻게 조직되고 상호작용하는지를 보여주는 대화의 전체적인 구조입니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html#첫-번째-기준-turn",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html#첫-번째-기준-turn",
    "title": "Part 3 — 대화 분석(사용자-AI 상호작용 매커니즘)",
    "section": "3.1 첫 번째 기준: Turn",
    "text": "3.1 첫 번째 기준: Turn\n\n3.1.1 싱글턴\n싱글턴은 한 가지 주제에 대해 한 번의 질문-답변으로 완결되는 대화 구조입니다.\n\n한 가지 주제만 다룹니다\n사용자가 한 번의 질문으로 원하는 정보를 얻습니다\n대화가 짧고 간결합니다 \n\n\n\n3.1.2 멀티턴\n멀티턴은 여러 가지 주제를 다루거나, 한 주제에 대해 여러 번의 질문-답변을 통해 목적을 달성하는 대화 구조입니다.\n\n여러 가지 주제를 다룹니다\n또는 한 주제에 대해 단계적으로 질문을 이어갑니다\n여러 번의 상호작용을 통해 목적을 달성합니다 \n\n\n\n3.1.3 프롬프트 작성 실습\n실습 문제\n다음 데이터에서 싱글턴과 멀티턴을 구분하는 프롬프트를 제작해보세요.\nText Data #1\nText Data #1: \n사용자: 선물하기 좋은 건강식품 알려줘  \nAI: 건강식품은 선물하기에 좋은 제품 중 하나입니다. 다만, 상대방의 건강 상태와 목적에 맞게 선택하는 것이 중요합니다. 일반적으로 선물하기 좋은 건강식품으로는 아래와 같은 것들이 있습니다.\n\n1. 골드 컬라겐\n2. 비타민C\n3. 오메가3 \n4. 멀티비타민\n5. 프로바이오틱스/유산균 \n6 .녹차추출물 \n7 .비타민D \n8 .루테인  \n9 .아연  \n10 히알루론산\n\n위의 제품들을 포함한 다양한 건강기능식品을 구매할 수 있는 오프라인 및 온라인 쇼핑몰에서 구입하실 수 있습니다.하지만, 제조사와 모델에 따라 가격대가 상이하기 때문에 구매 전 충분한 검색과 비교 분석 후 선택하는 것이 좋습니다.\n상대방의 식습관과 알러지 여부 등도 함께 고려하여 선택해주시길 바랍니다. \n\n사용자: 해루질뜻\n\nAI: 해루질이란, 어떤 일을 하다가 중간에 멈추고 다른 일로 바꾸는 것을 말합니다. 예를 들어, 공부하다가 갑자기 스마트폰으로 살짝 눈길이 가면서 SNS를 확인하는 것도 해루질다고 할 수 있습니다. 이러한 행동은 집중력 저하와 같은 부작용을 유발할 수 있으므로 주의해야 합니다.\n\n결과\nYour Answer: { Multiple turns }.\nText Data #2\nText Data #2: \n사용자: 임대에서 임차인이 사업자가 아닌경우 일반과세사업사는 부가세 신고를 해야하는가\nAI:일반과세사업자의 경우, 임대료에 부가세를 포함하여 청구해야 합니다. 그러나 임차인이 사업자가 아닌 경우에는 일반 소비자로 간주되어 부가세를 신고하지 않아도 됩니다.\n일반적으로 일반과세사업자는 매출액에서 직접 구입한 상품이나 서비스의 세금을 차감한 금액을 국세청에 납부하게 되며, 이 과정에서 발생하는 세금은 최종 소비자들이 부담하게 됩니다. 하지만 임차인이 사업장 등록증을 가진 사람(법인) 뿐만 아니라 개인(소득공제 대상)일 때도 해당될 수 있으므로 확인 후 처리해야 합니다.\n그러므로 정확한 정보와 절차를 위해서 전문 회계사와 상담하거나 국내 세무서 및 관련 기관 등에서 자문 받으시기 바랍니다.\n사용자: 오피스텔 임대에서 임차인이 사업자가 아닌경우 임대인 일반과세사업자는 부가세 신고를 해야하는가?\nAI:오피스텔 임대의 경우, 일반과세사업자인 임대인이 사업자가 아닌 개인에게 오피스텔을 임대할 때 부가세 신고 여부는 다음과 같습니다.\n일반적으로 주거용 오피스테를 개인에게 임대하는 경우 면세 대상입니다. 따라서 일반 과세사업자임에도 불구하고 이러한 거래에서 발생하는 부가 가치 세금은 면제되며 별도로 신고하지 않아도 됩니다.\n그러나 상황이 달라질 수 있으므로 전문 회계사와 상담하거나 국내 세무서 및 관련 기관 등에서 자문 받으시기 바랍니다.\n잘 만들어진 프롬프트 예시\nYour task is to determine whether the given text represents a single turn or multiple turns.\n\n- Single turn: involves only one topic.\n- Multiple turns: involves two or more conversational topics.\n\nText: {           }.\n\nYour Answer: {         }.\n결과\nYour Answer: { Single turn }.\n\n\n3.1.4 핵심 포인트\n위의 잘 만들어진 프롬프트 예시를 통해 Turn 기준의 핵심 포인트를 살펴보겠습니다:\n\n싱글턴의 핵심 구분 기준: 프롬프트에서 “Single turn: involves only one topic”이라고 명시한 것처럼, 싱글턴은 한 가지 주제만 다루는 대화 구조입니다. 한 번의 질문-답변으로 완결되며, 대화가 짧고 간결합니다.\n멀티턴의 핵심 구분 기준: 프롬프트에서 “Multiple turns: involves two or more conversational topics”라고 명시한 것처럼, 멀티턴은 두 가지 이상의 대화 주제를 다루는 대화 구조입니다. 여러 번의 상호작용을 통해 목적을 달성합니다.\n구분 방법: 주제의 개수를 기준으로 구분합니다. 한 가지 주제면 싱글턴, 두 가지 이상의 주제면 멀티턴입니다. 예를 들어, Text Data #1은 “건강식품”과 “해루질”이라는 두 가지 주제를 다루므로 멀티턴입니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html#두-번째-기준-action",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html#두-번째-기준-action",
    "title": "Part 3 — 대화 분석(사용자-AI 상호작용 매커니즘)",
    "section": "3.2 두 번째 기준: Action",
    "text": "3.2 두 번째 기준: Action\n\n3.2.1 생성형 AI 이용자는 무엇을 할까?\n사용자가 AI와 상호작용할 때 수행하는 행위(Action)는 크게 두 가지로 분류할 수 있습니다:\n\n정보 검색 유형: 특정 정보를 찾거나 질문에 답을 얻는 행위\n\n예: “오늘 날씨 알려줘”, “파이썬 문법 설명해줘”, “건강식품 추천해줘”\n\n다른 행위 유형: 정보 검색 이외의 다양한 행위\n\n작문: 텍스트 생성, 요약, 번역 등\n상담: 전문가의 조언이나 안내를 받는 행위\n캐릭터 AI 게임: 특정 캐릭터나 페르소나와의 대화형 게임이나 역할극\n나만의 상담사: 개인 맞춤형 상담 서비스나 심리 상담 등\n창작 활동: 스토리 작성, 시나리오 작성, 아이디어 브레인스토밍 등\n학습 도우미: 문제 풀이, 개념 설명, 학습 계획 수립 등\n\n\n\n\n3.2.2 Action 유형 및 판단 근거\nAction 유형을 판단하는 여러 가지 근거가 있습니다:\n1. 동사 분석\n사용자의 동사를 보면 유형을 판단할 수 있습니다:\n\n정보 검색 유형: “알려줘”, “설명해줘”, “찾아봐”, “추천해줘”, “어떻게 해야 해”, “방법 알려줘” 등\n작문 유형: “써줘”, “쓸거야”, “써봐”, “작성해줘”, “만들어줘”, “나열해줘”, “추가해줘”, “변경해줘” 등\n번역 유형: “번역해줘”, “번역해봐”, “영어로”, “한국어로” 등\n상담 유형: “조언해줘”, “도와줘”, “어떻게 생각해”, “추천해줘” (상황에 따라) 등\n\n2. 키워드 분석\n프롬프트에 포함된 키워드를 분석하여 판단할 수 있습니다:\n\n정보 검색 키워드: “알려줘”, “설명”, “방법”, “어떻게”, “무엇”, “왜”, “언제”, “어디서” 등\n작문 키워드: “작성”, “글”, “문서”, “요약”, “정리”, “구조”, “형식” 등\n창작 키워드: “이름 지어줘”, “아이디어”, “스토리”, “시나리오” 등\n상담 키워드: “조언”, “도움”, “추천”, “어떻게 해야 할까” 등\n\n3. 프롬프트의 목적 분석\n사용자가 원하는 최종 결과물의 성격을 분석합니다:\n\n정보 제공이 목적: 기존 정보를 찾거나 설명을 받는 경우 → 정보 검색\n새로운 콘텐츠 생성이 목적: 텍스트, 문서, 아이디어 등을 새로 만드는 경우 → 작문/창작\n상호작용이 목적: 대화, 게임, 역할극 등을 즐기는 경우 → 다른 행위 유형\n\n4. 문맥 분석\n프롬프트의 전체적인 문맥을 분석합니다:\n\n질문 형식: “~는 무엇인가?”, “~는 어떻게 하는가?” → 정보 검색\n요청 형식: “~를 작성해줘”, “~를 만들어줘” → 작문\n역할 설정: “너는 ~야”, “당신은 ~입니다” → 상담 또는 게임/역할극\n\n5. 출력물의 성격 분석\nAI가 생성해야 하는 결과물의 성격을 분석합니다:\n\n기존 정보의 설명: 정보 검색\n새로운 텍스트 생성: 작문\n대화형 상호작용: 상담, 게임, 역할극\n\n\n\n\n\n\n\n\n사용자 프롬프트\nAction\n\n\n\n\n콜드브루의 나라별 브랜드명 알려줘\n정보 검색\n\n\n네이버 블로그에 국내 핀테크 기업에 대한 소개글을 쓸거야 서론 적어줘\n작문\n\n\n여러 개의 이미지가 포함된 파일에서 한 개의 파일만 따로 분리하는 방법 설명해봐\n정보 검색\n\n\n이 문장에서 앞뒤 내용 반전시키는 문장을 추가해줘\n작문\n\n\n반지의제왕 소설을 발단, 전개, 위기, 절정, 결말의 5막 구조 형식으로 요약해서 써봐\n작문\n\n\n이링크와비슷한제품을팔고있는사이트세개를찾아봐\n정보 검색\n\n\n너는 면접 전문가야. 나는 대학의 행정 팀에 지원할 예정이야. 예상되는면접질문을나열해줘\n작문\n\n\n\n\n\n3.2.3 프롬프트 작성 실습\n실습 문제\n사용자의 행위(Action)를 추출하는 프롬프트를 제작해보세요.\n잘 만들어진 프롬프트 예시\n주어진 텍스트를 읽고 사용자의 \"Intention\"을 추출해.\nIntention은 다음처럼 단어로 뽑아야해.\n\n- 정보 검색\n- 작문\n- 번역\n- 상담\n테스트 데이터\n\n전기차의 발전이 인류에 미치는 영향\n미용실 이름 지어줘\n엑셀로 지정한 날짜를 찾는 수식 만들어줘\n지저분한 방 청소하는 법\n뮬란에 대해 설명해 줘\n\n결과\n아래는 각 문장의 사용자 Intention을 단일 단어로 분류한 결과이다.\n\n정보 검색\n작문\n작문\n정보 검색\n정보 검색\n\n\n\n3.2.4 핵심 포인트\n\n💡 실무적 활용: 이렇게 다양한 분석 방법을 통해 어떤 누군가의 프롬프트를 보고 유형을 판단하면, 해당 프롬프트가 정보 검색 유형인지 작문 유형인지 등을 파악할 수 있습니다. 이를 통해 정보 검색을 더 잘할 수 있게끔 또는 작문을 더 잘할 수 있게끔 고도화할 수 있는 아이디어를 얻을 수 있습니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html#세-번째-기준-structure",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html#세-번째-기준-structure",
    "title": "Part 3 — 대화 분석(사용자-AI 상호작용 매커니즘)",
    "section": "3.3 세 번째 기준: Structure",
    "text": "3.3 세 번째 기준: Structure\n\n3.3.1 AI 답변을 받은 사용자는 만족할까? 불만족할까?\nStructure는 사용자가 AI의 응답에 대해 만족하거나 불만족할 때 나타나는 대화 구조를 분석하는 기준입니다.\n\n\n3.3.2 Preferred Response (선호 응답 구조)\n사용자가 AI의 응답에 만족할 때 나타나는 구조입니다. 특징은 다음과 같습니다:\n\n답변 길이가 짧다: 단답형 응답\n언어 표현이 다양하다: 감사, 긍정적 평가 등 다양한 표현 사용\n주요 표현: “감사합니다”, “고맙습니다”, “땡큐”, “대단하다”, “좋아”, “와우!”, “맘에 들어요” 등\n\n\n\n3.3.3 Dispreferred Response (비선호 응답 구조)\n사용자가 AI의 응답에 불만족할 때 나타나는 구조입니다. 특징은 다음과 같습니다:\n\n답변 길이가 길다: 불만을 설명하거나 수정을 요청\n불만의 정도: 약한 불만 → 중간 불만 → 강한 불만\n주요 행동: 부인, 비난, 반박, 거절, 질책 등\n\n\n\n3.3.4 사용자의 만족과 불만족 시에 따른 언어 특징\n\n\n\n\n\n\n\n\n구분\n만족\n불만족\n\n\n\n\n턴 구조\n선호\n비선호\n\n\n특징\n답변 길이가 짧다. 단답형이다. 언어 표현이 다양하다.\n답변 길이가 길다.\n\n\n행동\n답변에 대한 감사, 답변에 대한 평가\n불만의 정도: 약한, 중간, 강함, 부인, 비난, 반박, 거절, 질책\n\n\n\n\n\n3.3.5 프롬프트 작성 실습\n실습 문제\n다음은 사용자의 불만족이 드러난 데이터입니다. 사용자의 불만을 완화하기 위한 아이디어를 생각하고 프롬프트로 제작해보세요.\nText Data\n사용자: 영어로 번역좀 해줘.\n안녕하세요 렌트비를 인상하는 것에 대해 우려가 많습니다. 작년에도 한 차례 렌트비 인상이 있었습니다. 당시 15% 인상률이었는데요. 이번 해에도 또 15%나 올리는 것은 부당하다고 생각됩니다. 저에게는 엄청난 경제적 부담이 돼요.\n\nAI: Hello, I have many concerns about raising the rent. There was already an increase in rent last year. At that time, it was raised by 15%. I think it's unfair to raise it by another 15% this year. It's a huge financial burden for me.\n\n사용자: 음.. 문장이 별로인데 좀 표현이 단호하면 좋겠어\n잘 만들어진 프롬프트 예시\n아래 텍스트를 영어로 번역 해줘.\n\nText: 안녕하세요 렌트비를 인상하는 것에 대해 우려가 많습니다. 작년에도 한 차례 렌트비 인상이 있었습니다. 당시 15% 인상률이었는데요. 이번 해에도 또 15%나 올리는 것은 부당하다고 생각됩니다. 저에게는 엄청난 경제적 부담이 돼요.\n\n조건: Assertive 한 단어와 표현 사용.\n결과\n\n\n\n3.3.6 핵심 포인트\n그래서 Structure 기준의 핵심 포인트는 다음과 같습니다:\n\n선호 응답 구조: 만족 시 짧고 긍정적인 응답\n비선호 응답 구조: 불만족 시 긴 설명과 수정 요청\n불만 완화 전략: 구체적인 조건이나 스타일을 명시하여 사용자의 요구를 정확히 반영"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html#네-번째-기준-stance",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/03-대화분석.html#네-번째-기준-stance",
    "title": "Part 3 — 대화 분석(사용자-AI 상호작용 매커니즘)",
    "section": "3.4 네 번째 기준: Stance",
    "text": "3.4 네 번째 기준: Stance\n\n3.4.1 사용자는 AI에게 감정이 있을까? 없을까?\nStance는 사용자가 AI와의 대화에서 보이는 감정적 태도를 분석하는 기준입니다.\n\n\n3.4.2 감정적 태도 vs. 비감정적 태도\n사용자는 때때로 AI에게 감정을 표현하기도 합니다. 이는 단순한 정보 교환을 넘어서는 상호작용을 의미할 수 있습니다.\n\n감정적 태도: 감정 표현, 친근한 톤, 개인적 경험 공유 등\n비감정적 태도: 객관적이고 사실적인 정보 요청\n\n\n\n3.4.3 핵심 포인트\n그래서 Stance 기준의 핵심 포인트는 다음과 같습니다:\n\n감정적 태도: 사용자가 AI와의 관계에서 감정을 표현하는 경우\n비감정적 태도: 순수하게 정보나 작업을 요청하는 경우\nStance 분석의 중요성: 사용자의 감정적 상태를 파악하여 적절한 톤과 스타일로 응답할 수 있습니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html",
    "title": "Part 1 — 프롬프트 분석의 필요성과 가치",
    "section": "",
    "text": "ChatGPT 사용자 경험 연구 결과, 많은 사용자들이 AI 답변에 불만을 느끼고 있습니다.\n\n\n\n\n실제 ChatGPT 대화 로그를 분석한 연구에서: - 107명의 응답자로부터 307개의 ChatGPT 대화 로그 수집 - 511개의 사용자 불만 사례 분석 - 7가지 사용자 불만 카테고리 식별\n\n\n\n가장 빈번한 불만은 다음과 같습니다:\n\n\n\n의도와 다른 답변 제공\n맥락 파악 실패\n\n\n\n\n\n잘못된 정보 포함\n사실과 다른 내용\n\n\n\n\n\n답변이 너무 일반적임 (21.7%)\n답변 형식 오류 (20.5%)\n답변 거절 (3.9%)\n\n\n\n\n\n불만족스러운 답변에 대한 사용자 대응 전략 5가지:\n\n프롬프트 재사용: 이전 프롬프트를 그대로 재사용\n의도 구체화: 질문을 구체화하여 재질문\n오류 식별 및 수정: 잘못된 답변 지적 및 수정 요청\n작업 적응: 작업이나 요구사항 변경 후 재시도\n없음 (No Tactic): 특별한 전략 없이 진행하거나 포기\n\n\n\n\n불만족스러운 답변에 대해 60.9%가 단순히 질문을 구체화하여 재질문합니다.\n사용자들은 프롬프트 작성에 최소한의 노력만 기울입니다.\n\n‘전술 없음’ 또는 ‘프롬프트 재사용’을 자주 사용\n효과적인 프롬프트 작성 방법에 대한 지식 부족\n질문 개선 방법을 모름\nAI와 효과적 소통 방법을 이해하지 못함\n같은 질문을 반복하거나 약간만 수정\n\n사용자들은 AI의 한계를 탓하지만, 실제로는 자신의 질문 방식에 문제가 있다는 것을 인식하지 못합니다.\n이것이 프롬프트 엔지니어링의 필요성이 대두되는 이유입니다.\n\n\n\n\n급격히 변화하는 AI 시대에서 사회적 기능을 유지하려면 일상의 혁신이 필요합니다.\n단순히 질문을 던지는 것이 아니라, 깊이 생각하고 행동으로 실천해야 합니다.\n“Think First” not “Just Do it”\n\n\n\n\n과거에는 모두에게 동일한 서비스를 제공했습니다. 이후 그룹 맞춤화로 발전했고, 이제는 개개인의 고유한 특성을 고려한 하이퍼 퍼스널라이제이션 시대입니다.\nAI와의 상호작용도 개인화되어야 합니다. 각 사용자의 목적, 맥락, 선호도를 반영한 프롬프트를 작성하는 것이 프롬프트 엔지니어링입니다.\n일반적인 질문에는 일반적인 답변만 나옵니다. 개인 특성을 고려한 프롬프트는 최적화된 답변을 제공합니다. 이것이 프롬프트 엔지니어링이 중요한 이유입니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html#연구-개요",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html#연구-개요",
    "title": "Part 1 — 프롬프트 분석의 필요성과 가치",
    "section": "",
    "text": "실제 ChatGPT 대화 로그를 분석한 연구에서: - 107명의 응답자로부터 307개의 ChatGPT 대화 로그 수집 - 511개의 사용자 불만 사례 분석 - 7가지 사용자 불만 카테고리 식별"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html#주요-불만-사항",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html#주요-불만-사항",
    "title": "Part 1 — 프롬프트 분석의 필요성과 가치",
    "section": "",
    "text": "가장 빈번한 불만은 다음과 같습니다:\n\n\n\n의도와 다른 답변 제공\n맥락 파악 실패\n\n\n\n\n\n잘못된 정보 포함\n사실과 다른 내용\n\n\n\n\n\n답변이 너무 일반적임 (21.7%)\n답변 형식 오류 (20.5%)\n답변 거절 (3.9%)"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html#사용자들의-해결-전략",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html#사용자들의-해결-전략",
    "title": "Part 1 — 프롬프트 분석의 필요성과 가치",
    "section": "",
    "text": "불만족스러운 답변에 대한 사용자 대응 전략 5가지:\n\n프롬프트 재사용: 이전 프롬프트를 그대로 재사용\n의도 구체화: 질문을 구체화하여 재질문\n오류 식별 및 수정: 잘못된 답변 지적 및 수정 요청\n작업 적응: 작업이나 요구사항 변경 후 재시도\n없음 (No Tactic): 특별한 전략 없이 진행하거나 포기"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html#문제의-근본-원인-사용자의-최소한의-노력",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html#문제의-근본-원인-사용자의-최소한의-노력",
    "title": "Part 1 — 프롬프트 분석의 필요성과 가치",
    "section": "",
    "text": "불만족스러운 답변에 대해 60.9%가 단순히 질문을 구체화하여 재질문합니다.\n사용자들은 프롬프트 작성에 최소한의 노력만 기울입니다.\n\n‘전술 없음’ 또는 ‘프롬프트 재사용’을 자주 사용\n효과적인 프롬프트 작성 방법에 대한 지식 부족\n질문 개선 방법을 모름\nAI와 효과적 소통 방법을 이해하지 못함\n같은 질문을 반복하거나 약간만 수정\n\n사용자들은 AI의 한계를 탓하지만, 실제로는 자신의 질문 방식에 문제가 있다는 것을 인식하지 못합니다.\n이것이 프롬프트 엔지니어링의 필요성이 대두되는 이유입니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html#변화하는-사회에서의-일상의-혁신",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html#변화하는-사회에서의-일상의-혁신",
    "title": "Part 1 — 프롬프트 분석의 필요성과 가치",
    "section": "",
    "text": "급격히 변화하는 AI 시대에서 사회적 기능을 유지하려면 일상의 혁신이 필요합니다.\n단순히 질문을 던지는 것이 아니라, 깊이 생각하고 행동으로 실천해야 합니다.\n“Think First” not “Just Do it”"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html#하이퍼-퍼스널라이제이션-시대의-프롬프트-엔지니어링",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/01-프롬프트분석.html#하이퍼-퍼스널라이제이션-시대의-프롬프트-엔지니어링",
    "title": "Part 1 — 프롬프트 분석의 필요성과 가치",
    "section": "",
    "text": "과거에는 모두에게 동일한 서비스를 제공했습니다. 이후 그룹 맞춤화로 발전했고, 이제는 개개인의 고유한 특성을 고려한 하이퍼 퍼스널라이제이션 시대입니다.\nAI와의 상호작용도 개인화되어야 합니다. 각 사용자의 목적, 맥락, 선호도를 반영한 프롬프트를 작성하는 것이 프롬프트 엔지니어링입니다.\n일반적인 질문에는 일반적인 답변만 나옵니다. 개인 특성을 고려한 프롬프트는 최적화된 답변을 제공합니다. 이것이 프롬프트 엔지니어링이 중요한 이유입니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "",
    "text": "범용성: 다양한 상황에서도 동작, 불특정 다수의 사용자 대상 다양한 상황과 과제에 적용 가능한 프롬프트의 결과를 내야 한다.\n\n목적 지향성: 특정 사용자 목적에 세분화된 기능을 제공해야 한다.\n일관성: 여러가지 LLM 모델을 사용하더라도, 생성 할 때마다 결과가 바뀌면 안된다. 어느정도 스펙트럼 안에서 일정한 결과 유지.\n경제성: 단어, 토큰수 운영 비용 API 비용 절감\n\n\n\n\n\n비계식 설계\n인간의 학습 이론(ZPD)을 적용\n외국어를 학습하는 사람들의 학습 능력을 최대한 끌어올리려면, 최대한 쉬운 단계부터 어려운 단계까지 차츰차츰 비계식으로 올라가야 한다.\n단어 -&gt; 문장 -&gt; 문단 완성을 하는 단계별 학습 방식 사용\n프롬프트 설계를 할떄도 이 방식을 사용하면 정말 잘 설계를 할 수 있다.\nUnderstand → Ideation → Analysis → Apply → Evaluate → Generalize\n풀어야될 문제(요구사항)에 대한 이해\n문제에 대한 이해를 바탕으로 여러가지 프롬프트를 만드는 아이디에이션 진행.\n아이디에이션을 통해 구현된 프롬프트를 분석.\n실제로 도입, 적용, 평가\n일반화 할 수 있는 결과를 얻으면 배포 진행.\n단계적 사고구조 유도\n\n\n\n\n\n\n\n최근까지 GPT 4/5\n최신모델을 사용하면 프롬프트가 조금 엉성해도 좋은 결과를 얻을 수 있다.\n그러나 GPT 3.5을 이용해 A 라는 기능을 4/5 만큼 끌어올릴 수 있다면, 이 방법이 좋은 방법이다.\n\n\n\n\n어떤 단어가 좀더 구체적, 또는 명확하게 표현이 되어있는지 확인 조금더 명확한 동작을 하는 단어가 있을 수 있다. 뭐를 나누다 라는 맥락이 없으면 뜻을 정확하게 이해하기가 어려운 언어이다. 예: 분석해, 정리해, 요약해, 작성해 등 –&gt; 정확하게 무엇을 하려고 하는지 맥락 없어도 이해 가능하다.\n\n\n\n구조화라 함은 어떻게 요소별로 나눈다던지 섹션별로 컴포지션을 나누어서, 언어모델이 읽기 편한 구조를 만든다. 대표적으로 2가지 방법(Markdown, 코드 프롬프트)이 있다. 프롬프트를 구조화하면 LLM이 입력을 더 명확하게 해석할 수 있고,\n작업 목적·규칙·입력 데이터·출력 형식을 혼동 없이 처리할 수 있다.\n구조화를 위한 핵심 기법은 Markdown, 코드 프롬프트, XML 태그이다.\n\nMarkdown 기호 사용하기 (Headers, Lists, Emphasis)\n\nMarkdown은 LLM이 가장 잘 해석하는 구조적 문법 중 하나이다.\n섹션을 명확히 나누고, 각 부분을 시각적으로 구분해줌으로써\n모델의 오류를 줄이고 반복 작업 시 유지보수성이 높아진다.\n1.1 헤더(Headers) 활용 헤더는 프롬프트의 구성을 크게 나누는 데 사용한다. 샾 개수만큼 주 제목, 부제목, 소제목 등의 계층적 우선순위 인덱스를 부여할 수 있다.\n# 역할(Role)\n너는 스포츠 기사 분석 엔진이다.\n\n## 작업(Task)\n아래 텍스트에서 장소(도시, 국가, 축구 클럽)를 모두 추출해라.\n\n## 출력 형식(Format)\n- \"장소: A, B, C\" 형태의 한 줄 출력\n- 설명 금지\n\n## 텍스트(Text)\n{{TEXT}}\n1.2 목록(Lists) 활용 하이픈이나, 번호를 이용 –&gt; 수행할 순서가 있는 프롬프트에 사용한다. 절차, 규칙, 조건을 번호 목록으로 정리하면 LLM이 하나씩 적용하기 쉽다.\n다음 규칙을 따라 작업을 수행해라.\n1. 사람 이름은 제외한다.\n2. 축구 클럽은 장소로 포함한다.\n3. 결과는 쉼표로 구분한다.\n4. 설명 문장은 쓰지 않는다.\n1.3 강조(Emphasis) 사용\n중요 조건을 굵게 또는 기울임으로 표시해 모델의 우선순위를 높인다. 실제로 이탤릭, 볼드체로 표현은 되지 않는다. 언어모델에게 일반 줄글의 텍스트가 아닌 다른 요소임을 강조.\n- 반드시 **한국어**로 작성하라.\n- 출력은 **한 줄**로만 작성한다.\n- *설명 문장은 포함하지 않는다.*\n\n코드 프롬프트(Code Prompting)\n\n구조화를 좀더 구체적으로 하는 방식에 대해서 소개. AdaPlanner 논순 발췌, 구글의 리서처 분들이 많이 사용한다. 파이썬 언어를 사용해서 언어 모델이 정확히 수행 해야 하는 내용을 작성. 자연어 대신 코드 형식으로 의도를 명세하면 애매함이 줄어들고 LLM이 구조적으로 이해해 할루시네이션이 감소한다.\n# 역할 정의\nrole = \"정보 추출 엔진\"\n\n# 작업 정의\ntask = \"텍스트에서 '장소명'을 추출해 정렬된 리스트로 반환\"\n\n# 출력 형식 정의\noutput = {\n    \"places\": [\"string\"]\n}\n코드 방식의 장점:\n\n논리 구조가 명확하게 표현됨\n조건과 출력 형식이 혼동되지 않음\n정형화된 포맷을 자주 재사용 가능\n\n\nXML 태그 기반 구조화 (Claude 최적화)\n\n엔트로픽 프롬팅 쿡북 참조하면 나오는 내용. 문장 내 구역 나눔, 해당 구적을 강조하는 효과, 반복작업에서 프롬프트 수정과 편집/용이, 언어모델의 처리 속도 향상 XML 태그는 텍스트 내 특정 영역을 명확히 구분해 Claude뿐 아니라 대부분의 LLM에서 구조적 파싱을 돕는 강력한 방식이다.\n이 방식의 장점은 탬플릿이 가능하다.\n\n태그로 영역 지정\n\n&lt;email&gt;\nShow up at 6AM because I say so.\n&lt;/email&gt;\n\nMake this email more polite.\nLLM은 &lt;email&gt;...&lt;/email&gt; 내부 텍스트만 변환하면 된다는 것을 명확히 인식한다.\n\n데이터 템플릿 예시\n\n&lt;animal&gt;{{ANIMAL}}&lt;/animal&gt;\n입력만 바꿔 여러 데이터를 동일한 템플릿에 적용할 수 있다.\n예:\n&lt;animal&gt;Cow&lt;/animal&gt;\n&lt;animal&gt;Dog&lt;/animal&gt;\n&lt;animal&gt;Seal&lt;/animal&gt;\n장점:\n\n구역별 의미가 명확\n반복 작업에서 수정이 쉽고 안정적\n모델이 태그 단위로 파싱하기 때문에 오류 감소\n\n\n구조화 기법이 필요한 이유\n\n\n명령어, 입력 데이터, 출력 형식을 명확히 구분해 모델의 해석 오류를 줄인다.\n규칙을 시각적으로 구분하여 작업 수행 품질의 일관성과 재현성을 높인다.\n재사용 가능한 템플릿이 되어 프롬프트 제작 비용과 시간 절감에 기여한다.\n\n\n\n\n\n한국어는 짧고 명확하게 작성\n톤·형식·분량을 구체적으로 지시\n\n- 나쁜 예\n5월의 봄을 주제로 시를 써주고 짧게\n작성해줘 봄의 느낌을 살려봐.\n결과: 오월의 푸른 하늘 아래\n새싹이 희망을 노래하네.\n아침 이슬에 빛나는 꽃들,\n봄바람 따라 춤추는 나비.\n모든 거리는 축제가 되어.\n\n- 좋은 예\n너는 시인이야. 한국의 계절, 봄을 상상해봐.\n5월이야. 다양한 꽃이 여기저기 폈어.\n그 분위기에 어울리는 짧은 시를 5줄 이내로\n작성해줘. 한글 고유의 멋이 시에 드러나면 좋겠어.\n결과: 봄바람, 너른 들녘을 스치며\n꽃잎들 춤추듯 흩날리네\n산들산들 부는 바람에\n눈부신 햇살 아래\n은은한 꽃 향기에 취하노라\n\n\n\n\n부정 지시보다 긍정적 행동 지시가 안정적 구체적인 내용을 단문 형식으로 제공함과 언어모델에게 추측을 해야 하는 여지를 주면 안된다.\n\n- 나쁜 예\n다음은 에이전트와 고객의 대화이다.\n고객에게 아이디와 비밀번호를 묻지\n않는다. 반복하지 않는다.\n\n- 좋은 예\n다음은 에이전트와 고객과의 대화내용이다.\n챗봇은 고객의 대화에서 드러난 문제를 진단하고 해결책을\n제시해야 한다. 사용자 아이디와 비밀번호같은 개인정보를\n묻지 않는 대신,\n사용자가 www.samplewebsite.com/help/faq에서 관련\n사항을 찾도록 안내해라.\n\n\n\n\n\n절대 나와서는 안되는 조건을 적용하기\n되도록 LLM 이 추론을 할 수 없게 구체적으로 주기\n긍정문을 쓰되 절대 나와서 안되는 문구들은 2중 부정을 사용"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html#대-원칙",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html#대-원칙",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "",
    "text": "범용성: 다양한 상황에서도 동작, 불특정 다수의 사용자 대상 다양한 상황과 과제에 적용 가능한 프롬프트의 결과를 내야 한다.\n\n목적 지향성: 특정 사용자 목적에 세분화된 기능을 제공해야 한다.\n일관성: 여러가지 LLM 모델을 사용하더라도, 생성 할 때마다 결과가 바뀌면 안된다. 어느정도 스펙트럼 안에서 일정한 결과 유지.\n경제성: 단어, 토큰수 운영 비용 API 비용 절감"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html#scaffolding-prompting",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html#scaffolding-prompting",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "",
    "text": "비계식 설계\n인간의 학습 이론(ZPD)을 적용\n외국어를 학습하는 사람들의 학습 능력을 최대한 끌어올리려면, 최대한 쉬운 단계부터 어려운 단계까지 차츰차츰 비계식으로 올라가야 한다.\n단어 -&gt; 문장 -&gt; 문단 완성을 하는 단계별 학습 방식 사용\n프롬프트 설계를 할떄도 이 방식을 사용하면 정말 잘 설계를 할 수 있다.\nUnderstand → Ideation → Analysis → Apply → Evaluate → Generalize\n풀어야될 문제(요구사항)에 대한 이해\n문제에 대한 이해를 바탕으로 여러가지 프롬프트를 만드는 아이디에이션 진행.\n아이디에이션을 통해 구현된 프롬프트를 분석.\n실제로 도입, 적용, 평가\n일반화 할 수 있는 결과를 얻으면 배포 진행.\n단계적 사고구조 유도"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html#핵심-5-tips",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html#핵심-5-tips",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "",
    "text": "최근까지 GPT 4/5\n최신모델을 사용하면 프롬프트가 조금 엉성해도 좋은 결과를 얻을 수 있다.\n그러나 GPT 3.5을 이용해 A 라는 기능을 4/5 만큼 끌어올릴 수 있다면, 이 방법이 좋은 방법이다.\n\n\n\n\n어떤 단어가 좀더 구체적, 또는 명확하게 표현이 되어있는지 확인 조금더 명확한 동작을 하는 단어가 있을 수 있다. 뭐를 나누다 라는 맥락이 없으면 뜻을 정확하게 이해하기가 어려운 언어이다. 예: 분석해, 정리해, 요약해, 작성해 등 –&gt; 정확하게 무엇을 하려고 하는지 맥락 없어도 이해 가능하다.\n\n\n\n구조화라 함은 어떻게 요소별로 나눈다던지 섹션별로 컴포지션을 나누어서, 언어모델이 읽기 편한 구조를 만든다. 대표적으로 2가지 방법(Markdown, 코드 프롬프트)이 있다. 프롬프트를 구조화하면 LLM이 입력을 더 명확하게 해석할 수 있고,\n작업 목적·규칙·입력 데이터·출력 형식을 혼동 없이 처리할 수 있다.\n구조화를 위한 핵심 기법은 Markdown, 코드 프롬프트, XML 태그이다.\n\nMarkdown 기호 사용하기 (Headers, Lists, Emphasis)\n\nMarkdown은 LLM이 가장 잘 해석하는 구조적 문법 중 하나이다.\n섹션을 명확히 나누고, 각 부분을 시각적으로 구분해줌으로써\n모델의 오류를 줄이고 반복 작업 시 유지보수성이 높아진다.\n1.1 헤더(Headers) 활용 헤더는 프롬프트의 구성을 크게 나누는 데 사용한다. 샾 개수만큼 주 제목, 부제목, 소제목 등의 계층적 우선순위 인덱스를 부여할 수 있다.\n# 역할(Role)\n너는 스포츠 기사 분석 엔진이다.\n\n## 작업(Task)\n아래 텍스트에서 장소(도시, 국가, 축구 클럽)를 모두 추출해라.\n\n## 출력 형식(Format)\n- \"장소: A, B, C\" 형태의 한 줄 출력\n- 설명 금지\n\n## 텍스트(Text)\n{{TEXT}}\n1.2 목록(Lists) 활용 하이픈이나, 번호를 이용 –&gt; 수행할 순서가 있는 프롬프트에 사용한다. 절차, 규칙, 조건을 번호 목록으로 정리하면 LLM이 하나씩 적용하기 쉽다.\n다음 규칙을 따라 작업을 수행해라.\n1. 사람 이름은 제외한다.\n2. 축구 클럽은 장소로 포함한다.\n3. 결과는 쉼표로 구분한다.\n4. 설명 문장은 쓰지 않는다.\n1.3 강조(Emphasis) 사용\n중요 조건을 굵게 또는 기울임으로 표시해 모델의 우선순위를 높인다. 실제로 이탤릭, 볼드체로 표현은 되지 않는다. 언어모델에게 일반 줄글의 텍스트가 아닌 다른 요소임을 강조.\n- 반드시 **한국어**로 작성하라.\n- 출력은 **한 줄**로만 작성한다.\n- *설명 문장은 포함하지 않는다.*\n\n코드 프롬프트(Code Prompting)\n\n구조화를 좀더 구체적으로 하는 방식에 대해서 소개. AdaPlanner 논순 발췌, 구글의 리서처 분들이 많이 사용한다. 파이썬 언어를 사용해서 언어 모델이 정확히 수행 해야 하는 내용을 작성. 자연어 대신 코드 형식으로 의도를 명세하면 애매함이 줄어들고 LLM이 구조적으로 이해해 할루시네이션이 감소한다.\n# 역할 정의\nrole = \"정보 추출 엔진\"\n\n# 작업 정의\ntask = \"텍스트에서 '장소명'을 추출해 정렬된 리스트로 반환\"\n\n# 출력 형식 정의\noutput = {\n    \"places\": [\"string\"]\n}\n코드 방식의 장점:\n\n논리 구조가 명확하게 표현됨\n조건과 출력 형식이 혼동되지 않음\n정형화된 포맷을 자주 재사용 가능\n\n\nXML 태그 기반 구조화 (Claude 최적화)\n\n엔트로픽 프롬팅 쿡북 참조하면 나오는 내용. 문장 내 구역 나눔, 해당 구적을 강조하는 효과, 반복작업에서 프롬프트 수정과 편집/용이, 언어모델의 처리 속도 향상 XML 태그는 텍스트 내 특정 영역을 명확히 구분해 Claude뿐 아니라 대부분의 LLM에서 구조적 파싱을 돕는 강력한 방식이다.\n이 방식의 장점은 탬플릿이 가능하다.\n\n태그로 영역 지정\n\n&lt;email&gt;\nShow up at 6AM because I say so.\n&lt;/email&gt;\n\nMake this email more polite.\nLLM은 &lt;email&gt;...&lt;/email&gt; 내부 텍스트만 변환하면 된다는 것을 명확히 인식한다.\n\n데이터 템플릿 예시\n\n&lt;animal&gt;{{ANIMAL}}&lt;/animal&gt;\n입력만 바꿔 여러 데이터를 동일한 템플릿에 적용할 수 있다.\n예:\n&lt;animal&gt;Cow&lt;/animal&gt;\n&lt;animal&gt;Dog&lt;/animal&gt;\n&lt;animal&gt;Seal&lt;/animal&gt;\n장점:\n\n구역별 의미가 명확\n반복 작업에서 수정이 쉽고 안정적\n모델이 태그 단위로 파싱하기 때문에 오류 감소\n\n\n구조화 기법이 필요한 이유\n\n\n명령어, 입력 데이터, 출력 형식을 명확히 구분해 모델의 해석 오류를 줄인다.\n규칙을 시각적으로 구분하여 작업 수행 품질의 일관성과 재현성을 높인다.\n재사용 가능한 템플릿이 되어 프롬프트 제작 비용과 시간 절감에 기여한다.\n\n\n\n\n\n한국어는 짧고 명확하게 작성\n톤·형식·분량을 구체적으로 지시\n\n- 나쁜 예\n5월의 봄을 주제로 시를 써주고 짧게\n작성해줘 봄의 느낌을 살려봐.\n결과: 오월의 푸른 하늘 아래\n새싹이 희망을 노래하네.\n아침 이슬에 빛나는 꽃들,\n봄바람 따라 춤추는 나비.\n모든 거리는 축제가 되어.\n\n- 좋은 예\n너는 시인이야. 한국의 계절, 봄을 상상해봐.\n5월이야. 다양한 꽃이 여기저기 폈어.\n그 분위기에 어울리는 짧은 시를 5줄 이내로\n작성해줘. 한글 고유의 멋이 시에 드러나면 좋겠어.\n결과: 봄바람, 너른 들녘을 스치며\n꽃잎들 춤추듯 흩날리네\n산들산들 부는 바람에\n눈부신 햇살 아래\n은은한 꽃 향기에 취하노라\n\n\n\n\n부정 지시보다 긍정적 행동 지시가 안정적 구체적인 내용을 단문 형식으로 제공함과 언어모델에게 추측을 해야 하는 여지를 주면 안된다.\n\n- 나쁜 예\n다음은 에이전트와 고객의 대화이다.\n고객에게 아이디와 비밀번호를 묻지\n않는다. 반복하지 않는다.\n\n- 좋은 예\n다음은 에이전트와 고객과의 대화내용이다.\n챗봇은 고객의 대화에서 드러난 문제를 진단하고 해결책을\n제시해야 한다. 사용자 아이디와 비밀번호같은 개인정보를\n묻지 않는 대신,\n사용자가 www.samplewebsite.com/help/faq에서 관련\n사항을 찾도록 안내해라."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html#프롬프트-제작에-100-절대적인-것은-없다.",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html#프롬프트-제작에-100-절대적인-것은-없다.",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "",
    "text": "절대 나와서는 안되는 조건을 적용하기\n되도록 LLM 이 추론을 할 수 없게 구체적으로 주기\n긍정문을 쓰되 절대 나와서 안되는 문구들은 2중 부정을 사용"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html#llm-한계",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html#llm-한계",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "2.1 LLM 한계",
    "text": "2.1 LLM 한계\n\n할루시네이션\n편향성\n근거 없는 출처 생성\n수학 및 추론 한계\nPrompt Injection(프롬프트 해킹)"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html#프롬프트-엔지니어링이-필요한-이유",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/02-Prompt-Structure.html#프롬프트-엔지니어링이-필요한-이유",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "2.2 프롬프트 엔지니어링이 필요한 이유",
    "text": "2.2 프롬프트 엔지니어링이 필요한 이유\n\n정확성 향상\n오류 및 편향 감소\n모델 행동 제어\n사용자 경험 개선\n비용 절감"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/04-LongContextReorder.html",
    "href": "docs/blog/posts/RAG/10-Retriever/04-LongContextReorder.html",
    "title": "긴 문맥 재정렬(LongContextReorder)",
    "section": "",
    "text": "모델의 아키텍처와 상관없이, 10개 이상의 검색된 문서를 포함할 경우 성능이 상당히 저하됩니다.\n간단히 말해, 모델이 긴 컨텍스트 중간에 있는 관련 정보에 접근해야 할 때, 제공된 문서를 무시하는 경향이 있습니다.\n자세한 내용은 다음 논문을 참조하세요\n이 문제를 피하기 위해, 검색 후 문서의 순서를 재배열하여 성능 저하를 방지할 수 있습니다."
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/04-LongContextReorder.html#문제의-원인",
    "href": "docs/blog/posts/RAG/10-Retriever/04-LongContextReorder.html#문제의-원인",
    "title": "긴 문맥 재정렬(LongContextReorder)",
    "section": "1 문제의 원인",
    "text": "1 문제의 원인\nLLM 은 두괄식으로 학습이 되어있어서 입력으로 들어온 텍스트에 대해 앞쪽 문서와 뒤쪽 문서를 중요하다고 생각한다. 그러나, Retreval 으로 가져온 결과들은 유사도 기반으로 정렬이 되어있는 문서이기 때문에 그대로 LLM 으로 입력을 했을 때 올바른 결과를 내어주지 못한다.\n\nChroma 벡터 저장소를 사용하여 텍스트 데이터를 저장하고 검색할 수 있는 retriever를 생성합니다.\nretriever의 invoke 메서드를 사용하여 주어진 쿼리에 대해 관련성이 높은 문서를 검색합니다.\n\n\n\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n\n\n\n\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH10-Retriever\")\n\n\n\n\n코드\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_community.document_transformers import LongContextReorder\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_openai import OpenAIEmbeddings\n\n\n# 임베딩을 가져옵니다.\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n\ntexts = [\n    \"이건 그냥 내가 아무렇게나 적어본 글입니다.\",\n    \"사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다.\",\n    \"아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다.\",\n    \"챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다.\",\n    \"챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다.\",\n    \"애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다.\",\n    \"ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다.\",\n    \"비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다.\",\n    \"ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다.\",\n    \"FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다.\",\n]\n\n\n# 검색기를 생성합니다. (K는 10으로 설정합니다)\nretriever = Chroma.from_texts(texts, embedding=embeddings).as_retriever(\n    search_kwargs={\"k\": 10}\n)\n\n\n검색기에 쿼리를 입력하여 검색을 수행합니다.\n\n\n코드\nquery = \"ChatGPT에 대해 무엇을 말해줄 수 있나요?\"\n\n# 관련성 점수에 따라 정렬된 관련 문서를 가져옵니다.\ndocs = retriever.invoke(query)\ndocs\n\n\nLongContextReorder 클래스의 인스턴스인 reordering을 생성합니다.\n\nreordering.transform_documents(docs)를 호출하여 문서 목록 docs를 재정렬합니다.\n\n덜 관련된 문서는 목록의 중간에 위치하고, 더 관련된 문서는 시작과 끝에 위치하도록 재정렬됩니다.\n\n\n\n\n코드\n# 문서를 재정렬합니다\n# 덜 관련된 문서는 목록의 중간에 위치하고 더 관련된 요소는 시작/끝에 위치합니다.\nreordering = LongContextReorder()\nreordered_docs = reordering.transform_documents(docs)\n\n# 4개의 관련 문서가 시작과 끝에 위치하는지 확인합니다.\nreordered_docs"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/04-LongContextReorder.html#context-reordering을-사용하여-질의-응답-체인-생성",
    "href": "docs/blog/posts/RAG/10-Retriever/04-LongContextReorder.html#context-reordering을-사용하여-질의-응답-체인-생성",
    "title": "긴 문맥 재정렬(LongContextReorder)",
    "section": "2 Context Reordering을 사용하여 질의-응답 체인 생성",
    "text": "2 Context Reordering을 사용하여 질의-응답 체인 생성\n\n\n코드\ndef format_docs(docs):\n    return \"\\n\".join([doc.page_content for i, doc in enumerate(docs)])\n\n\n\n\n코드\nprint(format_docs(docs))\n\n\n\n\n코드\ndef format_docs(docs):\n    return \"\\n\".join(\n        [\n            f\"[{i}] {doc.page_content} [source: teddylee777@gmail.com]\"\n            for i, doc in enumerate(docs)\n        ]\n    )\n\n\ndef reorder_documents(docs):\n    # 재정렬\n    reordering = LongContextReorder()\n    reordered_docs = reordering.transform_documents(docs)\n    combined = format_docs(reordered_docs)\n    print(combined)\n    return combined\n\n\n재정렬된 문서를 출력합니다.\n\n\n코드\n# 재정렬된 문서를 출력\n_ = reorder_documents(docs)\n\n\n\n\n코드\nfrom langchain.prompts import ChatPromptTemplate\nfrom operator import itemgetter\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableLambda\n\n# 프롬프트 템플릿\ntemplate = \"\"\"Given this text extracts:\n{context}\n\n-----\nPlease answer the following question:\n{question}\n\nAnswer in the following languages: {language}\n\"\"\"\n\n# 프롬프트 정의\nprompt = ChatPromptTemplate.from_template(template)\n\n# Chain 정의\nchain = (\n    {\n        \"context\": itemgetter(\"question\")\n        | retriever\n        | RunnableLambda(reorder_documents),  # 질문을 기반으로 문맥을 검색합니다.\n        \"question\": itemgetter(\"question\"),  # 질문을 추출합니다.\n        \"language\": itemgetter(\"language\"),  # 답변 언어를 추출합니다.\n    }\n    | prompt  # 프롬프트 템플릿에 값을 전달합니다.\n    | ChatOpenAI(model=\"gpt-4o-mini\")  # 언어 모델에 프롬프트를 전달합니다.\n    | StrOutputParser()  # 모델의 출력을 문자열로 파싱합니다.\n)\n\n\nquestion 에 쿼리를 입력하고 language 에 언어를 입력합니다.\n\n재정렬된 문서의 검색 결과도 확인합니다.\n\n\n\n코드\nanswer = chain.invoke(\n    {\"question\": \"ChatGPT에 대해 무엇을 말해줄 수 있나요?\", \"language\": \"KOREAN\"}\n)\n\n\n답변을 출력합니다.\n\n\n코드\nprint(answer)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/09-TimeWeightedVectorStoreRetriever.html",
    "href": "docs/blog/posts/RAG/10-Retriever/09-TimeWeightedVectorStoreRetriever.html",
    "title": "시간 가중 벡터저장소 리트리버(TimeWeightedVectorStoreRetriever)",
    "section": "",
    "text": "TimeWeightedVectorStoreRetriever 는 의미론적 유사성과 시간에 따른 감쇠를 결합해 사용하는 검색 도구입니다. 이를 통해 문서 또는 데이터의 “신선함” 과 “관련성” 을 모두 고려하여 결과를 제공합니다.\n스코어링 알고리즘은 다음과 같이 구성됩니다\n\\(\\text{semantic\\_similarity} + (1.0 - \\text{decay\\_rate})^{hours\\_passed}\\)\n여기서 semantic_similarity 는 문서 또는 데이터 간의 의미적 유사도를 나타내고, decay_rate 는 시간이 지남에 따라 점수가 얼마나 감소하는지를 나타내는 비율입니다. hours_passed 는 객체가 마지막으로 접근된 후부터 현재까지 경과한 시간(시간 단위)을 의미합니다.\n이 방식의 주요 특징은, 객체가 마지막으로 접근된 시간을 기준으로 하여 “정보의 신선함” 을 평가한다는 점입니다. 즉, 자주 접근되는 객체는 시간이 지나도 높은 점수를 유지하며, 이를 통해 자주 사용되거나 중요하게 여겨지는 정보가 검색 결과 상위에 위치할 가능성이 높아집니다. 이런 방식은 최신성과 관련성을 모두 고려하는 동적인 검색 결과를 제공합니다.\n특히, decay_rate 는 리트리버의 객체가 생성된 이후가 아니라 마지막으로 액세스된 이후 경과된 시간 을 의미합니다. 즉, 자주 액세스하는 객체는 ’최신’으로 유지됩니다.\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH10-Retriever\")"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/09-TimeWeightedVectorStoreRetriever.html#낮은-감쇠율low-decay_rate",
    "href": "docs/blog/posts/RAG/10-Retriever/09-TimeWeightedVectorStoreRetriever.html#낮은-감쇠율low-decay_rate",
    "title": "시간 가중 벡터저장소 리트리버(TimeWeightedVectorStoreRetriever)",
    "section": "1 낮은 감쇠율(low decay_rate)",
    "text": "1 낮은 감쇠율(low decay_rate)\n\ndecay rate 가 낮다는 것은 (여기서는 극단적으로 0에 가깝게 설정할 것입니다) 기억이 더 오래 “기억될” 것임을 의미합니다.\ndecay rate 가 0 이라는 것은 기억이 절대 잊혀지지 않는다는 것을 의미하며, 이는 이 retriever를 vector lookup과 동등하게 만듭니다.\n\nTimeWeightedVectorStoreRetriever를 초기화하며, 벡터 저장소, 감쇠율(decay_rate)을 매우 작은 값으로 설정하고, 검색할 벡터의 개수(k)를 1로 지정합니다.\n\n\n코드\nfrom datetime import datetime, timedelta\n\nimport faiss\nfrom langchain.docstore import InMemoryDocstore\nfrom langchain.retrievers import TimeWeightedVectorStoreRetriever\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_core.documents import Document\nfrom langchain_openai import OpenAIEmbeddings\n\n# 임베딩 모델을 정의합니다.\nembeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n\n# 벡터 저장소를 빈 상태로 초기화합니다.\nembedding_size = 1536\nindex = faiss.IndexFlatL2(embedding_size)\nvectorstore = FAISS(embeddings_model, index, InMemoryDocstore({}), {})\n\n# 시간 가중치가 적용된 벡터 저장소 검색기를 초기화합니다. (여기서는, 낮은 감쇠율을 적용합니다)\nretriever = TimeWeightedVectorStoreRetriever(\n    vectorstore=vectorstore, decay_rate=0.0000000000000000000000001, k=1\n)\n\n\n간단한 예제 데이터를 추가합니다.\n\n\n코드\n# 어제 날짜를 계산합니다.\nyesterday = datetime.now() - timedelta(days=1)\n\nretriever.add_documents(\n    # 문서를 추가하고, metadata에 어제 날짜를 설정합니다.\n    [\n        Document(\n            page_content=\"테디노트 구독해 주세요.\",\n            metadata={\"last_accessed_at\": yesterday},\n        )\n    ]\n)\n\n# 다른 문서를 추가합니다. metadata는 별도로 설정하지 않았습니다.\nretriever.add_documents([Document(page_content=\"테디노트 구독 해주실꺼죠? Please!\")])\n\n\nretriever.invoke() 를 호출하여 검색을 수행합니다.\n\n이는 가장 두드러진(salient) 문서이기 때문입니다.\ndecay_rate 가 0에 가깝기 때문 에 문서는 여전히 최신(recent)으로 간주됩니다.\n\n\n\n코드\n# \"테디노트 구독해 주세요.\" 가 가장 먼저 반환되는 이유는 가장 두드러지기 때문이며\n# 감쇠율이 0에 가깝기 때문에 여전히 최신 상태를 유지하고 있음을 의미합니다.\nretriever.invoke(\"테디노트\")"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/09-TimeWeightedVectorStoreRetriever.html#높음-감쇠율high-decay_rate",
    "href": "docs/blog/posts/RAG/10-Retriever/09-TimeWeightedVectorStoreRetriever.html#높음-감쇠율high-decay_rate",
    "title": "시간 가중 벡터저장소 리트리버(TimeWeightedVectorStoreRetriever)",
    "section": "2 높음 감쇠율(high decay_rate)",
    "text": "2 높음 감쇠율(high decay_rate)\n높은 decay_rate(예: 0.9999…)를 사용하면 recency score가 빠르게 0으로 수렴합니다.\n(만약 이 값을 1로 설정하면 모든 객체의 recency 값이 0이 되어, Vector Lookup 과 동일한 결과를 얻게 됩니다.)\nTimeWeightedVectorStoreRetriever를 사용하여 검색기를 초기화합니다. decay_rate를 0.999로 설정하여 시간에 따른 가중치 감소율을 조정합니다.\n\n\n코드\n# 임베딩 모델을 정의합니다.\nembeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n\n# 벡터 저장소를 빈 상태로 초기화합니다.\nembedding_size = 1536\nindex = faiss.IndexFlatL2(embedding_size)\nvectorstore = FAISS(embeddings_model, index, InMemoryDocstore({}), {})\n\n# 시간 가중치가 적용된 벡터 저장소 검색기를 초기화합니다.\nretriever = TimeWeightedVectorStoreRetriever(\n    vectorstore=vectorstore, decay_rate=0.999, k=1\n)\n\n\n다시 문서를 새롭게 추가합니다.\n\n\n코드\n# 어제 날짜를 계산합니다.\nyesterday = datetime.now() - timedelta(days=1)\n\nretriever.add_documents(\n    # 문서를 추가하고, metadata에 어제 날짜를 설정합니다.\n    [\n        Document(\n            page_content=\"테디노트 구독해 주세요.\",\n            metadata={\"last_accessed_at\": yesterday},\n        )\n    ]\n)\n\n# 다른 문서를 추가합니다. metadata는 별도로 설정하지 않았습니다.\nretriever.add_documents([Document(page_content=\"테디노트 구독 해주실꺼죠? Please!\")])\n\n\nretriever.invoke(\"테디노트\") 를 호출하면 \"\"테디노트 구독 해주실꺼죠? Please!\"\" 가 먼저 반환됩니다. - 이는 retriever가 “테디노트 구독해 주세요.” 와 관련된 문서를 대부분 잊어버렸기 때문입니다.\n\n\n코드\n# 검색 후 결과확인\nretriever.invoke(\"테디노트\")"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/09-TimeWeightedVectorStoreRetriever.html#감쇠율decay_rate-정리",
    "href": "docs/blog/posts/RAG/10-Retriever/09-TimeWeightedVectorStoreRetriever.html#감쇠율decay_rate-정리",
    "title": "시간 가중 벡터저장소 리트리버(TimeWeightedVectorStoreRetriever)",
    "section": "3 감쇠율(decay_rate) 정리",
    "text": "3 감쇠율(decay_rate) 정리\n\ndecay_rate 를 0.000001 로 매우 작게 설정한 경우\n\n감쇠율(즉, 정보를 망각하는 비율)이 매우 낮기 때문에 정보를 거의 잊지 않습니다.\n따라서, 최신 정보이든 오래된 정보든 시간 가중치 차이가 거의 없습니다. 이럴때는 유사도에 더 높은 점수를 주게 됩니다.\n\ndecay_rate 를 0.999 로 1에 가깝게 설정한 경우\n\n감쇠율(즉, 정보를 망각하는 비율)이 매우 높습니다. 따라서, 과거의 정보는 거의다 잊어버립니다.\n따라서, 이러한 경우는 최신 정보에 더 높은 점수를 주게 됩니다."
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/09-TimeWeightedVectorStoreRetriever.html#가상의-시간으로-decay_rate-조정",
    "href": "docs/blog/posts/RAG/10-Retriever/09-TimeWeightedVectorStoreRetriever.html#가상의-시간으로-decay_rate-조정",
    "title": "시간 가중 벡터저장소 리트리버(TimeWeightedVectorStoreRetriever)",
    "section": "4 가상의 시간으로 decay_rate 조정",
    "text": "4 가상의 시간으로 decay_rate 조정\nLangChain의 일부 유틸리티를 사용하면 시간 구성 요소를 모의(mock) 테스트 할 수 있습니다.\n\nmock_now 함수는 LangChain에서 제공하는 유틸리티 함수로, 현재 시간을 모의(mock)하는 데 사용됩니다.\n\n\n\n코드\nimport datetime\n\nfrom langchain.utils import mock_now\n\n# 현재 시간을 특정 시점으로 설정\nmock_now(datetime.datetime(2024, 8, 30, 00, 00))\n\n# 현재 시간 출력\nprint(datetime.datetime.now())\n\n\nmock_now 함수를 사용하여 현재 시간을 변경하면서 검색 결과를 테스트할 수 있습니다.\n\n해당 기능을 활용하여 적절한 decay_rate 를 찾는데 도움을 받을 수 있습니다.\n\n[주의] 만약 너무 오래전의 시간으로 설정하면, decay_rate 계산시 오류가 발생할 수 있습니다.\n\n\n코드\n# 현재 시간을 임의의 시간으로 변경합니다.\nwith mock_now(datetime.datetime(2024, 8, 29, 00, 00)):\n    # 변경된 시점에서 문서를 검색합니다.\n    print(retriever.invoke(\"테디노트\"))"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/08-SelfQueryRetriever.html",
    "href": "docs/blog/posts/RAG/10-Retriever/08-SelfQueryRetriever.html",
    "title": "셀프 쿼리(Self-querying)",
    "section": "",
    "text": "SelfQueryRetriever 는 자체적으로 질문을 생성하고 해결할 수 있는 기능을 갖춘 검색 도구입니다.\n이는 사용자가 제공한 자연어 질의를 바탕으로, query-constructing LLM chain을 사용해 구조화된 질의를 만듭니다. 그 후, 이 구조화된 질의를 기본 벡터 데이터 저장소(VectorStore)에 적용하여 검색을 수행합니다.\n이 과정을 통해, SelfQueryRetriever 는 단순히 사용자의 입력 질의를 저장된 문서의 내용과 의미적으로 비교하는 것을 넘어서, 사용자의 질의에서 문서의 메타데이터에 대한 필터를 추출 하고, 이 필터를 실행하여 관련된 문서를 찾을 수 있습니다.\n[참고]\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH10-Retriever\")"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/08-SelfQueryRetriever.html#샘플-데이터-생성",
    "href": "docs/blog/posts/RAG/10-Retriever/08-SelfQueryRetriever.html#샘플-데이터-생성",
    "title": "셀프 쿼리(Self-querying)",
    "section": "1 샘플 데이터 생성",
    "text": "1 샘플 데이터 생성\n화장품 상품의 설명과 메타데이터를 기반으로 유사도 검색이 가능한 벡터 저장소를 구축합니다.\n\n\n코드\nfrom langchain_chroma import Chroma\nfrom langchain_core.documents import Document\nfrom langchain_openai import OpenAIEmbeddings\n\n# 화장품 상품의 설명과 메타데이터 생성\ndocs = [\n    Document(\n        page_content=\"수분 가득한 히알루론산 세럼으로 피부 속 깊은 곳까지 수분을 공급합니다.\",\n        metadata={\"year\": 2024, \"category\": \"스킨케어\", \"user_rating\": 4.7},\n    ),\n    Document(\n        page_content=\"24시간 지속되는 매트한 피니시의 파운데이션, 모공을 커버하고 자연스러운 피부 표현이 가능합니다.\",\n        metadata={\"year\": 2023, \"category\": \"메이크업\", \"user_rating\": 4.5},\n    ),\n    Document(\n        page_content=\"식물성 성분으로 만든 저자극 클렌징 오일, 메이크업과 노폐물을 부드럽게 제거합니다.\",\n        metadata={\"year\": 2023, \"category\": \"클렌징\", \"user_rating\": 4.8},\n    ),\n    Document(\n        page_content=\"비타민 C 함유 브라이트닝 크림, 칙칙한 피부톤을 환하게 밝혀줍니다.\",\n        metadata={\"year\": 2023, \"category\": \"스킨케어\", \"user_rating\": 4.6},\n    ),\n    Document(\n        page_content=\"롱래스팅 립스틱, 선명한 발색과 촉촉한 사용감으로 하루종일 편안하게 사용 가능합니다.\",\n        metadata={\"year\": 2024, \"category\": \"메이크업\", \"user_rating\": 4.4},\n    ),\n    Document(\n        page_content=\"자외선 차단 기능이 있는 톤업 선크림, SPF50+/PA++++ 높은 자외선 차단 지수로 피부를 보호합니다.\",\n        metadata={\"year\": 2024, \"category\": \"선케어\", \"user_rating\": 4.9},\n    ),\n]\n\n# 벡터 저장소 생성\nvectorstore = Chroma.from_documents(\n    docs, OpenAIEmbeddings(model=\"text-embedding-3-small\")\n)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/08-SelfQueryRetriever.html#selfqueryretriever",
    "href": "docs/blog/posts/RAG/10-Retriever/08-SelfQueryRetriever.html#selfqueryretriever",
    "title": "셀프 쿼리(Self-querying)",
    "section": "2 SelfQueryRetriever",
    "text": "2 SelfQueryRetriever\n이제 retriever를 인스턴스화할 수 있습니다. 이를 위해서는 문서가 지원하는 메타데이터 필드 와 문서 내용에 대한 간단한 설명을 미리 제공 해야 합니다.\nAttributeInfo 클래스를 사용하여 화장품 메타데이터 필드에 대한 정보를 정의합니다.\n\n카테고리(category): 문자열 타입, 화장품의 카테고리를 나타내며 [‘스킨케어’, ‘메이크업’, ‘클렌징’, ‘선케어’] 중 하나의 값을 가집니다.\n연도(year): 정수 타입, 화장품이 출시된 연도를 나타냅니다.\n사용자 평점(user_rating): 실수 타입, 1-5 범위의 사용자 평점을 나타냅니다.\n\n\n\n코드\nfrom langchain.chains.query_constructor.base import AttributeInfo\n\n\n# 메타데이터 필드 정보 생성\nmetadata_field_info = [\n    AttributeInfo(\n        name=\"category\",\n        description=\"The category of the cosmetic product. One of ['스킨케어', '메이크업', '클렌징', '선케어']\",\n        type=\"string\",\n    ),\n    AttributeInfo(\n        name=\"year\",\n        description=\"The year the cosmetic product was released\",\n        type=\"integer\",\n    ),\n    AttributeInfo(\n        name=\"user_rating\",\n        description=\"A user rating for the cosmetic product, ranging from 1 to 5\",\n        type=\"float\",\n    ),\n]\n\n\nSelfQueryRetriever.from_llm() 메서드를 사용하여 retriever 객체를 생성합니다.\n\nllm: 언어 모델\nvectorstore: 벡터 저장소\ndocument_contents: 문서들의 내용 설명\nmetadata_field_info: 메타데이터 필드 정보\n\n\n\n코드\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain_openai import ChatOpenAI\n\n# LLM 정의\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n# SelfQueryRetriever 생성\nretriever = SelfQueryRetriever.from_llm(\n    llm=llm,\n    vectorstore=vectorstore,\n    document_contents=\"Brief summary of a cosmetic product\",\n    metadata_field_info=metadata_field_info,\n)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/08-SelfQueryRetriever.html#query-테스트",
    "href": "docs/blog/posts/RAG/10-Retriever/08-SelfQueryRetriever.html#query-테스트",
    "title": "셀프 쿼리(Self-querying)",
    "section": "3 Query 테스트",
    "text": "3 Query 테스트\n필터를 걸 수 있는 질의를 입력하여 검색을 수행합니다.\n\n\n코드\n# Self-query 검색\nretriever.invoke(\"평점이 4.8 이상인 제품을 추천해주세요\")\n\n\n\n\n코드\n# Self-query 검색\nretriever.invoke(\"2023년에 출시된 상품을 추천해주세요\")\n\n\n\n\n코드\n# Self-query 검색\nretriever.invoke(\"카테고리가 선케어인 상품을 추천해주세요\")\n\n\n복합 필터를 사용하여 검색을 수행할 수 있습니다.\n\n\n코드\n# Self-query 검색\nretriever.invoke(\n    \"카테고리가 메이크업인 상품 중에서 평점이 4.5 이상인 상품을 추천해주세요\"\n)\n\n\nk는 가져올 문서의 수를 의미합니다.\nSelfQueryRetriever를 사용하여 k를 지정할 수도 있습니다. 이는 생성자에 enable_limit=True를 전달하여 수행할 수 있습니다.\n\n\n코드\nretriever = SelfQueryRetriever.from_llm(\n    llm=llm,\n    vectorstore=vectorstore,\n    document_contents=\"Brief summary of a cosmetic product\",\n    metadata_field_info=metadata_field_info,\n    enable_limit=True,  # 검색 결과 제한 기능을 활성화합니다.\n    search_kwargs={\"k\": 2},  # k 의 값을 2로 지정하여 검색 결과를 2개로 제한합니다.\n)\n\n\n2023년도 출시된 상품은 3개가 있지만 “k” 값을 2로 지정하여 2개만 반환하도록 합니다.\n\n\n코드\n# Self-query 검색\nretriever.invoke(\"2023년에 출시된 상품을 추천해주세요\")\n\n\n하지만 코드로 명시적으로 search_kwargs를 지정하지 않고 query 에서 1개, 2개 등의 숫자를 사용하여 검색 결과를 제한할 수 있습니다.\n\n\n코드\nretriever = SelfQueryRetriever.from_llm(\n    llm=llm,\n    vectorstore=vectorstore,\n    document_contents=\"Brief summary of a cosmetic product\",\n    metadata_field_info=metadata_field_info,\n    enable_limit=True,  # 검색 결과 제한 기능을 활성화합니다.\n)\n\n# Self-query 검색\nretriever.invoke(\"2023년에 출시된 상품 1개를 추천해주세요\")\n\n\n\n\n코드\n# Self-query 검색\nretriever.invoke(\"2023년에 출시된 상품 2개를 추천해주세요\")"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/08-SelfQueryRetriever.html#더-깊게-들어가기",
    "href": "docs/blog/posts/RAG/10-Retriever/08-SelfQueryRetriever.html#더-깊게-들어가기",
    "title": "셀프 쿼리(Self-querying)",
    "section": "4 더 깊게 들어가기",
    "text": "4 더 깊게 들어가기\n내부에서 어떤 일이 일어나는지 확인하고 더 많은 사용자 정의 제어를 하기 위해, 우리는 retriever를 처음부터 재구성할 수 있습니다.\n이 과정은 query-construction chain 을 생성하는 것부터 시작합니다.\n\n참고 튜토리얼\n\n\n4.1 query_constructor chain 생성\n구조화된 쿼리를 생성하는 query_constructor chain 을 생성합니다.\nget_query_constructor_prompt 함수를 사용하여 쿼리 생성기 프롬프트를 가져옵니다.\n\n\n코드\nfrom langchain.chains.query_constructor.base import (\n    StructuredQueryOutputParser,\n    get_query_constructor_prompt,\n)\n\n# 문서 내용 설명과 메타데이터 필드 정보를 사용하여 쿼리 생성기 프롬프트를 가져옵니다.\nprompt = get_query_constructor_prompt(\n    \"Brief summary of a cosmetic product\",  # 문서 내용 설명\n    metadata_field_info,  # 메타데이터 필드 정보\n)\n\n# StructuredQueryOutputParser 를 생성\noutput_parser = StructuredQueryOutputParser.from_components()\n\n# query_constructor chain 을 생성\nquery_constructor = prompt | llm | output_parser\n\n\nprompt.format() 메서드를 사용하여 query 매개변수에 “dummy question” 문자열을 전달하고, 그 결과를 출력하여 Prompt 내용을 확인해 보겠습니다.\n\n\n코드\n# prompt 출력\nprint(prompt.format(query=\"dummy question\"))\n\n\nquery_constructor.invoke() 메서드를 호출하여 주어진 쿼리에 대한 처리를 수행합니다.\n\n\n코드\nquery_output = query_constructor.invoke(\n    {\n        # 쿼리 생성기를 호출하여 주어진 질문에 대한 쿼리를 생성합니다.\n        \"query\": \"2023년도에 출시한 상품 중 평점이 4.5 이상인 상품중에서 스킨케어 제품을 추천해주세요\"\n    }\n)\n\n\n생성된 쿼리를 확인해 보겠습니다.\n\n\n코드\n# 쿼리 출력\nquery_output.filter.arguments\n\n\nSelf-query retriever의 핵심 요소는 query constructor입니다. 훌륭한 검색 시스템을 만들기 위해서는 query constructor가 잘 작동하도록 해야 합니다.\n이를 위해서는 프롬프트(Prompt), 프롬프트 내의 예시, 속성 설명 등을 조정 해야 합니다.\n\n\n4.2 구조화된 쿼리 변환기(Structured Query Translator)를 사용하여 구조화된 쿼리로 변환\n다음으로 중요한 요소는 structured query translator입니다.\n이는 일반적인 StructuredQuery 객체를 사용 중인 vector store의 구문에 맞는 메타데이터 필터로 변환하는 역할을 담당합니다.\n\n\n코드\nfrom langchain.retrievers.self_query.chroma import ChromaTranslator\n\nretriever = SelfQueryRetriever(\n    query_constructor=query_constructor,  # 이전에 생성한 query_constructor chain 을 지정\n    vectorstore=vectorstore,  # 벡터 저장소를 지정\n    structured_query_translator=ChromaTranslator(),  # 쿼리 변환기\n)\n\n\nretriever.invoke() 메서드를 사용하여 주어진 질문에 대한 답변을 생성합니다.\n\n\n코드\nretriever.invoke(\n    # 질문\n    \"2023년도에 출시한 상품 중 평점이 4.5 이상인 상품중에서 스킨케어 제품을 추천해주세요\"\n)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/06-MultiQueryRetriever.html",
    "href": "docs/blog/posts/RAG/10-Retriever/06-MultiQueryRetriever.html",
    "title": "MultiQueryRetriever",
    "section": "",
    "text": "거리 기반 벡터 데이터베이스 검색은 고차원 공간에서의 쿼리 임베딩(표현)과 ’거리’를 기준으로 유사한 임베딩을 가진 문서를 찾는 방식입니다. 하지만 쿼리의 세부적인 차이나 임베딩이 데이터의 의미를 제대로 포착하지 못할 경우, 검색 결과가 달라질 수 있습니다. 또한, 이를 수동으로 조정하는 프롬프트 엔지니어링이나 튜닝 작업은 번거로울 수 있습니다.\n이런 문제를 해결하기 위해, MultiQueryRetriever 는 주어진 사용자 입력 쿼리에 대해 다양한 관점에서 여러 쿼리를 자동으로 생성하는 LLM(Language Learning Model)을 활용해 프롬프트 튜닝 과정을 자동화합니다.\n이 방식은 각각의 쿼리에 대해 관련 문서 집합을 검색하고, 모든 쿼리를 아우르는 고유한 문서들의 합집합을 추출해, 잠재적으로 관련된 더 큰 문서 집합을 얻을 수 있게 해줍니다.\n여러 관점에서 동일한 질문을 생성함으로써, MultiQueryRetriever 는 거리 기반 검색의 제한을 일정 부분 극복하고, 더욱 풍부한 검색 결과를 제공할 수 있습니다.\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH10-Retriever\")\n코드\n# 샘플 벡터DB 구축\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\n# 블로그 포스트 로드\nloader = WebBaseLoader(\n    \"https://teddylee777.github.io/openai/openai-assistant-tutorial/\", encoding=\"utf-8\"\n)\n\n# 문서 분할\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\ndocs = loader.load_and_split(text_splitter)\n\n# 임베딩 정의\nopenai_embedding = OpenAIEmbeddings()\n\n# 벡터DB 생성\ndb = FAISS.from_documents(docs, openai_embedding)\n\n# retriever 생성\nretriever = db.as_retriever()\n\n# 문서 검색\nquery = \"OpenAI Assistant API의 Functions 사용법에 대해 알려주세요.\"\nrelevant_docs = retriever.invoke(query)\n\n# 검색된 문서의 개수 출력\nlen(relevant_docs)\n검색된 결과 중 1개 문서의 내용을 출력합니다.\n코드\n# 1번 문서를 출력합니다.\nprint(relevant_docs[1].page_content)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/06-MultiQueryRetriever.html#사용방법",
    "href": "docs/blog/posts/RAG/10-Retriever/06-MultiQueryRetriever.html#사용방법",
    "title": "MultiQueryRetriever",
    "section": "1 사용방법",
    "text": "1 사용방법\nMultiQueryRetriever 에 사용할 LLM을 지정하고 질의 생성에 사용하면, retriever가 나머지 작업을 처리합니다.\n\n\n코드\nfrom langchain.retrievers.multi_query import MultiQueryRetriever\nfrom langchain_openai import ChatOpenAI\n\n\n# ChatOpenAI 언어 모델을 초기화합니다. temperature는 0으로 설정합니다.\nllm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n\nmultiquery_retriever = MultiQueryRetriever.from_llm(  # MultiQueryRetriever를 언어 모델을 사용하여 초기화합니다.\n    # 벡터 데이터베이스의 retriever와 언어 모델을 전달합니다.\n    retriever=db.as_retriever(),\n    llm=llm,\n)\n\n\n아래는 다중 쿼리를 생성하는 중간 과정을 디버깅하기 위하여 실행하는 코드입니다.\n먼저 \"langchain.retrievers.multi_query\" 로거를 가져옵니다.\n이는 logging.getLogger() 함수를 사용하여 수행됩니다. 그 다음, 이 로거의 로그 레벨을 INFO로 설정하여, INFO 레벨 이상의 로그 메시지만 출력되도록 할 수 있습니다.\n\n\n코드\n# 쿼리에 대한 로깅 설정\nimport logging\n\nlogging.basicConfig()\nlogging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n\n\n이 코드는 retriever_from_llm 객체의 invoke 메서드를 사용하여 주어진 question과 관련된 문서를 검색합니다.\n검색된 문서들은 unique_docs라는 변수에 저장되며, 이 변수의 길이를 확인함으로써 검색된 관련 문서의 총 개수를 알 수 있습니다. 이 과정을 통해 사용자의 질문에 대한 관련 정보를 효과적으로 찾아내고 그 양을 파악할 수 있습니다.\n\n\n코드\n# 질문을 정의합니다.\nquestion = \"OpenAI Assistant API의 Functions 사용법에 대해 알려주세요.\"\n# 문서 검색\nrelevant_docs = multiquery_retriever.invoke(question)\n\n# 검색된 고유한 문서의 개수를 반환합니다.\nprint(\n    f\"===============\\n검색된 문서 개수: {len(relevant_docs)}\",\n    end=\"\\n===============\\n\",\n)\n\n# 검색된 문서의 내용을 출력합니다.\nprint(relevant_docs[0].page_content)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/06-MultiQueryRetriever.html#lcel-chain-활용하는-방법",
    "href": "docs/blog/posts/RAG/10-Retriever/06-MultiQueryRetriever.html#lcel-chain-활용하는-방법",
    "title": "MultiQueryRetriever",
    "section": "2 LCEL Chain 활용하는 방법",
    "text": "2 LCEL Chain 활용하는 방법\n\n사용자 정의 프롬프트 정의하고, 정의한 프롬프트와 함께 Chain 을 생성합니다.\nChain 은 사용자의 질문을 입력 받으면 (아래의 예제에서는) 5개의 질문을 생성한 뒤 \"\\n\" 구분자로 구분하여 생성된 5개 질문을 반환합니다.\n\n\n\n코드\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\n# 프롬프트 템플릿을 정의합니다.(5개의 질문을 생성하도록 프롬프트를 작성하였습니다)\nprompt = PromptTemplate.from_template(\n    \"\"\"You are an AI language model assistant. \nYour task is to generate five different versions of the given user question to retrieve relevant documents from a vector database. \nBy generating multiple perspectives on the user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search. \nYour response should be a list of values separated by new lines, eg: `foo\\nbar\\nbaz\\n`\n\n#ORIGINAL QUESTION: \n{question}\n\n#Answer in Korean:\n\"\"\"\n)\n\n# 언어 모델 인스턴스를 생성합니다.\nllm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n\n# LLMChain을 생성합니다.\ncustom_multiquery_chain = (\n    {\"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n)\n\n# 질문을 정의합니다.\nquestion = \"OpenAI Assistant API의 Functions 사용법에 대해 알려주세요.\"\n\n# 체인을 실행하여 생성된 다중 쿼리를 확인합니다.\nmulti_queries = custom_multiquery_chain.invoke(question)\n# 결과를 확인합니다.(5개 질문 생성)\nmulti_queries\n\n\n이전에 생성한 Chain을 MultiQueryRetriever 에 전달하여 retrieve 할 수 있습니다.\n\n\n코드\nmultiquery_retriever = MultiQueryRetriever.from_llm(\n    llm=custom_multiquery_chain, retriever=db.as_retriever()\n)\n\n\nMultiQueryRetriever를 사용하여 문서를 검색하고 결과를 확인합니다.\n\n\n코드\n# 결과\nrelevant_docs = multiquery_retriever.invoke(question)\n\n# 검색된 고유한 문서의 개수를 반환합니다.\nprint(\n    f\"===============\\n검색된 문서 개수: {len(relevant_docs)}\",\n    end=\"\\n===============\\n\",\n)\n\n# 검색된 문서의 내용을 출력합니다.\nprint(relevant_docs[0].page_content)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/03-EnsembleRetriever.html",
    "href": "docs/blog/posts/RAG/10-Retriever/03-EnsembleRetriever.html",
    "title": "앙상블 검색기(Ensemble Retriever)",
    "section": "",
    "text": "EnsembleRetriever는 여러 검색기를 결합하여 더 강력한 검색 결과를 제공하는 LangChain의 기능입니다. 이 검색기는 다양한 검색 알고리즘의 장점을 활용하여 단일 알고리즘보다 더 나은 성능을 달성할 수 있습니다.\n주요 특징 1. 여러 검색기 통합: 다양한 유형의 검색기를 입력으로 받아 결과를 결합합니다. 2. 결과 재순위화: Reciprocal Rank Fusion 알고리즘을 사용하여 결과의 순위를 조정합니다. 3. 하이브리드 검색: 주로 sparse retriever(예: BM25)와 dense retriever(예: 임베딩 유사도)를 결합하여 사용합니다.\n장점 - Sparse retriever: 키워드 기반 검색에 효과적 - Dense retriever: 의미적 유사성 기반 검색에 효과적\n이러한 상호 보완적인 특성으로 인해 EnsembleRetriever는 다양한 검색 시나리오에서 향상된 성능을 제공할 수 있습니다.\n자세한 내용은 LangChain 공식 문서를 참조하세요.\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH10-Retriever\")\n코드\nfrom langchain.retrievers import BM25Retriever, EnsembleRetriever\nfrom langchain.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\n\n# 샘플 문서 리스트\ndoc_list = [\n    \"I like apples\",\n    \"I like apple company\",\n    \"I like apple's iphone\",\n    \"Apple is my favorite company\",\n    \"I like apple's ipad\",\n    \"I like apple's macbook\",\n]\n\n\n# bm25 retriever와 faiss retriever를 초기화합니다.\nbm25_retriever = BM25Retriever.from_texts(\n    doc_list,\n)\nbm25_retriever.k = 1  # BM25Retriever의 검색 결과 개수를 1로 설정합니다.\n\nembedding = OpenAIEmbeddings()  # OpenAI 임베딩을 사용합니다.\nfaiss_vectorstore = FAISS.from_texts(\n    doc_list,\n    embedding,\n)\nfaiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 1})\n\n# 앙상블 retriever를 초기화합니다.\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, faiss_retriever],\n    weights=[0.7, 0.3],\n)\nensemble_retriever 객체의 get_relevant_documents() 메서드를 호출하여 관련성 높은 문서를 검색합니다.\n코드\n# 검색 결과 문서를 가져옵니다.\nquery = \"my favorite fruit is apple\"\nensemble_result = ensemble_retriever.invoke(query)\nbm25_result = bm25_retriever.invoke(query)\nfaiss_result = faiss_retriever.invoke(query)\n\n# 가져온 문서를 출력합니다.\nprint(\"[Ensemble Retriever]\")\nfor doc in ensemble_result:\n    print(f\"Content: {doc.page_content}\")\n    print()\n\nprint(\"[BM25 Retriever]\")\nfor doc in bm25_result:\n    print(f\"Content: {doc.page_content}\")\n    print()\n\nprint(\"[FAISS Retriever]\")\nfor doc in faiss_result:\n    print(f\"Content: {doc.page_content}\")\n    print()\n코드\n# 검색 결과 문서를 가져옵니다.\nquery = \"Apple company makes my favorite iphone\"\nensemble_result = ensemble_retriever.invoke(query)\nbm25_result = bm25_retriever.invoke(query)\nfaiss_result = faiss_retriever.invoke(query)\n\n# 가져온 문서를 출력합니다.\nprint(\"[Ensemble Retriever]\")\nfor doc in ensemble_result:\n    print(f\"Content: {doc.page_content}\")\n    print()\n\nprint(\"[BM25 Retriever]\")\nfor doc in bm25_result:\n    print(f\"Content: {doc.page_content}\")\n    print()\n\nprint(\"[FAISS Retriever]\")\nfor doc in faiss_result:\n    print(f\"Content: {doc.page_content}\")\n    print()"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/03-EnsembleRetriever.html#런타임-config-변경",
    "href": "docs/blog/posts/RAG/10-Retriever/03-EnsembleRetriever.html#런타임-config-변경",
    "title": "앙상블 검색기(Ensemble Retriever)",
    "section": "1 런타임 Config 변경",
    "text": "1 런타임 Config 변경\n런타임에서도 retriever 의 속성을 변경할 수 있습니다. 이는 ConfigurableField 클래스를 사용하여 가능합니다.\n\nweights 매개변수를 ConfigurableField 객체로 정의합니다.\n\n필드의 ID는 “ensemble_weights”로 설정합니다.\n\n\n\n\n코드\nfrom langchain_core.runnables import ConfigurableField\n\n\nensemble_retriever = EnsembleRetriever(\n    # 리트리버 목록을 설정합니다. 여기서는 bm25_retriever와 faiss_retriever를 사용합니다.\n    retrievers=[bm25_retriever, faiss_retriever],\n).configurable_fields(\n    weights=ConfigurableField(\n        # 검색 매개변수의 고유 식별자를 설정합니다.\n        id=\"ensemble_weights\",\n        # 검색 매개변수의 이름을 설정합니다.\n        name=\"Ensemble Weights\",\n        # 검색 매개변수에 대한 설명을 작성합니다.\n        description=\"Ensemble Weights\",\n    )\n)\n\n\n\n검색 시 config 매개변수를 통해 검색 설정을 지정합니다.\n\nensemble_weights 옵션의 가중치를 [1, 0]으로 설정하여 모든 검색 결과의 가중치가 BM25 retriever 에 더 많이 부여 되도록 합니다.\n\n\n\n\n코드\nconfig = {\"configurable\": {\"ensemble_weights\": [1, 0]}}\n\n# config 매개변수를 사용하여 검색 설정을 지정합니다.\ndocs = ensemble_retriever.invoke(\"my favorite fruit is apple\", config=config)\ndocs  # 검색 결과인 docs를 출력합니다.\n\n\n이번에는 검색시 모든 검색 결과의 가중치가 FAISS retriever 에 더 많이 부여 되도록 합니다.\n\n\n코드\nconfig = {\"configurable\": {\"ensemble_weights\": [0, 1]}}\n\n# config 매개변수를 사용하여 검색 설정을 지정합니다.\ndocs = ensemble_retriever.invoke(\"my favorite fruit is apple\", config=config)\ndocs  # 검색 결과인 docs를 출력합니다."
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/03-Agent.html",
    "href": "docs/blog/posts/RAG/15-Agent/03-Agent.html",
    "title": "도구 호출 에이전트(Tool Calling Agent)",
    "section": "",
    "text": "도구 호출을 사용하면 모델이 하나 이상의 도구(tool) 가 호출되어야 하는 시기를 감지하고 해당 도구에 전달해야 하는 입력 으로 전달할 수 있습니다.\nAPI 호출에서 도구를 설명하고 모델이 이러한 도구를 호출하기 위한 인수가 포함된 JSON과 같은 구조화된 객체를 출력하도록 지능적으로 선택할 수 있습니다.\n도구 API 의 목표는 일반 텍스트 완성이나 채팅 API를 사용하여 수행할 수 있는 것보다 더 안정적으로 유효하고 유용한 도구 호출(tool call) 을 반환하는 것입니다.\n이러한 구조화된 출력을 도구 호출 채팅 모델에 여러 도구를 바인딩하고 모델이 호출할 도구를 선택할 수 있다는 사실과 결합하여 쿼리가 해결될 때까지 반복적으로 도구를 호출하고 결과를 수신하는 에이전트를 만들 수 있습니다.\n이것은 OpenAI 의 특정 도구 호출 스타일에 맞게 설계된 OpenAI 도구 에이전트의 보다 일반화된 버전 입니다.\n이 에이전트는 LangChain의 ToolCall 인터페이스를 사용하여 OpenAI 외에도 Anthropic, Google Gemini, Mistral과 같은 더 광범위한 공급자 구현을 지원합니다.\n참고 링크\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install -qU langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH15-Agents\")\n코드\nfrom langchain.tools import tool\nfrom typing import List, Dict, Annotated\nfrom langchain_teddynote.tools import GoogleNews\nfrom langchain_experimental.utilities import PythonREPL\n\n\n# 도구 생성\n@tool\ndef search_news(query: str) -&gt; List[Dict[str, str]]:\n    \"\"\"Search Google News by input keyword\"\"\"\n    news_tool = GoogleNews()\n    return news_tool.search_by_keyword(query, k=5)\n\n\n# 도구 생성\n@tool\ndef python_repl_tool(\n    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n):\n    \"\"\"Use this to execute python code. If you want to see the output of a value,\n    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n    result = \"\"\n    try:\n        result = PythonREPL().run(code)\n    except BaseException as e:\n        print(f\"Failed to execute. Error: {repr(e)}\")\n    finally:\n        return result\n\n\nprint(f\"도구 이름: {search_news.name}\")\nprint(f\"도구 설명: {search_news.description}\")\nprint(f\"도구 이름: {python_repl_tool.name}\")\nprint(f\"도구 설명: {python_repl_tool.description}\")\n코드\n# tools 정의\ntools = [search_news, python_repl_tool]"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/03-Agent.html#agent-프롬프트-생성",
    "href": "docs/blog/posts/RAG/15-Agent/03-Agent.html#agent-프롬프트-생성",
    "title": "도구 호출 에이전트(Tool Calling Agent)",
    "section": "1 Agent 프롬프트 생성",
    "text": "1 Agent 프롬프트 생성\n\nchat_history : 이전 대화 내용을 저장하는 변수 (멀티턴을 지원하지 않는다면, 생략 가능합니다.)\nagent_scratchpad : 에이전트가 임시로 저장하는 변수\ninput : 사용자의 입력\n\n\n\n코드\nfrom langchain_core.prompts import ChatPromptTemplate\n\n# 프롬프트 생성\n# 프롬프트는 에이전트에게 모델이 수행할 작업을 설명하는 텍스트를 제공합니다. (도구의 이름과 역할을 입력)\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You are a helpful assistant. \"\n            \"Make sure to use the `search_news` tool for searching keyword related news.\",\n        ),\n        (\"placeholder\", \"{chat_history}\"),\n        (\"human\", \"{input}\"),\n        (\"placeholder\", \"{agent_scratchpad}\"),\n    ]\n)"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/03-Agent.html#agent-생성",
    "href": "docs/blog/posts/RAG/15-Agent/03-Agent.html#agent-생성",
    "title": "도구 호출 에이전트(Tool Calling Agent)",
    "section": "2 Agent 생성",
    "text": "2 Agent 생성\n\n\n코드\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_tool_calling_agent\n\n# LLM 정의\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n# Agent 생성\nagent = create_tool_calling_agent(llm, tools, prompt)"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/03-Agent.html#agentexecutor",
    "href": "docs/blog/posts/RAG/15-Agent/03-Agent.html#agentexecutor",
    "title": "도구 호출 에이전트(Tool Calling Agent)",
    "section": "3 AgentExecutor",
    "text": "3 AgentExecutor\nAgentExecutor는 도구를 사용하는 에이전트를 실행하는 클래스입니다.\n주요 속성 - agent: 실행 루프의 각 단계에서 계획을 생성하고 행동을 결정하는 에이전트 - tools: 에이전트가 사용할 수 있는 유효한 도구 목록 - return_intermediate_steps: 최종 출력과 함께 에이전트의 중간 단계 경로를 반환할지 여부 - max_iterations: 실행 루프를 종료하기 전 최대 단계 수 - max_execution_time: 실행 루프에 소요될 수 있는 최대 시간 - early_stopping_method: 에이전트가 AgentFinish를 반환하지 않을 때 사용할 조기 종료 방법. (“force” or “generate”) - \"force\" 는 시간 또는 반복 제한에 도달하여 중지되었다는 문자열을 반환합니다. - \"generate\" 는 에이전트의 LLM 체인을 마지막으로 한 번 호출하여 이전 단계에 따라 최종 답변을 생성합니다. - handle_parsing_errors: 에이전트의 출력 파서에서 발생한 오류 처리 방법. (True, False, 또는 오류 처리 함수) - trim_intermediate_steps: 중간 단계를 트리밍하는 방법. (-1 trim 하지 않음, 또는 트리밍 함수)\n주요 메서드 1. invoke: 에이전트 실행 2. stream: 최종 출력에 도달하는 데 필요한 단계를 스트리밍\n주요 기능 1. 도구 검증: 에이전트와 호환되는 도구인지 확인 2. 실행 제어: 최대 반복 횟수 및 실행 시간 제한 설정 가능 3. 오류 처리: 출력 파싱 오류에 대한 다양한 처리 옵션 제공 4. 중간 단계 관리: 중간 단계 트리밍 및 반환 옵션 5. 비동기 지원: 비동기 실행 및 스트리밍 지원\n최적화 팁 - max_iterations와 max_execution_time을 적절히 설정하여 실행 시간 관리 - trim_intermediate_steps를 활용하여 메모리 사용량 최적화 - 복잡한 작업의 경우 stream 메서드를 사용하여 단계별 결과 모니터링\n\n\n코드\nfrom langchain.agents import AgentExecutor\n\n# AgentExecutor 생성\nagent_executor = AgentExecutor(\n    agent=agent,\n    tools=tools,\n    verbose=True,\n    max_iterations=10,\n    max_execution_time=10,\n    handle_parsing_errors=True,\n)\n\n# AgentExecutor 실행\nresult = agent_executor.invoke({\"input\": \"AI 투자와 관련된 뉴스를 검색해 주세요.\"})\n\nprint(\"Agent 실행 결과:\")\nprint(result[\"output\"])"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/03-Agent.html#stream-출력으로-단계별-결과-확인",
    "href": "docs/blog/posts/RAG/15-Agent/03-Agent.html#stream-출력으로-단계별-결과-확인",
    "title": "도구 호출 에이전트(Tool Calling Agent)",
    "section": "4 Stream 출력으로 단계별 결과 확인",
    "text": "4 Stream 출력으로 단계별 결과 확인\nAgentExecutor의 stream() 메소드를 사용하여 에이전트의 중간 단계를 스트리밍할 것입니다.\nstream()의 출력은 (Action, Observation) 쌍 사이에서 번갈아 나타나며, 최종적으로 에이전트가 목표를 달성했다면 답변으로 마무리됩니다.\n다음과 같은 형태로 보일 것입니다.\n\nAction 출력\nObservation 출력\nAction 출력\nObservation 출력\n\n… (목표 달성까지 계속) …\n그 다음, 최종 목표가 달성되면 에이전트는 최종 답변을 출력할 것입니다.\n이러한 출력의 내용은 다음과 같이 요약됩니다.\n\n\n\n\n\n\n\n출력\n내용\n\n\n\n\nAction\nactions: AgentAction 또는 그 하위 클래스messages: 액션 호출에 해당하는 채팅 메시지\n\n\nObservation\nsteps: 현재 액션과 그 관찰을 포함한 에이전트가 지금까지 수행한 작업의 기록messages: 함수 호출 결과(즉, 관찰)를 포함한 채팅 메시지\n\n\nFinal Answer\noutput: AgentFinishmessages: 최종 출력을 포함한 채팅 메시지\n\n\n\n\n::: {#bf7b4031 .cell execution_count=8}\n``` {.python .cell-code}\nfrom langchain.agents import AgentExecutor\n\n# AgentExecutor 생성\nagent_executor = AgentExecutor(\n    agent=agent,\n    tools=tools,\n    verbose=False,\n    handle_parsing_errors=True,\n)\n:::\n\n\n코드\n# 스트리밍 모드로 실행합니다\nresult = agent_executor.stream({\"input\": \"AI 투자와 관련된 뉴스를 검색해 주세요.\"})\n\nfor step in result:\n    # 중간 단계 출력\n    print(step)\n    print(\"===\" * 20)\n\n\n\n4.1 중간 단계 출력을 사용자 정의 함수로 출력\n다음의 3개 함수를 정의하고 이를 통해 중간 단계 출력을 사용자 정의합니다.\n\ntool_callback: 도구 호출 출력을 처리하는 함수\nobservation_callback: 관찰(Observation) 출력을 처리하는 함수\nresult_callback: 최종 답변 출력을 처리하는 함수\n\n\n\n코드\n# 업데이트\n# !pip install -U langchain-teddynote\n\n\n아래는 Agent 의 중간 단계 과정을 깔끔하게 출력하기 위하여 사용되는 콜백 함수입니다.\n이 콜백 함수는 Streamlit 에서 중간 단계를 출력하여 사용자에게 제공할 때 유용할 수 있습니다.\n\n\n코드\nfrom langchain_teddynote.messages import AgentStreamParser\n\nagent_stream_parser = AgentStreamParser()\n\n\n스트리밍 방식으로 Agent 의 응답 과정을 확인합니다.\n\n\n코드\n# 질의에 대한 답변을 스트리밍으로 출력 요청\nresult = agent_executor.stream(\n    {\"input\": \"matplotlib 을 사용하여 pie 차트를 그리는 코드를 작성하고 실행하세요.\"}\n)\n\nfor step in result:\n    # 중간 단계를 parser 를 사용하여 단계별로 출력\n    # print(step)\n    agent_stream_parser.process_agent_steps(step)\n\n\n다음은 callback 을 수정하여 사용하는 방법입니다.\n\n\n코드\n# AgentCallbacks와 AgentStreamParser를 langchain_teddynote.messages에서 가져옵니다.\nfrom langchain_teddynote.messages import AgentCallbacks, AgentStreamParser\n\n\n# 도구 호출 시 실행되는 콜백 함수입니다.\ndef tool_callback(tool) -&gt; None:\n    print(\"&lt;&lt;&lt;&lt;&lt;&lt;&lt; 도구 호출 &gt;&gt;&gt;&gt;&gt;&gt;\")\n    print(f\"Tool: {tool.get('tool')}\")  # 사용된 도구의 이름을 출력합니다.\n    print(\"&lt;&lt;&lt;&lt;&lt;&lt;&lt; 도구 호출 &gt;&gt;&gt;&gt;&gt;&gt;\")\n\n\n# 관찰 결과를 출력하는 콜백 함수입니다.\ndef observation_callback(observation) -&gt; None:\n    print(\"&lt;&lt;&lt;&lt;&lt;&lt;&lt; 관찰 내용 &gt;&gt;&gt;&gt;&gt;&gt;\")\n    print(\n        f\"Observation: {observation.get('observation')[0]}\"\n    )  # 관찰 내용을 출력합니다.\n    print(\"&lt;&lt;&lt;&lt;&lt;&lt;&lt; 관찰 내용 &gt;&gt;&gt;&gt;&gt;&gt;\")\n\n\n# 최종 결과를 출력하는 콜백 함수입니다.\ndef result_callback(result: str) -&gt; None:\n    print(\"&lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt;\")\n    print(result)  # 최종 답변을 출력합니다.\n    print(\"&lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt;\")\n\n\n# AgentCallbacks 객체를 생성하여 각 단계별 콜백 함수를 설정합니다.\nagent_callbacks = AgentCallbacks(\n    tool_callback=tool_callback,\n    observation_callback=observation_callback,\n    result_callback=result_callback,\n)\n\n# AgentStreamParser 객체를 생성하여 에이전트의 실행 과정을 파싱합니다.\nagent_stream_parser = AgentStreamParser(agent_callbacks)\n\n\n아래의 출력 내용을 확인해 보면 중간 내용의 출력 값이 내가 변경한 콜백 함수의 출력 값으로 변경된 것을 확인할 수 있습니다.\n\n\n코드\n# 질의에 대한 답변을 스트리밍으로 출력 요청\nresult = agent_executor.stream({\"input\": \"AI 투자관련 뉴스를 검색해 주세요.\"})\n\nfor step in result:\n    # 중간 단계를 parser 를 사용하여 단계별로 출력\n    agent_stream_parser.process_agent_steps(step)"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/03-Agent.html#이전-대화내용-기억하는-agent",
    "href": "docs/blog/posts/RAG/15-Agent/03-Agent.html#이전-대화내용-기억하는-agent",
    "title": "도구 호출 에이전트(Tool Calling Agent)",
    "section": "5 이전 대화내용 기억하는 Agent",
    "text": "5 이전 대화내용 기억하는 Agent\n이전의 대화내용을 기억하기 위해서는 RunnableWithMessageHistory 를 사용하여 AgentExecutor 를 감싸줍니다.\nRunnableWithMessageHistory 에 대한 자세한 내용은 아래 링크를 참고해 주세요.\n참고 - RunnableWithMessageHistory\n\n\n코드\nfrom langchain_community.chat_message_histories import ChatMessageHistory\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\n\n# session_id 를 저장할 딕셔너리 생성\nstore = {}\n\n\n# session_id 를 기반으로 세션 기록을 가져오는 함수\ndef get_session_history(session_ids):\n    if session_ids not in store:  # session_id 가 store에 없는 경우\n        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n        store[session_ids] = ChatMessageHistory()\n    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n\n\n# 채팅 메시지 기록이 추가된 에이전트를 생성합니다.\nagent_with_chat_history = RunnableWithMessageHistory(\n    agent_executor,\n    # 대화 session_id\n    get_session_history,\n    # 프롬프트의 질문이 입력되는 key: \"input\"\n    input_messages_key=\"input\",\n    # 프롬프트의 메시지가 입력되는 key: \"chat_history\"\n    history_messages_key=\"chat_history\",\n)\n\n\n\n\n코드\n# 질의에 대한 답변을 스트리밍으로 출력 요청\nresponse = agent_with_chat_history.stream(\n    {\"input\": \"안녕? 내 이름은 테디야!\"},\n    # session_id 설정\n    config={\"configurable\": {\"session_id\": \"abc123\"}},\n)\n\n# 출력 확인\nfor step in response:\n    agent_stream_parser.process_agent_steps(step)\n\n\n\n\n코드\n# 질의에 대한 답변을 스트리밍으로 출력 요청\nresponse = agent_with_chat_history.stream(\n    {\"input\": \"내 이름이 뭐라고?\"},\n    # session_id 설정\n    config={\"configurable\": {\"session_id\": \"abc123\"}},\n)\n\n# 출력 확인\nfor step in response:\n    agent_stream_parser.process_agent_steps(step)\n\n\n\n\n코드\n# 질의에 대한 답변을 스트리밍으로 출력 요청\nresponse = agent_with_chat_history.stream(\n    {\n        \"input\": \"내 이메일 주소는 teddy@teddynote.com 이야. 회사 이름은 테디노트 주식회사야.\"\n    },\n    # session_id 설정\n    config={\"configurable\": {\"session_id\": \"abc123\"}},\n)\n\n# 출력 확인\nfor step in response:\n    agent_stream_parser.process_agent_steps(step)\n\n\n\n\n코드\n# 질의에 대한 답변을 스트리밍으로 출력 요청\nresponse = agent_with_chat_history.stream(\n    {\n        \"input\": \"최신 뉴스 5개를 검색해서 이메일의 본문으로 작성해줘. \"\n        \"수신인에는 `셜리 상무님` 그리고, 발신인에는 내 인적정보를 적어줘.\"\n        \"정중한 어조로 작성하고, 메일의 시작과 끝에는 적절한 인사말과 맺음말을 적어줘.\"\n    },\n    # session_id 설정\n    config={\"configurable\": {\"session_id\": \"abc123\"}},\n)\n\n# 출력 확인\nfor step in response:\n    agent_stream_parser.process_agent_steps(step)\n\n\n\n\n코드\n# 질의에 대한 답변을 스트리밍으로 출력 요청\nresponse = agent_with_chat_history.stream(\n    {\n        \"input\": \"내 이름이 뭐야?\"\n    },\n    # session_id 설정\n    config={\"configurable\": {\"session_id\": \"def456\"}},\n)\n\n# 출력 확인\nfor step in response:\n    agent_stream_parser.process_agent_steps(step)"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/05-Iter-Human-In-the-Loop.html",
    "href": "docs/blog/posts/RAG/15-Agent/05-Iter-Human-In-the-Loop.html",
    "title": "Iteration 기능과 사람 개입(Human-in-the-loop)",
    "section": "",
    "text": "iter() 메서드는 에이전트의 실행 과정을 단계별로 반복할 수 있게 해주는 반복자(iterator)를 생성합니다.\n중간 과정에서 사용자의 입력을 받아 계속 진행할지 묻는 기능을 제공합니다. 이를 Human-in-the-loop 라고 합니다.\n\n\n코드\n# API KEY를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API KEY 정보로드\nload_dotenv()\n\n\n\n\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install -qU langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH15-Agents\")\n\n\n먼저, 도구(tool) 를 정의합니다.\n\n\n코드\nfrom langchain.agents import tool\n\n\n@tool\ndef add_function(a: float, b: float) -&gt; float:\n    \"\"\"Adds two numbers together.\"\"\"\n    return a + b\n\n\n다음으로는 add_function 을 사용하여 덧셈 계산을 수행하는 Agent 를 정의합니다.\n\n\n코드\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_tool_calling_agent, AgentExecutor\n\n# 도구 정의\ntools = [add_function]\n\n# LLM 생성\ngpt = ChatOpenAI(model=\"gpt-4o-mini\")\n\n# prompt 생성\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You are a helpful assistant.\",\n        ),\n        (\"human\", \"{input}\"),\n        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n    ]\n)\n\n# Agent 생성\ngpt_agent = create_tool_calling_agent(gpt, tools, prompt)\n\n# AgentExecutor 생성\nagent_executor = AgentExecutor(\n    agent=gpt_agent,\n    tools=tools,\n    verbose=False,\n    max_iterations=10,\n    handle_parsing_errors=True,\n)\n\n\n\n0.1 AgentExecutor의 iter()\n이 메서드는 AgentExecutor의 실행 과정을 단계별로 반복할 수 있게 해주는 반복자(iterator)를 생성합니다.\n함수 설명 iter() 는 에이전트가 최종 출력에 도달하기까지 거치는 단계들을 순차적으로 접근할 수 있는 AgentExecutorIterator 객체를 반환합니다.\n주요 기능 - 단계별 실행 접근: 에이전트의 실행 과정을 단계별로 살펴볼 수 있습니다.\n흐름 정리\n\"114.5 + 121.2 + 34.2 + 110.1\" 의 덧셈 계산을 수행하기 위해서는 단계별로 계산이 수행되게 됩니다.\n\n114.5 + 121.2 = 235.7\n235.7 + 34.2 = 270.9\n270.9 + 110.1 = 381.0\n\n이러한 계산 과정을 단계별로 살펴볼 수 있습니다.\n이때,\n단계별로 계산 결과를 사용자에게 보여주고, 사용자가 계속 진행할지 묻습니다. (Human-in-the-loop)\n사용자가 ’y’가 아닌 다른 입력을 하면 반복 중단됩니다.\n\n\n코드\n# 계산할 질문 설정\nquestion = \"114.5 + 121.2 + 34.2 + 110.1 의 계산 결과는?\"\n\n# agent_executor를 반복적으로 실행\nfor step in agent_executor.iter({\"input\": question}):\n    if output := step.get(\"intermediate_step\"):\n        action, value = output[0]\n        if action.tool == \"add_function\":\n            # Tool 실행 결과 출력\n            print(f\"\\nTool Name: {action.tool}, 실행 결과: {value}\")\n        # 사용자에게 계속 진행할지 묻습니다.\n        _continue = input(\"계속 진행하시겠습니다? (y/n)?:\\n\") or \"Y\"\n        # 사용자가 'y'가 아닌 다른 입력을 하면 반복 중단\n        if _continue.lower() != \"y\":\n            break\n\n# 최종 결과 출력\nif \"output\" in step:\n    print(step[\"output\"])"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/04-Agent-More-LLMs.html",
    "href": "docs/blog/posts/RAG/15-Agent/04-Agent-More-LLMs.html",
    "title": "OpenAI 외 도구 호출 에이전트(Tool Calling Agent)",
    "section": "",
    "text": "OpenAI 외에도 Anthropic, Google Gemini, Together.ai, Ollama, Mistral과 같은 더 광범위한 공급자 구현을 지원합니다.\n이번 챕터에서는 다양한 LLM 을 사용하여 도구 호출 에이전트를 생성하고 실행하는 방법을 살펴보겠습니다.\n참고 링크\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install -qU langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH15-Agents\")\n코드\nfrom langchain.tools import tool\nfrom typing import List, Dict\nfrom langchain_teddynote.tools import GoogleNews\n\n\n# 도구 정의\n@tool\ndef search_news(query: str) -&gt; List[Dict[str, str]]:\n    \"\"\"Search Google News by input keyword\"\"\"\n    news_tool = GoogleNews()\n    return news_tool.search_by_keyword(query, k=5)\n\n\nprint(f\"도구 이름: {search_news.name}\")\nprint(f\"도구 설명: {search_news.description}\")\n코드\n# tools 정의\ntools = [search_news]"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/04-Agent-More-LLMs.html#agent-용-프롬프트-생성",
    "href": "docs/blog/posts/RAG/15-Agent/04-Agent-More-LLMs.html#agent-용-프롬프트-생성",
    "title": "OpenAI 외 도구 호출 에이전트(Tool Calling Agent)",
    "section": "1 Agent 용 프롬프트 생성",
    "text": "1 Agent 용 프롬프트 생성\n\nchat_history : 이전 대화 내용을 저장하는 변수 (멀티턴을 지원하지 않는다면, 생략 가능합니다.)\nagent_scratchpad : 에이전트가 임시로 저장하는 변수\ninput : 사용자의 입력\n\n\n\n코드\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.agents import create_tool_calling_agent\n\n# 프롬프트 생성\n# 프롬프트는 에이전트에게 모델이 수행할 작업을 설명하는 텍스트를 제공합니다. (도구의 이름과 역할을 입력)\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You are a helpful assistant. \"\n            \"Make sure to use the `search_news` tool for searching keyword related news.\",\n        ),\n        (\"placeholder\", \"{chat_history}\"),\n        (\"human\", \"{input}\"),\n        (\"placeholder\", \"{agent_scratchpad}\"),\n    ]\n)"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/04-Agent-More-LLMs.html#tool-calling-을-지원하는-다양한-llm-목록",
    "href": "docs/blog/posts/RAG/15-Agent/04-Agent-More-LLMs.html#tool-calling-을-지원하는-다양한-llm-목록",
    "title": "OpenAI 외 도구 호출 에이전트(Tool Calling Agent)",
    "section": "2 Tool Calling 을 지원하는 다양한 LLM 목록",
    "text": "2 Tool Calling 을 지원하는 다양한 LLM 목록\n실습 진행을 위해서는 아래 내용을 설정해야 합니다.\nAnthropic\n\nAnthropic API 키 발급 관련\n.env 파일 내 ANTHROPIC_API_KEY 에 발급받은 키를 설정하세요\n\nGemini\n\nGemini API 키 발급 관련\n.env 파일 내 GOOGLE_API_KEY 에 발급받은 키를 설정하세요\n\nTogether AI\n\nTogether AI API 키 발급 관련\n.env 파일 내 TOGETHER_API_KEY 에 발급받은 키를 설정하세요\n\nOllama\n\nOllama Tool Calling 지원 모델 리스트\n이번 실습에 사용할 llama3.1 모델\n터미널 창에 ollama pull llama3.1 명령어를 입력하여 모델을 다운로드 받습니다.\n이전에 Ollama 를 사용하지 않았다면, Ollama 를 참고해 주세요.\n\nlangchain-ollama 설치를 한 뒤 진행해 주세요.\n\n\n코드\n# !pip install -qU langchain-ollama==0.1.3\n\n\n\n\n코드\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_openai import ChatOpenAI\nfrom langchain_ollama import ChatOllama\nimport os\n\n# GPT-4o-mini\ngpt = ChatOpenAI(model=\"gpt-4o-mini\")\n\n# Claude-3-5-sonnet\nclaude = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0)\n\n# Gemini-1.5-pro-latest\ngemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n\n# Llama-3.1-70B-Instruct-Turbo\nllama = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n)\n\n# Llama-3.1\nollama = ChatOllama(model=\"llama3.1\", temperature=0)\n\n# Qwen2.5 7B (한글 성능 괜찮은 편)\nqwen = ChatOllama(\n    model=\"qwen2.5:latest\",\n)\n\n\nLLM 기반으로 Agent 를 생성합니다.\n\n\n코드\nfrom langchain.agents import create_tool_calling_agent\n\n# Agent 생성\ngpt_agent = create_tool_calling_agent(gpt, tools, prompt)\nclaude_agent = create_tool_calling_agent(claude, tools, prompt)\ngemini_agent = create_tool_calling_agent(gemini, tools, prompt)\nllama_agent = create_tool_calling_agent(llama, tools, prompt)\nollama_agent = create_tool_calling_agent(ollama, tools, prompt)\nqwen_agent = create_tool_calling_agent(qwen, tools, prompt)"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/04-Agent-More-LLMs.html#agentexecutor-생성-후-실행-및-결과-확인",
    "href": "docs/blog/posts/RAG/15-Agent/04-Agent-More-LLMs.html#agentexecutor-생성-후-실행-및-결과-확인",
    "title": "OpenAI 외 도구 호출 에이전트(Tool Calling Agent)",
    "section": "3 AgentExecutor 생성 후 실행 및 결과 확인",
    "text": "3 AgentExecutor 생성 후 실행 및 결과 확인\n\n\n코드\nfrom langchain.agents import AgentExecutor\n\n# gpt_agent 실행\nagent_executor = AgentExecutor(\n    agent=gpt_agent,\n    tools=tools,\n    verbose=True,\n    handle_parsing_errors=True,\n)\n\nresult = agent_executor.invoke({\"input\": \"AI 투자와 관련된 뉴스를 검색해 주세요.\"})\n\nprint(\"Agent 실행 결과:\")\nprint(result[\"output\"])\n\n\n다양한 llm을 사용하여 에이전트를 실행합니다.\n다음은 입력받은 llm을 사용하여 Agent 를 생성하고 실행하여 결과를 출력하는 함수입니다.\n\n\n코드\ndef execute_agent(llm, tools, input_text, label):\n    agent = create_tool_calling_agent(llm, tools, prompt)\n    executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n    result = executor.invoke({\"input\": input_text})\n    print(f\"[{label}] 결과입니다.\")\n    if isinstance(result[\"output\"], list) and len(result[\"output\"]) &gt; 0:\n        for item in result[\"output\"]:\n            if \"text\" in item:\n                print(item[\"text\"])\n    elif isinstance(result[\"output\"], str):\n        print(result[\"output\"])\n    else:\n        print(result[\"output\"])\n\n\n각 llm 별로 에이전트를 생성하고 실행하여 결과를 출력합니다.\n\n\n코드\nquery = (\n    \"AI 투자와 관련된 뉴스를 검색하고, 결과를 Instagram 게시글 형식으로 작성해 주세요.\"\n)\n\n\n\n\n코드\n# gpt\nexecute_agent(gpt, tools, query, \"gpt\")\n\n\n\n\n코드\n# claude\nexecute_agent(claude, tools, query, \"claude\")\n\n\n\n\n코드\n# gemini\nexecute_agent(gemini, tools, query, \"gemini\")\n\n\n\n\n코드\n# llama3.1 70B (Together.ai)\nexecute_agent(\n    llama,\n    tools,\n    \"Search AI related news and write it in Instagram post format\",\n    \"llama3.1 70B\",\n)\n\n\n\n\n코드\n# llama3.1 8B (ollama)\nexecute_agent(ollama, tools, query, \"llama3.1(Ollama)\")\n\n\n\n\n코드\n# qwen2.5 7B (ollama)\nquery = \"AI 투자와 관련된 뉴스를 검색하고, 결과를 Instagram 게시글 형식으로 작성해 주세요. 한글로 답변하세요!\"\n\nexecute_agent(qwen, tools, query, \"qwen2.5(Ollama)\")"
  },
  {
    "objectID": "docs/blog/posts/Azure_Cloud/01-클라우드 인프라 설정/01-Data_Lake_Storage.html",
    "href": "docs/blog/posts/Azure_Cloud/01-클라우드 인프라 설정/01-Data_Lake_Storage.html",
    "title": "01-Data Lake Storage",
    "section": "",
    "text": "Azure Portal에서 Storage Account를 생성합니다.\n\n\n\n\n\n\n\nimage\n\n\n구독(Subscription) - 설명: 사용할 Azure 구독을 선택합니다. - 입력 값: swlab-test-subs\n리소스 그룹(Resource Group) - 설명: 스토리지 계정을 포함할 리소스 그룹을 선택하거나 새로 만듭니다. - 입력 값: rg-aipoc-test-krc-001\n\n\n\n스토리지 계정 이름 - 설명: 전역적으로 고유한 스토리지 계정 이름을 입력합니다 (3-24자, 소문자와 숫자만 사용 가능). - 입력 값: saaipoctestkrc001\n지역(Region) - 설명: 스토리지 계정이 생성될 Azure 데이터 센터 위치를 선택합니다. - 입력 값: (Asia Pacific) Korea Central\n기본 스토리지 유형 - 설명: 사용할 스토리지 서비스 유형을 선택합니다. - 입력 값: Azure Blob Storage 또는 Azure Data Lake Storage Gen 2 - 참고: 관련 지침을 제공하는 데 도움이 됩니다. 스토리지를 이 리스크 유형으로 제한하지 않습니다.\n기본 워크로드 - 설명: 빅 데이터 분석을 위해 데이터 레이크를 호스트하는 데 가장 적합한 워크로드와 가장 일치하는 항목을 선택하여 모범 사례를 기반으로 구축된 권장 구성을 가져옵니다. 안제든지 이 구성을 변경할 수 있습니다. - 입력 값: 빅 데이터 분석 - 참고: 📊 빅 데이터 분석을 위해 데이터 레이크를 호스트하는 데 가장 적합\n성능(Performance) - 설명: 스토리지 계정의 성능 계층을 선택합니다. - 표준: 대부분 시나리오에 권장됨 (범용 v2 계정) - 프리미엄: 짧은 대기 시간이 필요한 경우에 권장됨 - 선택 값: 표준: 대부분 시나리오에 권장됨(범용 v2 계정) - 참고: 📊 표준 성능 워크로드에는 빅 데이터 분석(를) 사용하는 것이 좋습니다.\n중복도(Redundancy) - 설명: 데이터 내구성을 위한 복제 전략을 선택합니다. - LRS: 로컬 중복 스토리지 - ZRS: 영역 중복 스토리지 - GRS: 지역 중복 스토리지 - RA-GRS: 읽기 액세스 지역 중복 스토리지 - 선택 값: LRS(로컬 중복 스토리지) - 참고: 📊 ZRS 워크로드에는 빅 데이터 분석(를) 사용하는 것이 좋습니다.\n\n\n\n\n\n\n\nimage\n\n\n\n\nREST API 작업을 위한 보안 전송 필요 - 설명: HTTPS를 통한 보안 연결만 허용합니다. - 선택 값: ☑ 체크됨\n개별 컨테이너에 대한 익명 액세스 허용 - 설명: 익명 Blob 액세스를 컨테이너 수준에서 허용할지 여부를 설정합니다. - 선택 값: ☐ 체크 안 됨\n스토리지 계정 키 액세스 사용 - 설명: 공유 키를 통한 스토리지 계정 액세스를 허용합니다. - 선택 값: ☑ 체크됨\nAzure Portal에서 Microsoft Entra 인증 기본값 사용 - 설명: Azure Portal 액세스 시 Microsoft Entra ID를 기본 인증 방법으로 사용합니다. - 선택 값: ☐ 체크 안 됨\n최소 TLS 버전 - 설명: 클라이언트에서 요청하는 최소 TLS(전송 계층 보안) 버전을 설정합니다. - 선택 값: 버전 1.2\n복사 작업에 대해 허용된 범위(미리 보기) - 설명: 데이터 복사 작업의 허용 범위를 지정합니다. - 선택 값: 모든 스토리지 계정에서\n\n\n\nData Lake Storage Gen2 엔드포인트로 보안되는 계층 구조 네임스페이스는 파일 및 디렉터리 의미 체계를 사용하고, 빅 데이터 분석 워크로드를 가속화하고, ACL(액세스 제어 목록)을 사용합니다.\n계층 구조 네임스페이스 사용 - 설명: Data Lake Storage Gen2 엔드포인트를 보안되는 계층 구조 네임스페이스입니다. 파일 및 디렉터리 의미 체계를 사용하고, ACL(액세스 제어 목록)을 사용합니다. - 선택 값: ☑ 체크됨 - 참고: 📊 계층 구조 네임스페이스 워크로드에는 빅 데이터 분석(를) 사용하는 것이 좋습니다.\n\n\n\nBLOB 및 Data Lake Gen2 엔드포인트는 기본적으로 프로토비전됨\nSFTP 사용 - 설명: SFTP 프로토콜을 통한 파일 전송을 활성화합니다. - 선택 값: ☑ 체크됨 - 참고: ℹ️ 로컬 사용자 기능은 SFTP로 활성화됩니다. 스토리지 계정을 만든 후 SFTP 끝점에 액세스할 로컬 사용자 ID를 만듭니다.\n네트워크 파일 시스템 v3 사용 - 설명: NFS v3 프로토콜을 사용하여 파일 시스템을 마운트합니다. - 선택 값: ☑ 체크됨\n\n\n\n테넌트 간 복제 허용 - 설명: 다른 Azure AD 테넌트 간 Blob 복제를 허용합니다. - 선택 값: ☐ 체크 안 됨 - 참고: ℹ️ 테넌트 간 복제 및 계층 구조 네임스페이스를 동시에 사용하도록 설정할 수 없습니다.\n액세스 계층 - 설명: 데이터 액세스 빈도에 따른 기본 저장소 계층을 선택합니다. - 핫: 자주 액세스하는 데이터 및 일상적인 사용 시나리오에 최적화됨 - 쿨: 자주 액세스하지 않는 데이터 및 백업 시나리오에 최적화됨 - 콜드: 거의 액세스하지 않는 데이터 및 백업 시나리오에 최적화됨 - 선택 값: 핫 - 참고: 📊 핫 Blob 액세스 계층 워크로드에는 빅 데이터 분석(를) 사용하는 것이 좋습니다.\n\n\n\n큰 파일 공유 사용 - 설명: 최대 100TiB 용량의 대용량 파일 공유를 지원합니다. - 선택 값: ☑ 체크됨 (비활성화됨)\n\n\n\n\n\n\n\nimage\n\n\n\n\n공용 네트워크를 통해 어디서나 리소스에 액세스합니다.\n참고: 공용 네트워크를 통해 리소스에 액세스할 수 있게 되면 보안 위험이 증가합니다.\n공용 네트워크 액세스 - 설명: 공용 인터넷에서 스토리지 계정에 대한 액세스 권한을 설정합니다. - 선택 값: 사용 - 이 리소스에 대한 리스크 액세스 구성을 사용하여 선택 인바운드 엔드포인트를 제한하는 옵션을 사용하며 인바운드 및 아웃바운드 엔드포인트를 허용합니다. - 옵션: - ⭕ 사용: 이 리소스에 대한 리스크 액세스 구성을 사용하여 선택 인바운드 엔드포인트를 제한하는 옵션을 사용하며 인바운드 및 아웃바운드 엔드포인트를 허용합니다. - ⚪ 사용 안 함: 아웃바운드 엔드포인트를 허용하면서 인바운드 엔드포인트를 제한합니다. - ⚪ 경계로 보호(가장 제한됨): 네트워크 보안 경계를 사용하여 인바운드 및 아웃바운드 엔드포인트를 제한합니다. 경계로 보호는 리소스를 보호하기 위해 가장 높은 수준의 인바운드 및 아웃바운드 제한을 제공합니다.\n공용 네트워크 액세스 범위 - 설명: 공용 네트워크를 통해 액세스할 수 있는 리소스의 범위를 지정합니다. - 선택 값: 선택한 가상 네트워크 및 IP 주소에서 사용 - 옵션: - ⚪ 모든 네트워크에서 사용 - ⭕ 선택한 가상 네트워크 및 IP 주소에서 사용\n\n\n\n선택한 네트워크만 이 스토리지 계정에 액세스할 수 있습니다.\n가상 네트워크 구독 - 설명: 가상 네트워크가 속한 Azure 구독을 선택합니다. - 입력 값: swlab-test-subs\n가상 네트워크 - 설명: 스토리지 계정에 액세스할 수 있는 가상 네트워크를 선택합니다. - 입력 값: vnet-aipoc-test-krc-insilico-001 - 링크: [가상 네트워크 만들기] / [선택한 가상 네트워크 관리]\n서브넷 - 설명: 가상 네트워크 내에서 액세스를 허용할 서브넷을 선택합니다. - 입력 값: subnet-aipoc-test-krc-insilico-001(172.16.0.0/24)\n\n\n\nAllow select public internet IP addresses to access your resource.\n허용된 IP 주소 - 설명: 스토리지 계정에 액세스할 수 있는 공용 IP 주소를 지정합니다. - 입력 값: 61.74.175.54\n\n\n\n\n\n\n경고⚠️ 중요\n\n\n\n이 값을 자신의 로컬 PC Public IP로 설정을 해 주어야지만, 추후 Azure Portal을 통해 파일 업로드가 가능합니다.\n\n\n\n\n\n프라이빗 엔드포인트 - 설명: 프라이빗 엔드포인트를 만들어 이 리소스에 대한 프라이빗 연결을 허용합니다. 추가 프라이빗 엔드포인트 연결은 스토리지 계정 또는 프라이빗 링크 센터 내에서 만들 수 있습니다. - 선택 값: [+ 프라이빗 엔드포인트 추가] 클릭 가능 - 상태: 프라이빗 엔드포인트를 만들려면 (추가를 클릭합니다)\n\n\n\n트래픽이 원본에서 Azure 엔드포인트로 이동하는 과정에서 트래픽을 라우팅할 방법을 결정하세요. 대부분의 고객의 경우 Microsoft 네트워크 라우팅이 권장됩니다.\n라우팅 기본 설정 - 설명: 트래픽이 원본에서 Azure 엔드포인트로 이동하는 과정에서 트래픽을 라우팅할 방법을 결정합니다. - 선택 값: Microsoft 네트워크 라우팅 - 옵션: - ⭕ Microsoft 네트워크 라우팅 - ⚪ 인터넷 라우팅\n\n\n\n\n\n\n\nimage\n\n\n\n\n\n전부 디폴트 설정으로 진행\n\nBlob에 일시 삭제 사용 - 설명: 일시 삭제를 사용하면 덮어쓴 Blob을 포함하여 이전에 삭제로 표시되었던 Blob을 복구할 수 있습니다. - 선택 값: ☑ 체크됨 - 삭제된 Blob 보존 기간(일): 7\n컨테이너에 일시 삭제 사용 - 설명: 일시 삭제를 사용하면 이전에 삭제로 표시된 컨테이너를 복구할 수 있습니다. - 선택 값: ☑ 체크됨 - 삭제된 컨테이너 보존 기간(일): 7 - 참고: 자주 덮어쓰는 데이터에 대해 일시 삭제를 사용하도록 설정하면 스토리지 비용이 증가할 수 있습니다.\n파일 공유에 일시 삭제 사용 - 설명: 일시 삭제를 사용하면 이전에 삭제로 표시된 파일 공유를 복구할 수 있습니다. - 선택 값: ☑ 체크됨 - 삭제된 파일 공유 보존 기간(일): 7\n\n\n\nBlob에 버전 관리 사용 - 설명: 버전 관리를 사용하여 Blob의 이전 버전을 자동으로 유지합니다. - 선택 값: ☐ 체크 안 됨 - 참고: 워크로드, 생성된 버전 수에 미치는 영향, 결과 비용을 고려하세요. 데이터 수명 주기를 자동으로 관리하여 비용을 최적화합니다.\nBlob 변경 피드 사용 - 설명: 계정의 Blob에 대한 만들기, 수정 및 삭제 변경 내용을 추적합니다. - 선택 값: ☐ 체크 안 됨\n\n\n\n버전 수준 불변성 지원 사용 - 설명: 모든 Blob 버전에 적용할 계정 수준에서 시간 기반 보존 정책을 설정할 수 있습니다. - 선택 값: ☐ 체크 안 됨 - 참고: 계정 수준에서 기본 정책을 설정하려면 이 기능을 사용하여 도록 설정합니다. 이 기능을 사용하지 않고도 컨테이너 수준에서 기본 정책을 설정하거나 특정 Blob 버전에 대한 정책을 설정할 수 있습니다. 이 속성을 사용하려면 버전 관리를 필요합니다."
  },
  {
    "objectID": "docs/blog/posts/Azure_Cloud/01-클라우드 인프라 설정/01-Data_Lake_Storage.html#기본-설정",
    "href": "docs/blog/posts/Azure_Cloud/01-클라우드 인프라 설정/01-Data_Lake_Storage.html#기본-설정",
    "title": "01-Data Lake Storage",
    "section": "",
    "text": "image\n\n\n구독(Subscription) - 설명: 사용할 Azure 구독을 선택합니다. - 입력 값: swlab-test-subs\n리소스 그룹(Resource Group) - 설명: 스토리지 계정을 포함할 리소스 그룹을 선택하거나 새로 만듭니다. - 입력 값: rg-aipoc-test-krc-001\n\n\n\n스토리지 계정 이름 - 설명: 전역적으로 고유한 스토리지 계정 이름을 입력합니다 (3-24자, 소문자와 숫자만 사용 가능). - 입력 값: saaipoctestkrc001\n지역(Region) - 설명: 스토리지 계정이 생성될 Azure 데이터 센터 위치를 선택합니다. - 입력 값: (Asia Pacific) Korea Central\n기본 스토리지 유형 - 설명: 사용할 스토리지 서비스 유형을 선택합니다. - 입력 값: Azure Blob Storage 또는 Azure Data Lake Storage Gen 2 - 참고: 관련 지침을 제공하는 데 도움이 됩니다. 스토리지를 이 리스크 유형으로 제한하지 않습니다.\n기본 워크로드 - 설명: 빅 데이터 분석을 위해 데이터 레이크를 호스트하는 데 가장 적합한 워크로드와 가장 일치하는 항목을 선택하여 모범 사례를 기반으로 구축된 권장 구성을 가져옵니다. 안제든지 이 구성을 변경할 수 있습니다. - 입력 값: 빅 데이터 분석 - 참고: 📊 빅 데이터 분석을 위해 데이터 레이크를 호스트하는 데 가장 적합\n성능(Performance) - 설명: 스토리지 계정의 성능 계층을 선택합니다. - 표준: 대부분 시나리오에 권장됨 (범용 v2 계정) - 프리미엄: 짧은 대기 시간이 필요한 경우에 권장됨 - 선택 값: 표준: 대부분 시나리오에 권장됨(범용 v2 계정) - 참고: 📊 표준 성능 워크로드에는 빅 데이터 분석(를) 사용하는 것이 좋습니다.\n중복도(Redundancy) - 설명: 데이터 내구성을 위한 복제 전략을 선택합니다. - LRS: 로컬 중복 스토리지 - ZRS: 영역 중복 스토리지 - GRS: 지역 중복 스토리지 - RA-GRS: 읽기 액세스 지역 중복 스토리지 - 선택 값: LRS(로컬 중복 스토리지) - 참고: 📊 ZRS 워크로드에는 빅 데이터 분석(를) 사용하는 것이 좋습니다."
  },
  {
    "objectID": "docs/blog/posts/Azure_Cloud/01-클라우드 인프라 설정/01-Data_Lake_Storage.html#고급-설정",
    "href": "docs/blog/posts/Azure_Cloud/01-클라우드 인프라 설정/01-Data_Lake_Storage.html#고급-설정",
    "title": "01-Data Lake Storage",
    "section": "",
    "text": "image\n\n\n\n\nREST API 작업을 위한 보안 전송 필요 - 설명: HTTPS를 통한 보안 연결만 허용합니다. - 선택 값: ☑ 체크됨\n개별 컨테이너에 대한 익명 액세스 허용 - 설명: 익명 Blob 액세스를 컨테이너 수준에서 허용할지 여부를 설정합니다. - 선택 값: ☐ 체크 안 됨\n스토리지 계정 키 액세스 사용 - 설명: 공유 키를 통한 스토리지 계정 액세스를 허용합니다. - 선택 값: ☑ 체크됨\nAzure Portal에서 Microsoft Entra 인증 기본값 사용 - 설명: Azure Portal 액세스 시 Microsoft Entra ID를 기본 인증 방법으로 사용합니다. - 선택 값: ☐ 체크 안 됨\n최소 TLS 버전 - 설명: 클라이언트에서 요청하는 최소 TLS(전송 계층 보안) 버전을 설정합니다. - 선택 값: 버전 1.2\n복사 작업에 대해 허용된 범위(미리 보기) - 설명: 데이터 복사 작업의 허용 범위를 지정합니다. - 선택 값: 모든 스토리지 계정에서\n\n\n\nData Lake Storage Gen2 엔드포인트로 보안되는 계층 구조 네임스페이스는 파일 및 디렉터리 의미 체계를 사용하고, 빅 데이터 분석 워크로드를 가속화하고, ACL(액세스 제어 목록)을 사용합니다.\n계층 구조 네임스페이스 사용 - 설명: Data Lake Storage Gen2 엔드포인트를 보안되는 계층 구조 네임스페이스입니다. 파일 및 디렉터리 의미 체계를 사용하고, ACL(액세스 제어 목록)을 사용합니다. - 선택 값: ☑ 체크됨 - 참고: 📊 계층 구조 네임스페이스 워크로드에는 빅 데이터 분석(를) 사용하는 것이 좋습니다.\n\n\n\nBLOB 및 Data Lake Gen2 엔드포인트는 기본적으로 프로토비전됨\nSFTP 사용 - 설명: SFTP 프로토콜을 통한 파일 전송을 활성화합니다. - 선택 값: ☑ 체크됨 - 참고: ℹ️ 로컬 사용자 기능은 SFTP로 활성화됩니다. 스토리지 계정을 만든 후 SFTP 끝점에 액세스할 로컬 사용자 ID를 만듭니다.\n네트워크 파일 시스템 v3 사용 - 설명: NFS v3 프로토콜을 사용하여 파일 시스템을 마운트합니다. - 선택 값: ☑ 체크됨\n\n\n\n테넌트 간 복제 허용 - 설명: 다른 Azure AD 테넌트 간 Blob 복제를 허용합니다. - 선택 값: ☐ 체크 안 됨 - 참고: ℹ️ 테넌트 간 복제 및 계층 구조 네임스페이스를 동시에 사용하도록 설정할 수 없습니다.\n액세스 계층 - 설명: 데이터 액세스 빈도에 따른 기본 저장소 계층을 선택합니다. - 핫: 자주 액세스하는 데이터 및 일상적인 사용 시나리오에 최적화됨 - 쿨: 자주 액세스하지 않는 데이터 및 백업 시나리오에 최적화됨 - 콜드: 거의 액세스하지 않는 데이터 및 백업 시나리오에 최적화됨 - 선택 값: 핫 - 참고: 📊 핫 Blob 액세스 계층 워크로드에는 빅 데이터 분석(를) 사용하는 것이 좋습니다.\n\n\n\n큰 파일 공유 사용 - 설명: 최대 100TiB 용량의 대용량 파일 공유를 지원합니다. - 선택 값: ☑ 체크됨 (비활성화됨)"
  },
  {
    "objectID": "docs/blog/posts/Azure_Cloud/01-클라우드 인프라 설정/01-Data_Lake_Storage.html#네트워킹-설정",
    "href": "docs/blog/posts/Azure_Cloud/01-클라우드 인프라 설정/01-Data_Lake_Storage.html#네트워킹-설정",
    "title": "01-Data Lake Storage",
    "section": "",
    "text": "image\n\n\n\n\n공용 네트워크를 통해 어디서나 리소스에 액세스합니다.\n참고: 공용 네트워크를 통해 리소스에 액세스할 수 있게 되면 보안 위험이 증가합니다.\n공용 네트워크 액세스 - 설명: 공용 인터넷에서 스토리지 계정에 대한 액세스 권한을 설정합니다. - 선택 값: 사용 - 이 리소스에 대한 리스크 액세스 구성을 사용하여 선택 인바운드 엔드포인트를 제한하는 옵션을 사용하며 인바운드 및 아웃바운드 엔드포인트를 허용합니다. - 옵션: - ⭕ 사용: 이 리소스에 대한 리스크 액세스 구성을 사용하여 선택 인바운드 엔드포인트를 제한하는 옵션을 사용하며 인바운드 및 아웃바운드 엔드포인트를 허용합니다. - ⚪ 사용 안 함: 아웃바운드 엔드포인트를 허용하면서 인바운드 엔드포인트를 제한합니다. - ⚪ 경계로 보호(가장 제한됨): 네트워크 보안 경계를 사용하여 인바운드 및 아웃바운드 엔드포인트를 제한합니다. 경계로 보호는 리소스를 보호하기 위해 가장 높은 수준의 인바운드 및 아웃바운드 제한을 제공합니다.\n공용 네트워크 액세스 범위 - 설명: 공용 네트워크를 통해 액세스할 수 있는 리소스의 범위를 지정합니다. - 선택 값: 선택한 가상 네트워크 및 IP 주소에서 사용 - 옵션: - ⚪ 모든 네트워크에서 사용 - ⭕ 선택한 가상 네트워크 및 IP 주소에서 사용\n\n\n\n선택한 네트워크만 이 스토리지 계정에 액세스할 수 있습니다.\n가상 네트워크 구독 - 설명: 가상 네트워크가 속한 Azure 구독을 선택합니다. - 입력 값: swlab-test-subs\n가상 네트워크 - 설명: 스토리지 계정에 액세스할 수 있는 가상 네트워크를 선택합니다. - 입력 값: vnet-aipoc-test-krc-insilico-001 - 링크: [가상 네트워크 만들기] / [선택한 가상 네트워크 관리]\n서브넷 - 설명: 가상 네트워크 내에서 액세스를 허용할 서브넷을 선택합니다. - 입력 값: subnet-aipoc-test-krc-insilico-001(172.16.0.0/24)\n\n\n\nAllow select public internet IP addresses to access your resource.\n허용된 IP 주소 - 설명: 스토리지 계정에 액세스할 수 있는 공용 IP 주소를 지정합니다. - 입력 값: 61.74.175.54\n\n\n\n\n\n\n경고⚠️ 중요\n\n\n\n이 값을 자신의 로컬 PC Public IP로 설정을 해 주어야지만, 추후 Azure Portal을 통해 파일 업로드가 가능합니다.\n\n\n\n\n\n프라이빗 엔드포인트 - 설명: 프라이빗 엔드포인트를 만들어 이 리소스에 대한 프라이빗 연결을 허용합니다. 추가 프라이빗 엔드포인트 연결은 스토리지 계정 또는 프라이빗 링크 센터 내에서 만들 수 있습니다. - 선택 값: [+ 프라이빗 엔드포인트 추가] 클릭 가능 - 상태: 프라이빗 엔드포인트를 만들려면 (추가를 클릭합니다)\n\n\n\n트래픽이 원본에서 Azure 엔드포인트로 이동하는 과정에서 트래픽을 라우팅할 방법을 결정하세요. 대부분의 고객의 경우 Microsoft 네트워크 라우팅이 권장됩니다.\n라우팅 기본 설정 - 설명: 트래픽이 원본에서 Azure 엔드포인트로 이동하는 과정에서 트래픽을 라우팅할 방법을 결정합니다. - 선택 값: Microsoft 네트워크 라우팅 - 옵션: - ⭕ Microsoft 네트워크 라우팅 - ⚪ 인터넷 라우팅"
  },
  {
    "objectID": "docs/blog/posts/Azure_Cloud/01-클라우드 인프라 설정/01-Data_Lake_Storage.html#데이터-보호-설정",
    "href": "docs/blog/posts/Azure_Cloud/01-클라우드 인프라 설정/01-Data_Lake_Storage.html#데이터-보호-설정",
    "title": "01-Data Lake Storage",
    "section": "",
    "text": "image\n\n\n\n\n\n전부 디폴트 설정으로 진행\n\nBlob에 일시 삭제 사용 - 설명: 일시 삭제를 사용하면 덮어쓴 Blob을 포함하여 이전에 삭제로 표시되었던 Blob을 복구할 수 있습니다. - 선택 값: ☑ 체크됨 - 삭제된 Blob 보존 기간(일): 7\n컨테이너에 일시 삭제 사용 - 설명: 일시 삭제를 사용하면 이전에 삭제로 표시된 컨테이너를 복구할 수 있습니다. - 선택 값: ☑ 체크됨 - 삭제된 컨테이너 보존 기간(일): 7 - 참고: 자주 덮어쓰는 데이터에 대해 일시 삭제를 사용하도록 설정하면 스토리지 비용이 증가할 수 있습니다.\n파일 공유에 일시 삭제 사용 - 설명: 일시 삭제를 사용하면 이전에 삭제로 표시된 파일 공유를 복구할 수 있습니다. - 선택 값: ☑ 체크됨 - 삭제된 파일 공유 보존 기간(일): 7\n\n\n\nBlob에 버전 관리 사용 - 설명: 버전 관리를 사용하여 Blob의 이전 버전을 자동으로 유지합니다. - 선택 값: ☐ 체크 안 됨 - 참고: 워크로드, 생성된 버전 수에 미치는 영향, 결과 비용을 고려하세요. 데이터 수명 주기를 자동으로 관리하여 비용을 최적화합니다.\nBlob 변경 피드 사용 - 설명: 계정의 Blob에 대한 만들기, 수정 및 삭제 변경 내용을 추적합니다. - 선택 값: ☐ 체크 안 됨\n\n\n\n버전 수준 불변성 지원 사용 - 설명: 모든 Blob 버전에 적용할 계정 수준에서 시간 기반 보존 정책을 설정할 수 있습니다. - 선택 값: ☐ 체크 안 됨 - 참고: 계정 수준에서 기본 정책을 설정하려면 이 기능을 사용하여 도록 설정합니다. 이 기능을 사용하지 않고도 컨테이너 수준에서 기본 정책을 설정하거나 특정 Blob 버전에 대한 정책을 설정할 수 있습니다. 이 속성을 사용하려면 버전 관리를 필요합니다."
  },
  {
    "objectID": "docs/blog/posts/Azure_Cloud/index.html",
    "href": "docs/blog/posts/Azure_Cloud/index.html",
    "title": "Azure Cloud",
    "section": "",
    "text": "01-Data Lake Storage",
    "crumbs": [
      "Blog",
      "Blog Posts",
      "Azure Cloud"
    ]
  },
  {
    "objectID": "docs/blog/posts/Azure_Cloud/index.html#azure-cloud",
    "href": "docs/blog/posts/Azure_Cloud/index.html#azure-cloud",
    "title": "Azure Cloud",
    "section": "",
    "text": "01-Data Lake Storage",
    "crumbs": [
      "Blog",
      "Blog Posts",
      "Azure Cloud"
    ]
  },
  {
    "objectID": "docs/blog/posts/RAG/index.html",
    "href": "docs/blog/posts/RAG/index.html",
    "title": "RAG",
    "section": "",
    "text": "01-VectorStoreRetriever\n02-ContextualCompressionRetriever\n\n\n\n\n\n01-Tools\n02-Bind-Tools\n03-Agent\n04-Agent-More-LLMs\n05-Iter-Human-In-the-Loop",
    "crumbs": [
      "Blog",
      "Blog Posts",
      "RAG"
    ]
  },
  {
    "objectID": "docs/blog/posts/RAG/index.html#rag",
    "href": "docs/blog/posts/RAG/index.html#rag",
    "title": "RAG",
    "section": "",
    "text": "01-VectorStoreRetriever\n02-ContextualCompressionRetriever\n\n\n\n\n\n01-Tools\n02-Bind-Tools\n03-Agent\n04-Agent-More-LLMs\n05-Iter-Human-In-the-Loop",
    "crumbs": [
      "Blog",
      "Blog Posts",
      "RAG"
    ]
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/01-Tools.html",
    "href": "docs/blog/posts/RAG/15-Agent/01-Tools.html",
    "title": "도구 (Tools)",
    "section": "",
    "text": "도구(Tool)는 에이전트, 체인 또는 LLM이 외부 세계와 상호작용하기 위한 인터페이스입니다.\nLangChain 에서 기본 제공하는 도구를 사용하여 쉽게 도구를 활용할 수 있으며, 사용자 정의 도구(Custom Tool) 를 쉽게 구축하는 것도 가능합니다.\nLangChain 에 통합된 도구 리스트는 아래 링크에서 확인할 수 있습니다.\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install -qU langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH15-Tools\")\n코드\nimport warnings\n\n# 경고 메시지 무시\nwarnings.filterwarnings(\"ignore\")"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/01-Tools.html#빌트인-도구built-in-tools",
    "href": "docs/blog/posts/RAG/15-Agent/01-Tools.html#빌트인-도구built-in-tools",
    "title": "도구 (Tools)",
    "section": "1 빌트인 도구(built-in tools)",
    "text": "1 빌트인 도구(built-in tools)\n랭체인에서 제공하는 사전에 정의된 도구(tool) 와 툴킷(toolkit) 을 사용할 수 있습니다.\ntool 은 단일 도구를 의미하며, toolkit 은 여러 도구를 묶어서 하나의 도구로 사용할 수 있습니다.\n관련 도구는 아래의 링크에서 참고하실 수 있습니다.\n참고 - LangChain Tools/Toolkits\n\n1.1 Python REPL 도구\n이 도구는 Python 코드를 REPL(Read-Eval-Print Loop) 환경에서 실행하기 위한 클래스를 제공합니다 어떤 코드를 만들어서 실행하는 것이다. - PythonREPLTool\n설명\n\nPython 셸 환경을 제공합니다.\n유효한 Python 명령어를 입력으로 받아 실행합니다.\n결과를 보려면 print(…) 함수를 사용해야 합니다.\n\n주요 특징\n\nsanitize_input: 입력을 정제하는 옵션 (기본값: True)\npython_repl: PythonREPL 인스턴스 (기본값: 전역 범위에서 실행)\n\n사용 방법\n\nPythonREPLTool 인스턴스 생성\nrun 또는 arun, invoke 메서드를 사용하여 Python 코드 실행\n\n입력 정제\n\n입력 문자열에서 불필요한 공백, 백틱, ‘python’ 키워드 등을 제거합니다.\n\n\n\n코드\nfrom langchain_experimental.tools import PythonREPLTool\n\n# 파이썬 코드를 실행하는 도구를 생성합니다.\npython_tool = PythonREPLTool()\n\n\n\n\n코드\n# 파이썬 코드를 실행하고 결과를 반환합니다.\nprint(python_tool.invoke(\"print(100 + 200)\"))\n\n\n아래는 LLM 에게 파이썬 코드를 작성하도록 요청하고 결과를 반환하는 예제입니다.\n흐름 정리 1. LLM 모델에게 특정 작업을 수행하는 Python 코드를 작성하도록 요청합니다. 2. 작성된 코드를 실행하여 결과를 얻습니다. 3. 결과를 출력합니다.\n\n\n코드\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableLambda\n\n\n# 파이썬 코드를 실행하고 중간 과정을 출력하고 도구 실행 결과를 반환하는 함수\ndef print_and_execute(code, debug=False):\n    if debug:\n        print(\"CODE:\")\n        print(code)\n    return python_tool.invoke(code)\n\n\n# 파이썬 코드를 작성하도록 요청하는 프롬프트\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You are Raymond Hetting, an expert python programmer, well versed in meta-programming and elegant, concise and short but well documented code. You follow the PEP8 style guide. \"\n            \"Return only the code, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the code.\",\n        ),\n        (\"human\", \"{input}\"),\n    ]\n)\n# LLM 모델 생성\nllm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n\n# 프롬프트와 LLM 모델을 사용하여 체인 생성\nchain = prompt | llm | StrOutputParser() | RunnableLambda(print_and_execute)\n\n\n\n\n코드\n# 결과 출력\nprint(chain.invoke(\"로또 번호 생성기를 출력하는 코드를 작성하세요.\"))\n\n\n\n\n1.2 검색 API 도구\nTavily 검색 API를 활용하여 검색 기능을 구현하는 도구입니다. 이 도구는 두 가지 주요 클래스를 제공합니다: TavilySearchResults와 TavilyAnswer.\nAPI 키 발급 주소 - https://app.tavily.com/\n발급한 API 키를 환경변수에 설정합니다.\n.env 파일에 아래와 같이 설정합니다.\nTAVILY_API_KEY=tvly-abcdefghijklmnopqrstuvwxyz\n\n\n1.3 TavilySearchResults\n설명 - Tavily 검색 API를 쿼리하고 JSON 형식의 결과를 반환합니다. - 포괄적이고 정확하며 신뢰할 수 있는 결과에 최적화된 검색 엔진입니다. - 현재 이벤트에 대한 질문에 답변할 때 유용합니다. - 사용자가 LLM/RAG 에서도 없는 최신 정보가 불만족스럽거나, 그럴때 사용하는것.\n주요 매개변수 - max_results (int): 반환할 최대 검색 결과 수 (기본값: 5) - search_depth (str): 검색 깊이 (“basic” 또는 “advanced”) - include_domains (List[str]): 검색 결과에 포함할 도메인 목록 - exclude_domains (List[str]): 검색 결과에서 제외할 도메인 목록 - include_answer (bool): 원본 쿼리에 대한 짧은 답변 포함 여부 - include_raw_content (bool): 각 사이트의 정제된 HTML 콘텐츠 포함 여부 - include_images (bool): 쿼리 관련 이미지 목록 포함 여부\n반환 값 - 검색 결과를 포함하는 JSON 형식의 문자열(url, content)\n혹은 아래의 주석을 해제하고 발급받은 API 키를 입력합니다.\n\n\n코드\n# import os\n\n# os.environ[\"TAVILY_API_KEY\"] = \"TAVILY API 키 입력\"\n\n\n\n\n코드\nfrom langchain_community.tools.tavily_search import TavilySearchResults\n\n# 도구 생성\ntool = TavilySearchResults(\n    max_results=6,\n    include_answer=True,\n    include_raw_content=True,\n    # include_images=True,\n    # search_depth=\"advanced\", # or \"basic\"\n    include_domains=[\"github.io\", \"wikidocs.net\"],\n    # exclude_domains = []\n)\n\n\n\n\n코드\n# 도구 실행\ntool.invoke({\"query\": \"LangChain Tools 에 대해서 알려주세요\"})\n\n\n\n\n1.4 Image 생성 도구 (DALL-E)\n\nDallEAPIWrapper 클래스: OpenAI의 DALL-E 이미지 생성기를 위한 래퍼(wrapper)입니다.\n\n이 도구를 사용하면 DALL-E API를 쉽게 통합하여 텍스트 기반 이미지 생성 기능을 구현할 수 있습니다. 다양한 설정 옵션을 통해 유연하고 강력한 이미지 생성 도구로 활용할 수 있습니다.\n주요 속성\n\nmodel: 사용할 DALL-E 모델 이름 (기본값: “dall-e-2”, “dall-e-3”)\nn: 생성할 이미지 수 (기본값: 1)\nsize: 생성할 이미지 크기\n\n“dall-e-2”: “1024x1024”, “512x512”, “256x256”\n“dall-e-3”: “1024x1024”, “1792x1024”, “1024x1792”\n\nstyle: 생성될 이미지의 스타일 (기본값: “natural”, “vivid”)\nquality: 생성될 이미지의 품질 (기본값: “standard”, “hd”)\nmax_retries: 생성 시 최대 재시도 횟수\n\n주요 기능 - DALL-E API를 사용하여 텍스트 설명에 기반한 이미지 생성\n흐름 정리\n다음은 DALL-E Image Generator 를 사용하여 이미지를 생성하는 예제입니다.\n이번에는 DallEAPIWrapper 를 사용하여 이미지를 생성해 보겠습니다.\n이때 입력 프롬프트는 LLM 모델에게 이미지를 생성하는 프롬프트를 작성하도록 요청합니다.\n\n\n코드\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n# ChatOpenAI 모델 초기화\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.9, max_tokens=1000)\n\n# DALL-E 이미지 생성을 위한 프롬프트 템플릿 정의\nprompt = PromptTemplate.from_template(\n    \"Generate a detailed IMAGE GENERATION prompt for DALL-E based on the following description. \"\n    \"Return only the prompt, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the prompt\"\n    \"Output should be less than 1000 characters. Write in English only.\"\n    \"Image Description: \\n{image_desc}\",\n)\n\n# 프롬프트, LLM, 출력 파서를 연결하는 체인 생성\nchain = prompt | llm | StrOutputParser()\n\n# 체인 실행\nimage_prompt = chain.invoke(\n    {\"image_desc\": \"스마트폰을 바라보는 사람들을 풍자한 neo-classicism painting\"}\n)\n\n# 이미지 프롬프트 출력\nprint(image_prompt)\n\n\n그럼, 이전에 생성한 이미지 프롬프트를 DallEAPIWrapper 에 입력하여 이미지를 생성해 보겠습니다.\nDallEAPIWrapper 에 대한 임시 버그 안내사항 (작성일: 2024-10-13)\n\n현재 langchain 0.3.x 이상 버전에서 DallEAPIWrapper 에 대한 임시 버그가 있습니다. (401 오류: invalid API key)\n\n따라서, 아래의 코드를 오류 없이 실행하기 위해서는 LangChain 버전을 0.2.16 으로 변경해야 합니다.\n아래의 주석을 해제하고 실행하면 LangChain 버전을 0.2.16 으로 변경됩니다.\n하지만, 이후 내용에서는 LangChain 버전을 0.3.x 이상으로 변경하여 사용하기 때문에\npoetry shell 명령어를 통해 다시 최신 langchain 버전으로 변경해야 합니다.\n이 과정이 번거로운 분들은 일단 DallEAPIWrapper 를 사용하지 않고 진행하셔도 무방합니다.\n업그레이드/다운그레이드 후에는 반드시 상단 메뉴의 “Restart” 버튼을 클릭한 뒤 진행해야 합니다.\n\n\n코드\n# 임시 버전 다운그레이드 명령어 (실행 후 restart)\n# !pip install langchain==0.2.16 langchain-community==0.2.16 langchain-text-splitters==0.2.4 langchain-experimental==0.0.65 langchain-openai==0.1.20\n\n\n\n\n코드\n# DALL-E API 래퍼 가져오기\nfrom langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\nfrom IPython.display import Image\nimport os\n\n# DALL-E API 래퍼 초기화\n# model: 사용할 DALL-E 모델 버전\n# size: 생성할 이미지 크기\n# quality: 이미지 품질\n# n: 생성할 이미지 수\ndalle = DallEAPIWrapper(\n    model=\"dall-e-3\",\n    size=\"1024x1024\",\n    quality=\"standard\",\n    n=1,\n)\n\n# 질문\nquery = \"스마트폰을 바라보는 사람들을 풍자한 neo-classicism painting\"\n\n# 이미지 생성 및 URL 받기\n# chain.invoke()를 사용하여 이미지 설명을 DALL-E 프롬프트로 변환\n# dalle.run()을 사용하여 실제 이미지 생성\nimage_url = dalle.run(chain.invoke({\"image_desc\": query}))\n\n# 생성된 이미지를 표시합니다.\nImage(url=image_url, width=500)"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/01-Tools.html#사용자-정의-도구custom-tool",
    "href": "docs/blog/posts/RAG/15-Agent/01-Tools.html#사용자-정의-도구custom-tool",
    "title": "도구 (Tools)",
    "section": "2 사용자 정의 도구(Custom Tool)",
    "text": "2 사용자 정의 도구(Custom Tool)\nLangChain 에서 제공하는 빌트인 도구 외에도 사용자가 직접 도구를 정의하여 사용할 수 있습니다.\n이를 위해서는 langchain.tools 모듈에서 제공하는 tool 데코레이터를 사용하여 함수를 도구로 변환합니다.\n\n2.1 @tool 데코레이터\n이 데코레이터는 함수를 도구로 변환하는 기능을 제공합니다. 다양한 옵션을 통해 도구의 동작을 커스터마이즈할 수 있습니다.\n사용 방법 1. 함수 위에 @tool 데코레이터 적용 2. 필요에 따라 데코레이터 매개변수 설정\n이 데코레이터를 사용하면 일반 Python 함수를 강력한 도구로 쉽게 변환할 수 있으며, 자동화된 문서화와 유연한 인터페이스 생성이 가능합니다.\n\n\n코드\nfrom langchain.tools import tool\n\n\n# 데코레이터를 사용하여 함수를 도구로 변환합니다.\n@tool\ndef add_numbers(a: int, b: int) -&gt; int:\n    \"\"\"Add two numbers\"\"\"\n    return a + b\n\n\n@tool\ndef multiply_numbers(a: int, b: int) -&gt; int:\n    \"\"\"Multiply two numbers\"\"\"\n    return a * b\n\n\n\n\n코드\n# 도구 실행\nadd_numbers.invoke({\"a\": 3, \"b\": 4})\n\n\n\n\n코드\n# 도구 실행\nmultiply_numbers.invoke({\"a\": 3, \"b\": 4})\n\n\n\n\n2.2 구글 뉴스기사 검색 도구\nlangchain-teddynote 패키지에서 제공하는 GoogleNews 도구를 사용하여 구글 뉴스기사를 검색하는 도구입니다.\n참고 - API 키가 필요하지 않습니다. (RSS 피드를 사용하기 때문)\nnews.google.com 에서 제공하는 뉴스기사를 검색하는 도구입니다.\n설명 - 구글 뉴스 검색 API를 사용하여 최신 뉴스를 검색합니다. - 키워드를 기반으로 뉴스를 검색할 수 있습니다. - 최신 뉴스를 검색할 수 있습니다.\n주요 매개변수 - k (int): 반환할 최대 검색 결과 수 (기본값: 5)\n사용하기 전 패키지를 업데이트 해주세요.\n\n\n코드\n# !pip install -qU langchain-teddynote\n\n\n\n\n코드\nfrom langchain_teddynote.tools import GoogleNews\n\n# 도구 생성\nnews_tool = GoogleNews()\n\n\n\n\n코드\n# 최신 뉴스 검색\nnews_tool.search_latest(k=5)\n\n\n\n\n코드\n# 키워드로 뉴스 검색\nnews_tool.search_by_keyword(\"AI 투자\", k=3)\n\n\n\n\n코드\nfrom langchain_teddynote.tools import GoogleNews\nfrom langchain.tools import tool\nfrom typing import List, Dict\n\n\n# 키워드로 뉴스 검색하는 도구 생성\n@tool\ndef search_keyword(query: str) -&gt; List[Dict[str, str]]:\n    \"\"\"Look up news by keyword\"\"\"\n    print(query)\n    news_tool = GoogleNews()\n    return news_tool.search_by_keyword(query, k=5)\n\n\n\n\n코드\n# 실행 결과\nsearch_keyword.invoke({\"query\": \"LangChain AI\"})"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/02-Bind-Tools.html",
    "href": "docs/blog/posts/RAG/15-Agent/02-Bind-Tools.html",
    "title": "LLM 에 도구 바인딩(Binding Tools)",
    "section": "",
    "text": "LLM 모델이 도구(tool) 를 호출할 수 있으려면 chat 요청을 할 때 모델에 도구 스키마(tool schema) 를 전달해야 합니다.\n도구 호출(tool calling) 기능을 지원하는 LangChain Chat Model 은 .bind_tools() 메서드를 구현하여 LangChain 도구 객체, Pydantic 클래스 또는 JSON 스키마 목록을 수신하고 공급자별 예상 형식으로 채팅 모델에 바인딩(binding) 합니다.\n바인딩된 Chat Model 의 후속 호출은 모델 API에 대한 모든 호출에 도구 스키마를 포함합니다.\n코드\n# API KEY를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API KEY 정보로드\nload_dotenv()\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install -qU langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH15-Bind-Tools\")"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/02-Bind-Tools.html#llm에-바인딩할-tool-정의",
    "href": "docs/blog/posts/RAG/15-Agent/02-Bind-Tools.html#llm에-바인딩할-tool-정의",
    "title": "LLM 에 도구 바인딩(Binding Tools)",
    "section": "1 LLM에 바인딩할 Tool 정의",
    "text": "1 LLM에 바인딩할 Tool 정의\n실험을 위한 도구(tool) 를 정의합니다.\n\nget_word_length : 단어의 길이를 반환하는 함수\nadd_function : 두 숫자를 더하는 함수\nnaver_news_crawl : 네이버 뉴스 기사를 크롤링하여 본문 내용을 반환하는 함수\n\n참고 - 도구를 정의할 때 @tool 데코레이터를 사용하여 도구를 정의합니다. - docstring 은 가급적 영어로 작성하는 것을 권장합니다.\n\n\n코드\nimport re\nimport requests\nfrom bs4 import BeautifulSoup\nfrom langchain.agents import tool\n\n\n# 도구를 정의합니다.\n@tool\ndef get_word_length(word: str) -&gt; int:\n    \"\"\"Returns the length of a word.\"\"\"\n    return len(word)\n\n\n@tool\ndef add_function(a: float, b: float) -&gt; float:\n    \"\"\"Adds two numbers together.\"\"\"\n    return a + b\n\n\n@tool\ndef naver_news_crawl(news_url: str) -&gt; str:\n    \"\"\"Crawls a 네이버 (naver.com) news article and returns the body content.\"\"\"\n    # HTTP GET 요청 보내기\n    response = requests.get(news_url)\n\n    # 요청이 성공했는지 확인\n    if response.status_code == 200:\n        # BeautifulSoup을 사용하여 HTML 파싱\n        soup = BeautifulSoup(response.text, \"html.parser\")\n\n        # 원하는 정보 추출\n        title = soup.find(\"h2\", id=\"title_area\").get_text()\n        content = soup.find(\"div\", id=\"contents\").get_text()\n        cleaned_title = re.sub(r\"\\n{2,}\", \"\\n\", title)\n        cleaned_content = re.sub(r\"\\n{2,}\", \"\\n\", content)\n    else:\n        print(f\"HTTP 요청 실패. 응답 코드: {response.status_code}\")\n\n    return f\"{cleaned_title}\\n{cleaned_content}\"\n\n\ntools = [get_word_length, add_function, naver_news_crawl]"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/02-Bind-Tools.html#bind_tools-로-llm-에-도구-바인딩",
    "href": "docs/blog/posts/RAG/15-Agent/02-Bind-Tools.html#bind_tools-로-llm-에-도구-바인딩",
    "title": "LLM 에 도구 바인딩(Binding Tools)",
    "section": "2 bind_tools() 로 LLM 에 도구 바인딩",
    "text": "2 bind_tools() 로 LLM 에 도구 바인딩\nllm 모델에 bind_tools() 를 사용하여 도구를 바인딩합니다.\n\n\n코드\nfrom langchain_openai import ChatOpenAI\n\n# 모델 생성\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n# 도구 바인딩\nllm_with_tools = llm.bind_tools(tools)\n\n\n실행결과를 확인합니다.\n결과는 tool_calls 에 저장됩니다. 따라서, .tool_calls 를 확인하여 도구 호출 결과를 확인할 수 있습니다.\n참고 - name 은 도구의 이름을 의미합니다. - args 는 도구에 전달되는 인자를 의미합니다.\n\n\n코드\n# 실행 결과\nllm_with_tools.invoke(\"What is the length of the word 'teddynote'?\").tool_calls\n\n\n다음으로는 llm_with_tools 와 JsonOutputToolsParser 를 연결하여 tool_calls 를 parsing 하여 결과를 확인합니다.\n\n\n코드\nfrom langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n\n# 도구 바인딩 + 도구 파서\nchain = llm_with_tools | JsonOutputToolsParser(tools=tools)\n\n# 실행 결과\ntool_call_results = chain.invoke(\"What is the length of the word 'teddynote'?\")\n\n\n\n\n코드\nprint(tool_call_results)\n\n\n실행 결과는 다음과 같습니다.\n참고 - type: 도구의 이름 - args: 도구에 전달되는 인자\n\n\n코드\nprint(tool_call_results, end=\"\\n\\n==========\\n\\n\")\n# 첫 번째 도구 호출 결과\nsingle_result = tool_call_results[0]\n# 도구 이름\nprint(single_result[\"type\"])\n# 도구 인자\nprint(single_result[\"args\"])\n\n\n도구 이름과 일치하는 도구를 찾아 실행합니다.\n\n\n코드\ntool_call_results[0][\"type\"], tools[0].name\n\n\nexecute_tool_calls 함수는 도구를 찾아 args 를 전달하여 도구를 실행합니다.\n즉, type 은 도구의 이름을 의미하고 args 는 도구에 전달되는 인자를 의미합니다.\n\n\n코드\ndef execute_tool_calls(tool_call_results):\n    \"\"\"\n    도구 호출 결과를 실행하는 함수\n\n    :param tool_call_results: 도구 호출 결과 리스트\n    :param tools: 사용 가능한 도구 리스트\n    \"\"\"\n    # 도구 호출 결과 리스트를 순회합니다.\n    for tool_call_result in tool_call_results:\n        # 도구의 이름과 인자를 추출합니다.\n        tool_name = tool_call_result[\"type\"]  # 도구의 이름(함수명)\n        tool_args = tool_call_result[\"args\"]  # 도구에 전달되는 인자\n\n        # 도구 이름과 일치하는 도구를 찾아 실행합니다.\n        # next() 함수를 사용하여 일치하는 첫 번째 도구를 찾습니다.\n        matching_tool = next((tool for tool in tools if tool.name == tool_name), None)\n\n        if matching_tool:\n            # 일치하는 도구를 찾았다면 해당 도구를 실행합니다.\n            result = matching_tool.invoke(tool_args)\n            # 실행 결과를 출력합니다.\n            print(f\"[실행도구] {tool_name} [Argument] {tool_args}\\n[실행결과] {result}\")\n        else:\n            # 일치하는 도구를 찾지 못했다면 경고 메시지를 출력합니다.\n            print(f\"경고: {tool_name}에 해당하는 도구를 찾을 수 없습니다.\")\n\n\n# 도구 호출 실행\n# 이전에 얻은 tool_call_results를 인자로 전달하여 함수를 실행합니다.\nexecute_tool_calls(tool_call_results)"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/02-Bind-Tools.html#bind_tools-parser-execution",
    "href": "docs/blog/posts/RAG/15-Agent/02-Bind-Tools.html#bind_tools-parser-execution",
    "title": "LLM 에 도구 바인딩(Binding Tools)",
    "section": "3 bind_tools + Parser + Execution",
    "text": "3 bind_tools + Parser + Execution\n이번에는 일련의 과정을 한 번에 실행합니다.\n\nllm_with_tools : 도구를 바인딩한 모델\nJsonOutputToolsParser : 도구 호출 결과를 파싱하는 파서\nexecute_tool_calls : 도구 호출 결과를 실행하는 함수\n\n흐름 정리 1. 모델에 도구를 바인딩 2. 도구 호출 결과를 파싱 3. 도구 호출 결과를 실행\n\n\n코드\nfrom langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n\n# bind_tools + Parser + Execution\nchain = llm_with_tools | JsonOutputToolsParser(tools=tools) | execute_tool_calls\n\n\n\n\n코드\n# 실행 결과\nchain.invoke(\"What is the length of the word 'teddynote'?\")\n\n\n\n\n코드\n# 실행 결과\nchain.invoke(\"114.5 + 121.2\")\nprint(114.5 + 121.2)\n\n\n\n\n코드\n# 실행 결과\nchain.invoke(\n    \"뉴스 기사 내용을 크롤링해줘: https://n.news.naver.com/mnews/hotissue/article/092/0002347672?type=series&cid=2000065\"\n)"
  },
  {
    "objectID": "docs/blog/posts/RAG/15-Agent/02-Bind-Tools.html#bind_tools-agent-agentexecutor-로-대체",
    "href": "docs/blog/posts/RAG/15-Agent/02-Bind-Tools.html#bind_tools-agent-agentexecutor-로-대체",
    "title": "LLM 에 도구 바인딩(Binding Tools)",
    "section": "4 bind_tools > Agent & AgentExecutor 로 대체",
    "text": "4 bind_tools &gt; Agent & AgentExecutor 로 대체\nbind_tools() 는 모델에 사용할 수 있는 스키마(도구)를 제공합니다.\nAgentExecutor 는 실제로 llm 호출, 올바른 도구로 라우팅, 실행, 모델 재호출 등을 위한 실행 루프를 생성합니다.\n참고 - Agent 와 AgentExecutor 에 대해서는 다음 장에서 자세히 다룹니다.\n\n\n코드\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_openai import ChatOpenAI\n\n# Agent 프롬프트 생성\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You are very powerful assistant, but don't know current events\",\n        ),\n        (\"user\", \"{input}\"),\n        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n    ]\n)\n\n# 모델 생성\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n\n\n\n코드\nfrom langchain.agents import create_tool_calling_agent\nfrom langchain.agents import AgentExecutor\n\n# 이전에 정의한 도구 사용\ntools = [get_word_length, add_function, naver_news_crawl]\n\n# Agent 생성\nagent = create_tool_calling_agent(llm, tools, prompt)\n\n# AgentExecutor 생성\nagent_executor = AgentExecutor(\n    agent=agent,\n    tools=tools,\n    verbose=True,\n    handle_parsing_errors=True,\n)\n\n\n\n\n코드\n# Agent 실행\nresult = agent_executor.invoke({\"input\": \"How many letters in the word `teddynote`?\"})\n\n# 결과 확인\nprint(result[\"output\"])\n\n\n\n\n코드\n# Agent 실행\nresult = agent_executor.invoke({\"input\": \"114.5 + 121.2 의 계산 결과는?\"})\n\n# 결과 확인\nprint(result[\"output\"])\n\n\n한 번의 실행으로 끝나는 것이 아닌, 모델이 자신의 결과를 확인하고 다시 자신을 호출하는 과정을 거칩니다.\n\n\n코드\n# Agent 실행\nresult = agent_executor.invoke(\n    {\"input\": \"114.5 + 121.2 + 34.2 + 110.1 의 계산 결과는?\"}\n)\n\n# 결과 확인\nprint(result[\"output\"])\nprint(\"==========\\n\")\nprint(114.5 + 121.2 + 34.2 + 110.1)\n\n\n이번에는 뉴스 결과를 크롤링 해서 요약 해달라는 요청을 수행합니다.\n\n\n코드\nresult = agent_executor.invoke(\n    {\n        \"input\": \"뉴스 기사를 요약해 줘: https://n.news.naver.com/mnews/hotissue/article/092/0002347672?type=series&cid=2000065\"\n    }\n)\nprint(result[\"output\"])"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/02-ContextualCompressionRetriever.html",
    "href": "docs/blog/posts/RAG/10-Retriever/02-ContextualCompressionRetriever.html",
    "title": "문맥 압축 검색기(ContextualCompressionRetriever)",
    "section": "",
    "text": "검색 시스템에서 직면하는 어려움 중 하나는 데이터를 시스템에 수집할 때 어떤 특정 질의를 처리해야 할지 미리 알 수 없다는 점입니다.\n이는 질의와 가장 관련성이 높은 정보가 많은 양의 무관한 텍스트를 포함한 문서에 묻혀 있을 수 있음을 의미합니다.\n이러한 전체 문서를 애플리케이션에 전달하면 더 비용이 많이 드는 LLM 호출과 품질이 낮은 응답으로 이어질 수 있습니다.\nContextualCompressionRetriever 은 이 문제를 해결하기 위해 고안되었습니다.\n아이디어는 간단합니다. 검색된 문서를 그대로 즉시 반환하는 대신, 주어진 질의의 맥락을 사용하여 문서를 압축함으로써 관련 정보만 반환되도록 할 수 있습니다.\n여기서 “압축”은 개별 문서의 내용을 압축하는 것과 문서를 전체적으로 필터링하는 것 모두를 의미합니다.\nContextualCompressionRetriever 는 질의를 base retriever에 전달하고, 초기 문서를 가져와 Document Compressor를 통과시킵니다.\nDocument Compressor는 문서 목록을 가져와 문서의 내용을 줄이거나 문서를 완전히 삭제하여 목록을 축소합니다.\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH10-Retriever\")\n코드\n# 패키지 업데이트\n!pip install -qU langchain-teddynote\npretty_print_docs 함수는 문서 리스트를 예쁘게 출력하는 헬퍼 함수입니다.\n코드\n# 문서를 예쁘게 출력하기 위한 도우미 함수\ndef pretty_print_docs(docs):\n    print(\n        f\"\\n{'-' * 100}\\n\".join(\n            [f\"문서 {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n        )\n    )"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/02-ContextualCompressionRetriever.html#기본-retriever-설정",
    "href": "docs/blog/posts/RAG/10-Retriever/02-ContextualCompressionRetriever.html#기본-retriever-설정",
    "title": "문맥 압축 검색기(ContextualCompressionRetriever)",
    "section": "1 기본 Retriever 설정",
    "text": "1 기본 Retriever 설정\n간단한 벡터 스토어 retriever를 초기화하고 텍스트 문서를 청크 단위로 저장하는 것부터 시작해 보겠습니다.\n예시 질문을 던졌을 때, retriever는 관련 있는 문서 1~2개와 관련 없는 문서 몇 개를 반환하는 것을 확인할 수 있습니다.\n\n\n코드\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import CharacterTextSplitter\n\n# TextLoader를 사용하여 \"appendix-keywords.txt\" 파일에서 문서를 로드합니다.\nloader = TextLoader(\"./data/appendix-keywords.txt\")\n\n# CharacterTextSplitter를 사용하여 문서를 청크 크기 300자와 청크 간 중복 0으로 분할합니다.\ntext_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\ntexts = loader.load_and_split(text_splitter)\n\n# OpenAIEmbeddings를 사용하여 FAISS 벡터 저장소를 생성하고 검색기로 변환합니다.\nretriever = FAISS.from_documents(texts, OpenAIEmbeddings()).as_retriever()\n\n# 쿼리에 질문을 정의하고 관련 문서를 검색합니다.\ndocs = retriever.invoke(\"Semantic Search 에 대해서 알려줘.\")\n\n# 검색된 문서를 예쁘게 출력합니다.\npretty_print_docs(docs)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/02-ContextualCompressionRetriever.html#맥락적-압축contextualcompression",
    "href": "docs/blog/posts/RAG/10-Retriever/02-ContextualCompressionRetriever.html#맥락적-압축contextualcompression",
    "title": "문맥 압축 검색기(ContextualCompressionRetriever)",
    "section": "2 맥락적 압축(ContextualCompression)",
    "text": "2 맥락적 압축(ContextualCompression)\nLLMChainExtractor 를 활용하여 생성한 DocumentCompressor 를 retriever 에 적용한 것이 바로 ContextualCompressionRetriever 입니다.\n\n\n코드\nfrom langchain_teddynote.document_compressors import LLMChainExtractor\nfrom langchain.retrievers import ContextualCompressionRetriever\n\n# from langchain.retrievers.document_compressors import LLMChainExtractor\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")  # OpenAI 언어 모델 초기화\n\n# LLM을 사용하여 문서 압축기 생성\ncompressor = LLMChainExtractor.from_llm(llm)\ncompression_retriever = ContextualCompressionRetriever(\n    # 문서 압축기와 리트리버를 사용하여 컨텍스트 압축 리트리버 생성\n    base_compressor=compressor,\n    base_retriever=retriever,\n)\n\npretty_print_docs(retriever.invoke(\"Semantic Search 에 대해서 알려줘.\"))\n\nprint(\"=========================================================\")\nprint(\"============== LLMChainExtractor 적용 후 ==================\")\n\ncompressed_docs = (\n    compression_retriever.invoke(  # 컨텍스트 압축 리트리버를 사용하여 관련 문서 검색\n        \"Semantic Search 에 대해서 알려줘.\"\n    )\n)\npretty_print_docs(compressed_docs)  # 검색된 문서를 예쁘게 출력"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/02-ContextualCompressionRetriever.html#llm-을-활용한-문서-필터링",
    "href": "docs/blog/posts/RAG/10-Retriever/02-ContextualCompressionRetriever.html#llm-을-활용한-문서-필터링",
    "title": "문맥 압축 검색기(ContextualCompressionRetriever)",
    "section": "3 LLM 을 활용한 문서 필터링",
    "text": "3 LLM 을 활용한 문서 필터링\n–&gt; LLM 으로 할까? 임베딩으로 할까?\n\n3.1 LLMChainFilter\nLLMChainFilter는 초기에 검색된 문서 중 어떤 문서를 필터링하고 어떤 문서를 반환할지 결정하기 위해 LLM 체인을 사용하는 보다 단순하지만 강력한 압축기입니다.\n이 필터는 문서 내용을 변경(압축)하지 않고 문서를 선택적으로 반환 합니다.\n\n\n코드\nfrom langchain_teddynote.document_compressors import LLMChainFilter\n\n# LLM을 사용하여 LLMChainFilter 객체를 생성합니다.\n_filter = LLMChainFilter.from_llm(llm)\n\ncompression_retriever = ContextualCompressionRetriever(\n    # LLMChainFilter와 retriever를 사용하여 ContextualCompressionRetriever 객체를 생성합니다.\n    base_compressor=_filter,\n    base_retriever=retriever,\n)\n\ncompressed_docs = compression_retriever.invoke(\n    # 쿼리\n    \"Semantic Search 에 대해서 알려줘.\"\n)\npretty_print_docs(compressed_docs)  # 압축된 문서를 예쁘게 출력합니다.\n\n\n\n\n3.2 EmbeddingsFilter\n각각의 검색된 문서에 대해 추가적인 LLM 호출을 수행하는 것은 비용이 많이 들고 속도가 느립니다.\nEmbeddingsFilter는 문서와 쿼리를 임베딩하고 쿼리와 충분히 유사한 임베딩을 가진 문서만 반환함으로써 더 저렴하고 빠른 옵션을 제공합니다.\n이를 통해 검색 결과의 관련성을 유지하면서도 계산 비용과 시간을 절약할 수 있습니다.\nEmbeddingsFilter 와 ContextualCompressionRetriever 를 사용하여 관련 문서를 압축하고 검색하는 과정입니다.\n\nEmbeddingsFilter 를 사용하여 지정된 유사도 임계값(0.86) 이상인 문서를 필터링 합니다.\n\n\n\n코드\nfrom langchain.retrievers.document_compressors import EmbeddingsFilter\nfrom langchain_openai import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings()\n\n# 유사도 임계값이 0.76인 EmbeddingsFilter 객체를 생성합니다.\nembeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.86)\n\n# 기본 압축기로 embeddings_filter를, 기본 검색기로 retriever를 사용하여 ContextualCompressionRetriever 객체를 생성합니다.\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=embeddings_filter, base_retriever=retriever\n)\n\n# ContextualCompressionRetriever 객체를 사용하여 관련 문서를 검색합니다.\ncompressed_docs = compression_retriever.invoke(\n    # 쿼리\n    \"Semantic Search 에 대해서 알려줘.\"\n)\n# 압축된 문서를 예쁘게 출력합니다.\npretty_print_docs(compressed_docs)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/02-ContextualCompressionRetriever.html#파이프라인-생성압축기문서-변환기",
    "href": "docs/blog/posts/RAG/10-Retriever/02-ContextualCompressionRetriever.html#파이프라인-생성압축기문서-변환기",
    "title": "문맥 압축 검색기(ContextualCompressionRetriever)",
    "section": "4 파이프라인 생성(압축기+문서 변환기)",
    "text": "4 파이프라인 생성(압축기+문서 변환기)\nDocumentCompressorPipeline 을 사용하면 여러 compressor를 순차적으로 결합할 수 있습니다.\nCompressor와 함께 BaseDocumentTransformer를 파이프라인에 추가할 수 있는데, 이는 맥락적 압축을 수행하지 않고 단순히 문서 집합에 대한 변환을 수행합니다.\n예를 들어, TextSplitter는 문서를 더 작은 조각으로 분할하기 위해 document transformer로 사용될 수 있으며, EmbeddingsRedundantFilter는 문서 간의 임베딩 유사성(기본값: 0.95 유사도 이상을 중복 문서로 간주) 을 기반으로 중복 문서를 필터링하는 데 사용될 수 있습니다.\n아래에서는 먼저 문서를 더 작은 청크로 분할한 다음, 중복 문서를 제거하고, 쿼리와의 관련성을 기준으로 필터링하여 compressor pipeline을 생성합니다.\n\n\n코드\nfrom langchain.retrievers.document_compressors import DocumentCompressorPipeline\nfrom langchain_community.document_transformers import EmbeddingsRedundantFilter\nfrom langchain_text_splitters import CharacterTextSplitter\n\n# 문자 기반 텍스트 분할기를 생성하고, 청크 크기를 300으로, 청크 간 중복을 0으로 설정합니다.\nsplitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n\n# 임베딩을 사용하여 중복 필터를 생성합니다.\nredundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n\n# 임베딩을 사용하여 관련성 필터를 생성하고, 유사도 임계값을 0.86으로 설정합니다.\nrelevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.86)\n\npipeline_compressor = DocumentCompressorPipeline(\n    # 문서 압축 파이프라인을 생성하고, 분할기, 중복 필터, 관련성 필터, LLMChainExtractor를 변환기로 설정합니다.\n    transformers=[\n        splitter,\n        redundant_filter,\n        relevant_filter,\n        LLMChainExtractor.from_llm(llm),\n    ]\n)\n\n\nContextualCompressionRetriever를 초기화하며, base_compressor로 pipeline_compressor를, base_retriever로 retriever를 사용합니다.\n\n\n코드\ncompression_retriever = ContextualCompressionRetriever(\n    # 기본 압축기로 pipeline_compressor를 사용하고, 기본 검색기로 retriever를 사용하여 ContextualCompressionRetriever를 초기화합니다.\n    base_compressor=pipeline_compressor,\n    base_retriever=retriever,\n)\n\ncompressed_docs = compression_retriever.invoke(\n    # 쿼리\n    \"Semantic Search 에 대해서 알려줘.\"\n)\n# 압축된 문서를 예쁘게 출력합니다.\npretty_print_docs(compressed_docs)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/05-ParentDocumentRetriever.html",
    "href": "docs/blog/posts/RAG/10-Retriever/05-ParentDocumentRetriever.html",
    "title": "Parent Document Retriever",
    "section": "",
    "text": "문서 검색과 문서 분할의 균형 잡기\n문서 검색 과정에서 문서를 적절한 크기의 조각(청크)으로 나누는 것은 다음의 상충되는 두 가지 중요한 요소를 고려해야 합니다.\nParentDocumentRetriever의 역할\n이 두 요구 사항 사이의 균형을 맞추기 위해 ParentDocumentRetriever라는 도구가 사용됩니다. 이 도구는 문서를 작은 조각으로 나누고, 이 조각들을 관리합니다. 검색을 진행할 때는, 먼저 이 작은 조각들을 찾아낸 다음, 이 조각들이 속한 원본 문서(또는 더 큰 조각)의 식별자(ID)를 통해 전체적인 맥락을 파악할 수 있습니다.\n여기서 ’부모 문서’란, 작은 조각이 나누어진 원본 문서를 말합니다. 이는 전체 문서일 수도 있고, 비교적 큰 다른 조각일 수도 있습니다. 이 방식을 통해 문서의 의미를 정확하게 파악하면서도, 전체적인 맥락을 유지할 수 있게 됩니다.\n정리\n여러 개의 텍스트 파일을 로드하기 위해 TextLoader 객체를 생성하고 데이터를 로드합니다.\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH10-Retriever\")\n코드\nfrom langchain.storage import InMemoryStore\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_chroma import Chroma\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain.retrievers import ParentDocumentRetriever\n코드\nloaders = [\n    # 파일을 로드합니다.\n    TextLoader(\"./data/appendix-keywords.txt\"),\n]\n\ndocs = []\nfor loader in loaders:\n    # 로더를 사용하여 문서를 로드하고 docs 리스트에 추가합니다.\n    docs.extend(loader.load())"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/05-ParentDocumentRetriever.html#전체-문서-검색",
    "href": "docs/blog/posts/RAG/10-Retriever/05-ParentDocumentRetriever.html#전체-문서-검색",
    "title": "Parent Document Retriever",
    "section": "1 전체 문서 검색",
    "text": "1 전체 문서 검색\n이 모드에서는 전체 문서를 검색하고자 합니다. 따라서 child_splitter 만 지정하도록 하겠습니다.\n\n나중에는 parent_splitter 도 지정하여 결과를 비교해 보겠습니다.\n\n\n\n코드\n# 자식 분할기를 생성합니다.\nchild_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n\n# DB를 생성합니다.\nvectorstore = Chroma(\n    collection_name=\"full_documents\", embedding_function=OpenAIEmbeddings()\n)\n\nstore = InMemoryStore()\n\n# Retriever 를 생성합니다.\nretriever = ParentDocumentRetriever(\n    vectorstore=vectorstore,\n    docstore=store,\n    child_splitter=child_splitter,\n)\n\n\nretriever.add_documents(docs, ids=None) 함수로 문서목록을 추가합니다.\n\nids 가 None 이면 자동으로 생성됩니다.\nadd_to_docstore=False 로 설정시 document 를 중복으로 추가하지 않습니다. 단, 중복을 체크하기 위한 ids 값이 필수 값으로 요구됩니다.\n\n\n\n코드\n# 문서를 검색기에 추가합니다. docs는 문서 목록이고, ids는 문서의 고유 식별자 목록입니다.\nretriever.add_documents(docs, ids=None, add_to_docstore=True)\n\n\n이 코드는 두 개의 키를 반환해야 합니다. 그 이유는 우리가 두 개의 문서를 추가했기 때문입니다.\n\nstore 객체의 yield_keys() 메서드를 호출하여 반환된 키(key) 값들을 리스트로 변환합니다.\n\n\n\n코드\n# 저장소의 모든 키를 리스트로 반환합니다.\nlist(store.yield_keys())\n\n\n이제 벡터 스토어 검색 기능을 호출해 보겠습니다.\n우리가 작은 청크(chunk)들을 저장하고 있기 때문에, 검색 결과로 작은 청크들이 반환되는 것을 확인할 수 있을 것입니다.\nvectorstore 객체의 similarity_search 메서드를 사용하여 유사도 검색을 수행합니다.\n\n\n코드\n# 유사도 검색을 수행합니다.\nsub_docs = vectorstore.similarity_search(\"Word2Vec\")\n\n\nsub_docs[0].page_content를 출력합니다.\n\n\n코드\n# sub_docs 리스트의 첫 번째 요소의 page_content 속성을 출력합니다.\nprint(sub_docs[0].page_content)\n\n\n이제 전체 retriever에서 검색해 보겠습니다. 이 과정에서는 작은 청크(chunk)들이 위치한 문서를 반환 하기 때문에 상대적으로 큰 문서들이 반환될 것입니다.\nretriever 객체의 invoke() 메서드를 사용하여 쿼리와 관련된 문서를 검색합니다.\n\n\n코드\n# 문서를 검색하여 가져옵니다.\nretrieved_docs = retriever.invoke(\"Word2Vec\")\n\n\n검색된 문서(retrieved_docs[0])의 일부 내용을 출력합니다.\n\n\n코드\n# 검색된 문서의 문서의 페이지 내용의 길이를 출력합니다.\nprint(\n    f\"문서의 길이: {len(retrieved_docs[0].page_content)}\",\n    end=\"\\n\\n=====================\\n\\n\",\n)\n\n# 문서의 일부를 출력합니다.\nprint(retrieved_docs[0].page_content[2000:2500])"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/05-ParentDocumentRetriever.html#더-큰-chunk-의-크기를-조절",
    "href": "docs/blog/posts/RAG/10-Retriever/05-ParentDocumentRetriever.html#더-큰-chunk-의-크기를-조절",
    "title": "Parent Document Retriever",
    "section": "2 더 큰 Chunk 의 크기를 조절",
    "text": "2 더 큰 Chunk 의 크기를 조절\n이전의 결과처럼 전체 문서가 너무 커서 있는 그대로 검색하기에는 부적합 할 수 있습니다.\n이런 경우, 실제로 우리가 하고 싶은 것은 먼저 원시 문서를 더 큰 청크로 분할한 다음, 더 작은 청크로 분할하는 것입니다.\n그런 다음 작은 청크들을 인덱싱하지만, 검색 시에는 더 큰 청크를 검색합니다 (그러나 여전히 전체 문서는 아닙니다).\n\nRecursiveCharacterTextSplitter를 사용하여 부모 문서와 자식 문서를 생성합니다.\n\n부모 문서는 chunk_size가 1000으로 설정되어 있습니다.\n자식 문서는 chunk_size가 200으로 설정되어 있으며, 부모 문서보다 작은 크기로 생성됩니다.\n\n\n\n\n코드\n# 부모 문서를 생성하는 데 사용되는 텍스트 분할기입니다.\nparent_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n# 자식 문서를 생성하는 데 사용되는 텍스트 분할기입니다.\n# 부모보다 작은 문서를 생성해야 합니다.\nchild_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소입니다.\nvectorstore = Chroma(\n    collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings()\n)\n# 부모 문서의 저장 계층입니다.\nstore = InMemoryStore()\n\n\nParentDocumentRetriever를 초기화하는 코드입니다.\n\nvectorstore 매개변수는 문서 벡터를 저장하는 벡터 저장소를 지정합니다.\ndocstore 매개변수는 문서 데이터를 저장하는 문서 저장소를 지정합니다.\nchild_splitter 매개변수는 하위 문서를 분할하는 데 사용되는 문서 분할기를 지정합니다.\nparent_splitter 매개변수는 상위 문서를 분할하는 데 사용되는 문서 분할기를 지정합니다.\n\nParentDocumentRetriever는 계층적 문서 구조를 처리하며, 상위 문서와 하위 문서를 별도로 분할하고 저장합니다. 이를 통해 검색 시 상위 문서와 하위 문서를 효과적으로 활용할 수 있습니다.\n\n\n코드\nretriever = ParentDocumentRetriever(\n    # 벡터 저장소를 지정합니다.\n    vectorstore=vectorstore,\n    # 문서 저장소를 지정합니다.\n    docstore=store,\n    # 하위 문서 분할기를 지정합니다.\n    child_splitter=child_splitter,\n    # 상위 문서 분할기를 지정합니다.\n    parent_splitter=parent_splitter,\n)\n\n\nretriever 객체에 docs를 추가합니다. retriever가 검색할 수 있는 문서 집합에 새로운 문서들을 추가하는 역할을 합니다.\n\n\n코드\nretriever.add_documents(docs)  # 문서를 retriever에 추가합니다.\n\n\n이제 문서의 수가 훨씬 더 많아진 것을 볼 수 있습니다. 이는 더 큰 청크(chunk)들입니다.\n\n\n코드\n# 저장소에서 키를 생성하고 리스트로 변환한 후 길이를 반환합니다.\nlen(list(store.yield_keys()))\n\n\n기본 벡터 저장소가 여전히 작은 청크를 검색하는지 확인해 보겠습니다.\nvectorstore 객체의 similarity_search 메서드를 사용하여 유사도 검색을 수행합니다.\n\n\n코드\n# 유사도 검색을 수행합니다.\nsub_docs = vectorstore.similarity_search(\"Word2Vec\")\n# sub_docs 리스트의 첫 번째 요소의 page_content 속성을 출력합니다.\nprint(sub_docs[0].page_content)\n\n\n이번에는 retriever 객체의 invoke() 메서드를 사용하여 문서를 검색합니다.\n\n\n코드\n# 문서를 검색하여 가져옵니다.\nretrieved_docs = retriever.invoke(\"Word2Vec\")\n\n# 검색된 문서의 첫 번째 문서의 페이지 내용의 길이를 반환합니다.\nprint(retrieved_docs[0].page_content)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/11-CC-EnsembleRetriever.html",
    "href": "docs/blog/posts/RAG/10-Retriever/11-CC-EnsembleRetriever.html",
    "title": "Ensemble Retriever Convex Combination(CC) 추가",
    "section": "",
    "text": "written by@teddynote\n아래의 주석을 풀고 패키지를 업데이트 후 진행합니다.\n코드\n# 업데이트 후 진행\n# !pip install -qU langchain-teddynote\n코드\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nTrue"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/11-CC-EnsembleRetriever.html#실험을-위한-사전-셋업",
    "href": "docs/blog/posts/RAG/10-Retriever/11-CC-EnsembleRetriever.html#실험을-위한-사전-셋업",
    "title": "Ensemble Retriever Convex Combination(CC) 추가",
    "section": "1 실험을 위한 사전 셋업",
    "text": "1 실험을 위한 사전 셋업\n\n\n코드\nfrom langchain.retrievers import EnsembleRetriever as OriginalEnsembleRetriever\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders import PDFPlumberLoader\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_teddynote.retrievers import KiwiBM25Retriever\n\n# 문서 로드(Load Documents)\nloader = PDFPlumberLoader(\"data/디지털정부혁신 추진계획.pdf\")\n\n# 문서 분할(Split Documents): 테스트를 위하여 작은 Chunk Size로 설정\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\nsplit_documents = loader.load_and_split(text_splitter)\n\n# 임베딩(Embedding) 생성\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n\n# FaissRetriever 생성\nfaiss = FAISS.from_documents(\n    documents=split_documents, embedding=embeddings\n).as_retriever(search_kwargs={\"k\": 5})\n\n# KiwiBM25Retriever 생성(한글 형태소 분석기 + BM25 알고리즘)\nbm25 = KiwiBM25Retriever.from_documents(documents=split_documents, embedding=embeddings)\nbm25.k = 5\n\n# LangChain 버전의 EnsembleRetriever\noriginal_ensemble_retriever = OriginalEnsembleRetriever(retrievers=[faiss, bm25])\n\n\nCC 방식과 RRF 방식의 EnsembleRetriever 생성\n\n\n코드\nfrom langchain_teddynote.retrievers import (\n    EnsembleRetriever,\n    EnsembleMethod,\n)\n\n# RRF 방식의 EnsembleRetriever (기본값으로 RRF 가 설정되어 있음)\nrrf_ensemble_retriever = EnsembleRetriever(\n    retrievers=[faiss, bm25], method=EnsembleMethod.RRF\n)\n\n# CC 방식의 EnsembleRetriever\ncc_ensemble_retriever = EnsembleRetriever(\n    retrievers=[faiss, bm25], method=EnsembleMethod.CC  # method 지정: CC\n)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/11-CC-EnsembleRetriever.html#검색-결과-비교",
    "href": "docs/blog/posts/RAG/10-Retriever/11-CC-EnsembleRetriever.html#검색-결과-비교",
    "title": "Ensemble Retriever Convex Combination(CC) 추가",
    "section": "2 검색 결과 비교",
    "text": "2 검색 결과 비교\n\n\n코드\ndef pretty_print(query):\n    for i, (original_doc, cc_doc, rrf_doc) in enumerate(\n        zip(\n            original_ensemble_retriever.invoke(query),\n            cc_ensemble_retriever.invoke(query),\n            rrf_ensemble_retriever.invoke(query),\n        )\n    ):\n        print(f\"[{i}] [Original] Q: {query}\", end=\"\\n\\n\")\n        print(original_doc.page_content)\n        print(\"-\" * 100)\n        print(f\"[{i}] [RRF] Q: {query}\", end=\"\\n\\n\")\n        print(rrf_doc.page_content)\n        print(\"-\" * 100)\n        print(f\"[{i}] [CC] Q: {query}\", end=\"\\n\\n\")\n        print(cc_doc.page_content)\n        print(\"=\" * 100, end=\"\\n\\n\")\n\n\n\n검색 결과에 \"Original\" 과 \"RRF\" 는 차이가 없어야 합니다. (LangChain 그대로 구현)\n검색 결과에 \"CC\" 는 \"RRF\" 와 차이가 있을 수 있습니다.\n\nRRF 와 CC 방식의 검색 결과 비교하여 문서에 적합한 방식을 차용하시길 바랍니다.\n\n\n코드\n# 검색 결과 비교\npretty_print(\"디지털 트랜스포메이션이란 무엇인가요?\")\n\n\n[0] [Original] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n참고 1 디지털 정부혁신 추진전략\n디지털로 여는 좋은 세상\n□ 비전\n※ 부제 : 대한민국이 먼저 갑니다.\n□ 추진원칙 △ 최종 이용자의 관점에서\n△ 공공서비스 수준 향상을 목표로\n----------------------------------------------------------------------------------------------------\n[0] [RRF] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n참고 1 디지털 정부혁신 추진전략\n디지털로 여는 좋은 세상\n□ 비전\n※ 부제 : 대한민국이 먼저 갑니다.\n□ 추진원칙 △ 최종 이용자의 관점에서\n△ 공공서비스 수준 향상을 목표로\n----------------------------------------------------------------------------------------------------\n[0] [CC] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n○ (시스템) 디지털 신기술의 적기 도입과 활용 곤란\n- 기존 복잡한 용역개발 방식은 혁신주기가 짧은 디지털 전환에 부적합\n====================================================================================================\n\n[1] [Original] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n○ (시스템) 디지털 신기술의 적기 도입과 활용 곤란\n- 기존 복잡한 용역개발 방식은 혁신주기가 짧은 디지털 전환에 부적합\n----------------------------------------------------------------------------------------------------\n[1] [RRF] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n○ (시스템) 디지털 신기술의 적기 도입과 활용 곤란\n- 기존 복잡한 용역개발 방식은 혁신주기가 짧은 디지털 전환에 부적합\n----------------------------------------------------------------------------------------------------\n[1] [CC] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n○ (디지털 고지‧수납) 각종 고지서·안내문* 등을 온라인(공공‧민간)\n으로 받고, 간편하게 납부할 수 있도록 디지털 고지‧수납 활성화\n====================================================================================================\n\n[2] [Original] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\nⅠ. 개 요\n□ 추진 배경\n○ 우리나라는 국가적 초고속 정보통신망 투자와 적극적인 공공정보화\n사업 추진에 힘입어 세계 최고수준의 전자정부를 구축‧운영\n----------------------------------------------------------------------------------------------------\n[2] [RRF] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\nⅠ. 개 요\n□ 추진 배경\n○ 우리나라는 국가적 초고속 정보통신망 투자와 적극적인 공공정보화\n사업 추진에 힘입어 세계 최고수준의 전자정부를 구축‧운영\n----------------------------------------------------------------------------------------------------\n[2] [CC] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n참고 1 디지털 정부혁신 추진전략\n디지털로 여는 좋은 세상\n□ 비전\n※ 부제 : 대한민국이 먼저 갑니다.\n□ 추진원칙 △ 최종 이용자의 관점에서\n△ 공공서비스 수준 향상을 목표로\n====================================================================================================\n\n[3] [Original] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n○ (디지털 고지‧수납) 각종 고지서·안내문* 등을 온라인(공공‧민간)\n으로 받고, 간편하게 납부할 수 있도록 디지털 고지‧수납 활성화\n----------------------------------------------------------------------------------------------------\n[3] [RRF] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n○ (디지털 고지‧수납) 각종 고지서·안내문* 등을 온라인(공공‧민간)\n으로 받고, 간편하게 납부할 수 있도록 디지털 고지‧수납 활성화\n----------------------------------------------------------------------------------------------------\n[3] [CC] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n○ 오픈소스 중심의 디지털정부 생태계와 공공시장 수요를 바탕으로\n첨단 디지털 산업의 혁신 가속화와 글로벌 도약을 위한 전기 마련\n====================================================================================================\n\n[4] [Original] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n보다 안정성‧편의성이 높은 스마트폰 기반 디지털 신분증 도입\n* 학생증, 공무원증 등 이용대상과 목적이 명확한 분야부터 안전성 점검 후 단계적 확대\n----------------------------------------------------------------------------------------------------\n[4] [RRF] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n보다 안정성‧편의성이 높은 스마트폰 기반 디지털 신분증 도입\n* 학생증, 공무원증 등 이용대상과 목적이 명확한 분야부터 안전성 점검 후 단계적 확대\n----------------------------------------------------------------------------------------------------\n[4] [CC] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n디지털 정부혁신 추진계획\n2019. 10. 29.\n관계부처 합동\n====================================================================================================\n\n[5] [Original] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n○ 오픈소스 중심의 디지털정부 생태계와 공공시장 수요를 바탕으로\n첨단 디지털 산업의 혁신 가속화와 글로벌 도약을 위한 전기 마련\n----------------------------------------------------------------------------------------------------\n[5] [RRF] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n○ 오픈소스 중심의 디지털정부 생태계와 공공시장 수요를 바탕으로\n첨단 디지털 산업의 혁신 가속화와 글로벌 도약을 위한 전기 마련\n----------------------------------------------------------------------------------------------------\n[5] [CC] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\nⅠ. 개 요\n□ 추진 배경\n○ 우리나라는 국가적 초고속 정보통신망 투자와 적극적인 공공정보화\n사업 추진에 힘입어 세계 최고수준의 전자정부를 구축‧운영\n====================================================================================================\n\n[6] [Original] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n디지털기기 사용이 어려운 분들이 차별없이 서비스를 받도록 지원하겠습니다.\n권익위,\n□1 국민의 소리 청취·분석 시스템 개선 (22년)\n각부처·지자체\n----------------------------------------------------------------------------------------------------\n[6] [RRF] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n디지털기기 사용이 어려운 분들이 차별없이 서비스를 받도록 지원하겠습니다.\n권익위,\n□1 국민의 소리 청취·분석 시스템 개선 (22년)\n각부처·지자체\n----------------------------------------------------------------------------------------------------\n[6] [CC] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n보다 안정성‧편의성이 높은 스마트폰 기반 디지털 신분증 도입\n* 학생증, 공무원증 등 이용대상과 목적이 명확한 분야부터 안전성 점검 후 단계적 확대\n====================================================================================================\n\n[7] [Original] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n디지털 정부혁신 추진계획\n2019. 10. 29.\n관계부처 합동\n----------------------------------------------------------------------------------------------------\n[7] [RRF] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n디지털 정부혁신 추진계획\n2019. 10. 29.\n관계부처 합동\n----------------------------------------------------------------------------------------------------\n[7] [CC] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n디지털기기 사용이 어려운 분들이 차별없이 서비스를 받도록 지원하겠습니다.\n권익위,\n□1 국민의 소리 청취·분석 시스템 개선 (22년)\n각부처·지자체\n====================================================================================================\n\n[8] [Original] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n참고 3 디지털 정부혁신 기대효과\n◈ 동 방안을 성공적으로 추진하는 경우, 정부 디지털 서비스에서 세계 최고\n----------------------------------------------------------------------------------------------------\n[8] [RRF] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n참고 3 디지털 정부혁신 기대효과\n◈ 동 방안을 성공적으로 추진하는 경우, 정부 디지털 서비스에서 세계 최고\n----------------------------------------------------------------------------------------------------\n[8] [CC] Q: 디지털 트랜스포메이션이란 무엇인가요?\n\n참고 3 디지털 정부혁신 기대효과\n◈ 동 방안을 성공적으로 추진하는 경우, 정부 디지털 서비스에서 세계 최고\n===================================================================================================="
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/10-Kiwi-BM25Retriever.html",
    "href": "docs/blog/posts/RAG/10-Retriever/10-Kiwi-BM25Retriever.html",
    "title": "한글 단어 리트리버 튜닝",
    "section": "",
    "text": "한글 형태소 분석기 라이브러리인 kiwipiepy 를 설치합니다. - kiwipiepy 프로젝트 링크\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n\n\nTrue\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH10-Retriever\")\n\n\nLangSmith 추적을 시작합니다.\n[프로젝트명]\nCH10-Retriever\n코드\n# !pip install kiwipiepy\n코드\nfrom kiwipiepy import Kiwi\n\nkiwi = Kiwi()\n토큰화를 진행합니다.\n코드\nkiwi.tokenize(\"안녕하세요? 형태소 분석기 키위입니다\")\n\n\n[Token(form='안녕', tag='NNG', start=0, len=2),\n Token(form='하', tag='XSA', start=2, len=1),\n Token(form='세요', tag='EF', start=3, len=2),\n Token(form='?', tag='SF', start=5, len=1),\n Token(form='형태소', tag='NNG', start=7, len=3),\n Token(form='분석기', tag='NNG', start=11, len=3),\n Token(form='키위', tag='NNG', start=15, len=2),\n Token(form='이', tag='VCP', start=17, len=1),\n Token(form='ᆸ니다', tag='EF', start=17, len=3)]"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/10-Kiwi-BM25Retriever.html#다양한-문장으로-테스트",
    "href": "docs/blog/posts/RAG/10-Retriever/10-Kiwi-BM25Retriever.html#다양한-문장으로-테스트",
    "title": "한글 단어 리트리버 튜닝",
    "section": "1 다양한 문장으로 테스트",
    "text": "1 다양한 문장으로 테스트\n\n\n코드\nfrom langchain.retrievers import EnsembleRetriever\nfrom langchain_community.retrievers import BM25Retriever\nfrom langchain_core.documents import Document\nfrom langchain.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\n\ndocs = [\n    Document(\n        page_content=\"금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\"\n    ),\n    Document(\n        page_content=\"금융저축보험은 규칙적인 저축을 통해 목돈을 마련할 수 있으며, 생명보험 기능도 겸비하고 있습니다.\"\n    ),\n    Document(\n        page_content=\"저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\"\n    ),\n    Document(\n        page_content=\"금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\"\n    ),\n    Document(\n        page_content=\"금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\"\n    ),\n    Document(\n        page_content=\"금보험은 저축성과를 극대화합니다. 특히 노후 대비 저축에 유리하게 구성되어 있습니다.\"\n    ),\n    Document(\n        page_content=\"금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\"\n    ),\n]\n\n\n\n\n코드\nfor doc in docs:\n    print(\" \".join([token.form for token in kiwi.tokenize(doc.page_content)]))\n\n\n금융 보험 은 장기 적 이 ᆫ 자산 관리 와 위험 대비 를 목적 으로 고안 되 ᆫ 금융 상품 이 ᆸ니다 .\n금융 저축 보험 은 규칙 적 이 ᆫ 저축 을 통하 어 목돈 을 마련 하 ᆯ 수 있 으며 , 생명 보험 기능 도 겸비 하 고 있 습니다 .\n저축 금융 보험 은 저축 과 금융 을 통하 어 목돈 마련 에 도움 을 주 는 보험 이 ᆸ니다 . 또한 , 사망 보장 기능 도 제공 하 ᆸ니다 .\n금융 저 축산물 보험 은 장기 적 이 ᆫ 저축 목적 과 더불 어 , 축산물 제공 기능 을 갖추 고 있 는 특별 금융 상품 이 ᆸ니다 .\n금융 단 폭격 보험 은 저축 은 커녕 위험 대비 에 초점 을 맞추 ᆫ 상품 이 ᆸ니다 . 높 은 위험 을 감수 하 고자 하 는 고객 에게 적합 하 ᆸ니다 .\n금 보험 은 저축 성과 를 극대 화 하 ᆸ니다 . 특히 노후 대비 저축 에 유리 하 게 구성 되 어 있 습니다 .\n금융 보 씨 험하 ᆫ 말 좀 하 지 말 시 고 , 저축 이나 좀 하 시 던가요 . 뭐 가 그리 급하 시 ᆫ지 모르 겠 네요 .\n\n\n\n\n코드\n# 토큰화 함수를 생성\ndef kiwi_tokenize(text):\n    return [token.form for token in kiwi.tokenize(text)]\n\n\n\n1.1 실험: 다양한 종류의 검색기를 사용하여 검색 결과를 비교\n\n\n코드\nbm25 = BM25Retriever.from_documents(docs)\n\nkiwi_bm25 = BM25Retriever.from_documents(docs, preprocess_func=kiwi_tokenize)\n\nfaiss = FAISS.from_documents(docs, OpenAIEmbeddings()).as_retriever()\n\nbm25_faiss_73 = EnsembleRetriever(\n    retrievers=[bm25, faiss],  # 사용할 검색 모델의 리스트\n    weights=[0.7, 0.3],  # 각 검색 모델의 결과에 적용할 가중치\n    search_type=\"mmr\",  # 검색 결과의 다양성을 증진시키는 MMR 방식을 사용\n)\nbm25_faiss_37 = EnsembleRetriever(\n    retrievers=[bm25, faiss],  # 사용할 검색 모델의 리스트\n    weights=[0.3, 0.7],  # 각 검색 모델의 결과에 적용할 가중치\n    search_type=\"mmr\",  # 검색 결과의 다양성을 증진시키는 MMR 방식을 사용\n)\nkiwibm25_faiss_73 = EnsembleRetriever(\n    retrievers=[kiwi_bm25, faiss],  # 사용할 검색 모델의 리스트\n    weights=[0.7, 0.3],  # 각 검색 모델의 결과에 적용할 가중치\n    search_type=\"mmr\",  # 검색 결과의 다양성을 증진시키는 MMR 방식을 사용\n)\nkiwibm25_faiss_37 = EnsembleRetriever(\n    retrievers=[kiwi_bm25, faiss],  # 사용할 검색 모델의 리스트\n    weights=[0.3, 0.7],  # 각 검색 모델의 결과에 적용할 가중치\n    search_type=\"mmr\",  # 검색 결과의 다양성을 증진시키는 MMR 방식을 사용\n)\n\nretrievers = {\n    \"bm25\": bm25,\n    \"kiwi_bm25\": kiwi_bm25,\n    \"faiss\": faiss,\n    \"bm25_faiss_73\": bm25_faiss_73,\n    \"bm25_faiss_37\": bm25_faiss_37,\n    \"kiwi_bm25_faiss_73\": kiwibm25_faiss_73,\n    \"kiwi_bm25_faiss_37\": kiwibm25_faiss_37,\n}\n\n\n\n\n코드\ndef print_search_results(retrievers, query):\n    print(f\"Query: {query}\")\n    for name, retriever in retrievers.items():\n        print(f\"{name}    \\t: {retriever.invoke(query)[0].page_content}\")\n    print(\"===\" * 20)\n\n\n검색 결과를 출력합니다.\n\n\n코드\nprint_search_results(retrievers, \"금융보험\")\nprint_search_results(retrievers, \"금융 보험\")\nprint_search_results(retrievers, \"금융저축보험\")\nprint_search_results(retrievers, \"축산물 보험\")\nprint_search_results(retrievers, \"저축금융보험\")\nprint_search_results(retrievers, \"금융보씨 개인정보 조회\")\n\n\nQuery: 금융보험\nbm25        : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nkiwi_bm25       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nfaiss       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nbm25_faiss_73       : 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\nbm25_faiss_37       : 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\nkiwi_bm25_faiss_73      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkiwi_bm25_faiss_37      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\n============================================================\nQuery: 금융 보험\nbm25        : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkiwi_bm25       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nfaiss       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nbm25_faiss_73       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nbm25_faiss_37       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkiwi_bm25_faiss_73      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkiwi_bm25_faiss_37      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\n============================================================\nQuery: 금융저축보험\nbm25        : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nkiwi_bm25       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nfaiss       : 금융저축보험은 규칙적인 저축을 통해 목돈을 마련할 수 있으며, 생명보험 기능도 겸비하고 있습니다.\nbm25_faiss_73       : 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\nbm25_faiss_37       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nkiwi_bm25_faiss_73      : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nkiwi_bm25_faiss_37      : 금융저축보험은 규칙적인 저축을 통해 목돈을 마련할 수 있으며, 생명보험 기능도 겸비하고 있습니다.\n============================================================\nQuery: 축산물 보험\nbm25        : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nkiwi_bm25       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nfaiss       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nbm25_faiss_73       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nbm25_faiss_37       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nkiwi_bm25_faiss_73      : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nkiwi_bm25_faiss_37      : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\n============================================================\nQuery: 저축금융보험\nbm25        : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nkiwi_bm25       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nfaiss       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nbm25_faiss_73       : 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\nbm25_faiss_37       : 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\nkiwi_bm25_faiss_73      : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nkiwi_bm25_faiss_37      : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\n============================================================\nQuery: 금융보씨 개인정보 조회\nbm25        : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nkiwi_bm25       : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nfaiss       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nbm25_faiss_73       : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nbm25_faiss_37       : 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\nkiwi_bm25_faiss_73      : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nkiwi_bm25_faiss_37      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\n============================================================"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/10-Kiwi-BM25Retriever.html#konlpy",
    "href": "docs/blog/posts/RAG/10-Retriever/10-Kiwi-BM25Retriever.html#konlpy",
    "title": "한글 단어 리트리버 튜닝",
    "section": "2 Konlpy",
    "text": "2 Konlpy\n\n\n코드\n# !pip install konlpy\n\n\n\n\n코드\nfrom konlpy.tag import Kkma, Okt, Komoran, Hannanum\nfrom kiwipiepy import Kiwi\n\nkkma = Kkma()\nokt = Okt()\nkomoran = Komoran()\nhannanum = Hannanum()\nkiwi = Kiwi()\n\n\n\n\n코드\ntext = \"안녕하세요? 형태소 분석기 테스트베드입니다.\"\n\n\n\n\n코드\nprint(\"kkma    : \\t\", end=\"\")\nprint(\" \".join(kkma.morphs(text)))\nprint(\"okt     : \\t\", end=\"\")\nprint(\" \".join(okt.morphs(text)))\nprint(\"komoran : \\t\", end=\"\")\nprint(\" \".join(komoran.morphs(text)))\nprint(\"hannanum: \\t\", end=\"\")\nprint(\" \".join(hannanum.morphs(text)))\nprint(\"kiwi    : \\t\", end=\"\")\nprint(\" \".join([tok.form for tok in kiwi.tokenize(text)]))\n\n\nkkma    :   안녕 하 세요 ? 형태소 분석기 테스트 베드 이 ㅂ니다 .\nokt     :   안녕하세요 ? 형태소 분석 기 테스트 베드 입니다 .\nkomoran :   안녕하세요 ? 형태소 분석기 테스트 베드 이 ㅂ니다 .\nhannanum:   안녕 하 세 요 ? 형태소 분석기 테스트베드 이 ㅂ니다 .\nkiwi    :   안녕 하 세요 ? 형태소 분석기 테스트 베드 이 ᆸ니다 .\n\n\n\n\n코드\nkiwi.add_user_word(\"안녕하세요 반가워요\", \"NNP\", 0)\n\n\nTrue\n\n\n\n\n코드\nprint(\"kiwi    : \\t\", end=\"\")\nprint(\" \".join([tok.form for tok in kiwi.tokenize(text)]))\n\n\nkiwi    :   안녕 하 세요 ? 형태소 분석기 테스트 베드 이 ᆸ니다 .\n\n\n\n\n코드\ndef kkma_tokenize(text):\n    return [token for token in kkma.morphs(text)]\n\n\n\n\n코드\ndef okt_tokenize(text):\n    return [token for token in okt.morphs(text)]\n\n\n\n\n코드\nkkma_bm25 = BM25Retriever.from_documents(docs, preprocess_func=kkma_tokenize)\nkkma_bm25_faiss_73 = EnsembleRetriever(\n    retrievers=[kkma_bm25, faiss],  # 사용할 검색 모델의 리스트\n    weights=[0.7, 0.3],  # 각 검색 모델의 결과에 적용할 가중치\n    search_type=\"mmr\",  # 검색 결과의 다양성을 증진시키는 MMR 방식을 사용\n)\nkkma_bm25_faiss_37 = EnsembleRetriever(\n    retrievers=[kkma_bm25, faiss],  # 사용할 검색 모델의 리스트\n    weights=[0.3, 0.7],  # 각 검색 모델의 결과에 적용할 가중치\n    search_type=\"mmr\",  # 검색 결과의 다양성을 증진시키는 MMR 방식을 사용\n)\n\nokt_bm25 = BM25Retriever.from_documents(docs, preprocess_func=okt_tokenize)\nokt_bm25_faiss_73 = EnsembleRetriever(\n    retrievers=[okt_bm25, faiss],  # 사용할 검색 모델의 리스트\n    weights=[0.7, 0.3],  # 각 검색 모델의 결과에 적용할 가중치\n    search_type=\"mmr\",  # 검색 결과의 다양성을 증진시키는 MMR 방식을 사용\n)\nokt_bm25_faiss_37 = EnsembleRetriever(\n    retrievers=[okt_bm25, faiss],  # 사용할 검색 모델의 리스트\n    weights=[0.3, 0.7],  # 각 검색 모델의 결과에 적용할 가중치\n    search_type=\"mmr\",  # 검색 결과의 다양성을 증진시키는 MMR 방식을 사용\n)\n\nretrievers = {\n    \"bm25\": bm25,\n    \"kiwi_bm25\": kiwi_bm25,\n    \"faiss\": faiss,\n    \"bm25_faiss_73\": bm25_faiss_73,\n    \"bm25_faiss_37\": bm25_faiss_37,\n    \"kiwi_bm25_faiss_73\": kiwibm25_faiss_73,\n    \"kiwi_bm25_faiss_37\": kiwibm25_faiss_37,\n    \"kkma_bm25\": kkma_bm25,\n    \"kkma_bm25_faiss_73\": kkma_bm25_faiss_73,\n    \"kkma_bm25_faiss_37\": kkma_bm25_faiss_37,\n    \"okt_bm25\": okt_bm25,\n    \"okt_bm25_faiss_73\": okt_bm25_faiss_73,\n    \"okt_bm25_faiss_37\": okt_bm25_faiss_37,\n}\n\n\n\n\n코드\nprint_search_results(retrievers, \"금융보험\")\nprint_search_results(retrievers, \"금융 보험\")\nprint_search_results(retrievers, \"금융저축보험\")\nprint_search_results(retrievers, \"축산물 보험\")\nprint_search_results(retrievers, \"저축금융보험\")\nprint_search_results(retrievers, \"금융보씨 개인정보 조회\")\n\n\nQuery: 금융보험\nbm25        : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nkiwi_bm25       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nfaiss       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nbm25_faiss_73       : 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\nbm25_faiss_37       : 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\nkiwi_bm25_faiss_73      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkiwi_bm25_faiss_37      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkkma_bm25       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nkkma_bm25_faiss_73      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkkma_bm25_faiss_37      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nokt_bm25        : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nokt_bm25_faiss_73       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nokt_bm25_faiss_37       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\n============================================================\nQuery: 금융 보험\nbm25        : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkiwi_bm25       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nfaiss       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nbm25_faiss_73       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nbm25_faiss_37       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkiwi_bm25_faiss_73      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkiwi_bm25_faiss_37      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkkma_bm25       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nkkma_bm25_faiss_73      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkkma_bm25_faiss_37      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nokt_bm25        : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nokt_bm25_faiss_73       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nokt_bm25_faiss_37       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\n============================================================\nQuery: 금융저축보험\nbm25        : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nkiwi_bm25       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nfaiss       : 금융저축보험은 규칙적인 저축을 통해 목돈을 마련할 수 있으며, 생명보험 기능도 겸비하고 있습니다.\nbm25_faiss_73       : 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\nbm25_faiss_37       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nkiwi_bm25_faiss_73      : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nkiwi_bm25_faiss_37      : 금융저축보험은 규칙적인 저축을 통해 목돈을 마련할 수 있으며, 생명보험 기능도 겸비하고 있습니다.\nkkma_bm25       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nkkma_bm25_faiss_73      : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nkkma_bm25_faiss_37      : 금융저축보험은 규칙적인 저축을 통해 목돈을 마련할 수 있으며, 생명보험 기능도 겸비하고 있습니다.\nokt_bm25        : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nokt_bm25_faiss_73       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nokt_bm25_faiss_37       : 금융저축보험은 규칙적인 저축을 통해 목돈을 마련할 수 있으며, 생명보험 기능도 겸비하고 있습니다.\n============================================================\nQuery: 축산물 보험\nbm25        : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nkiwi_bm25       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nfaiss       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nbm25_faiss_73       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nbm25_faiss_37       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nkiwi_bm25_faiss_73      : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nkiwi_bm25_faiss_37      : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nkkma_bm25       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nkkma_bm25_faiss_73      : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nkkma_bm25_faiss_37      : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nokt_bm25        : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nokt_bm25_faiss_73       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\nokt_bm25_faiss_37       : 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\n============================================================\nQuery: 저축금융보험\nbm25        : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nkiwi_bm25       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nfaiss       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nbm25_faiss_73       : 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\nbm25_faiss_37       : 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\nkiwi_bm25_faiss_73      : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nkiwi_bm25_faiss_37      : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nkkma_bm25       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nkkma_bm25_faiss_73      : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nkkma_bm25_faiss_37      : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nokt_bm25        : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nokt_bm25_faiss_73       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\nokt_bm25_faiss_37       : 저축금융보험은 저축과 금융을 통해 목돈 마련에 도움을 주는 보험입니다. 또한, 사망 보장 기능도 제공합니다.\n============================================================\nQuery: 금융보씨 개인정보 조회\nbm25        : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nkiwi_bm25       : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nfaiss       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nbm25_faiss_73       : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nbm25_faiss_37       : 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\nkiwi_bm25_faiss_73      : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nkiwi_bm25_faiss_37      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nkkma_bm25       : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nkkma_bm25_faiss_73      : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nkkma_bm25_faiss_37      : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\nokt_bm25        : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nokt_bm25_faiss_73       : 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\nokt_bm25_faiss_37       : 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\n============================================================"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/01-VectorStoreRetriever.html",
    "href": "docs/blog/posts/RAG/10-Retriever/01-VectorStoreRetriever.html",
    "title": "벡터스토어 기반 검색기(VectorStore-backed Retriever)",
    "section": "",
    "text": "VectorStore 지원 검색기 는 vector store를 사용하여 문서를 검색하는 retriever입니다.\nVector store에 구현된 유사도 검색(similarity search) 이나 MMR 과 같은 검색 메서드를 사용하여 vector store 내의 텍스트를 쿼리합니다.\n아래의 코드를 실행하여 VectorStore 를 생성합니다.\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH10-Retriever\")\n코드\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import CharacterTextSplitter\nfrom langchain_community.document_loaders import TextLoader\n\n# TextLoader를 사용하여 파일을 로드합니다.\nloader = TextLoader(\"./data/appendix-keywords.txt\")\n\n# 문서를 로드합니다.\ndocuments = loader.load()\n\n# 문자 기반으로 텍스트를 분할하는 CharacterTextSplitter를 생성합니다. 청크 크기는 300이고 청크 간 중복은 없습니다.\ntext_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n\n# 로드된 문서를 분할합니다.\nsplit_docs = text_splitter.split_documents(documents)\n\n# OpenAI 임베딩을 생성합니다.\nembeddings = OpenAIEmbeddings()\n\n# 분할된 텍스트와 임베딩을 사용하여 FAISS 벡터 데이터베이스를 생성합니다.\ndb = FAISS.from_documents(split_docs, embeddings)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/01-VectorStoreRetriever.html#동적-설정configurable",
    "href": "docs/blog/posts/RAG/10-Retriever/01-VectorStoreRetriever.html#동적-설정configurable",
    "title": "벡터스토어 기반 검색기(VectorStore-backed Retriever)",
    "section": "1 동적 설정(Configurable)",
    "text": "1 동적 설정(Configurable)\n\n검색 설정을 동적으로 조정하기 위해 ConfigurableField 를 사용합니다.\nConfigurableField 는 검색 매개변수의 고유 식별자, 이름, 설명을 설정하는 역할을 합니다.\n검색 설정을 조정하기 위해 config 매개변수를 사용하여 검색 설정을 지정합니다.\n검색 설정은 config 매개변수에 전달된 딕셔너리의 configurable 키에 저장됩니다.\n검색 설정은 검색 쿼리와 함께 전달되며, 검색 쿼리에 따라 동적으로 조정됩니다.\n\n\n\n코드\nfrom langchain_core.runnables import ConfigurableField\n\n# k 설정\nretriever = db.as_retriever(search_kwargs={\"k\": 1}).configurable_fields(\n    search_type=ConfigurableField(\n        id=\"search_type\",\n        name=\"Search Type\",\n        description=\"The search type to use\",\n    ),\n    search_kwargs=ConfigurableField(\n        # 검색 매개변수의 고유 식별자를 설정\n        id=\"search_kwargs\",\n        # 검색 매개변수의 이름을 설정\n        name=\"Search Kwargs\",\n        # 검색 매개변수에 대한 설명을 작성\n        description=\"The search kwargs to use\",\n    ),\n)\n\n\n아래는 동적 검색설정을 적용한 예시입니다.\n\n\n코드\n# 검색 설정을 지정. Faiss 검색에서 k=3로 설정하여 가장 유사한 문서 3개를 반환\nconfig = {\"configurable\": {\"search_kwargs\": {\"k\": 3}}}\n\n# 관련 문서를 검색\ndocs = retriever.invoke(\"임베딩(Embedding)은 무엇인가요?\", config=config)\n\n# 관련 문서를 검색\nfor doc in docs:\n    print(doc.page_content)\n    print(\"=========================================================\")\n\n\n\n\n코드\n# 검색 설정을 지정. score_threshold 0.8 이상의 점수를 가진 문서만 반환\nconfig = {\n    \"configurable\": {\n        \"search_type\": \"similarity_score_threshold\",\n        \"search_kwargs\": {\n            \"score_threshold\": 0.8,\n        },\n    }\n}\n\n# 관련 문서를 검색\ndocs = retriever.invoke(\"Word2Vec 은 무엇인가요?\", config=config)\n\n# 관련 문서를 검색\nfor doc in docs:\n    print(doc.page_content)\n    print(\"=========================================================\")\n\n\n\n\n코드\n# 검색 설정을 지정. mmr 검색 설정.\nconfig = {\n    \"configurable\": {\n        \"search_type\": \"mmr\",\n        \"search_kwargs\": {\"k\": 2, \"fetch_k\": 10, \"lambda_mult\": 0.6},\n    }\n}\n\n# 관련 문서를 검색\ndocs = retriever.invoke(\"Word2Vec 은 무엇인가요?\", config=config)\n\n# 관련 문서를 검색\nfor doc in docs:\n    print(doc.page_content)\n    print(\"=========================================================\")"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/01-VectorStoreRetriever.html#upstage-임베딩과-같이-query-passage-embedding-model-이-분리된-경우",
    "href": "docs/blog/posts/RAG/10-Retriever/01-VectorStoreRetriever.html#upstage-임베딩과-같이-query-passage-embedding-model-이-분리된-경우",
    "title": "벡터스토어 기반 검색기(VectorStore-backed Retriever)",
    "section": "2 Upstage 임베딩과 같이 Query & Passage embedding model 이 분리된 경우",
    "text": "2 Upstage 임베딩과 같이 Query & Passage embedding model 이 분리된 경우\n기본 retriever는 쿼리와 문서에 대해 동일한 임베딩 모델을 사용합니다.\n하지만 쿼리와 문서에 대해 서로 다른 임베딩 모델을 사용하는 경우가 있습니다.\n이러한 경우에는 쿼리 임베딩 모델을 사용하여 쿼리를 임베딩하고, 문서 임베딩 모델을 사용하여 문서를 임베딩합니다.\n이렇게 하면 쿼리와 문서에 대해 서로 다른 임베딩 모델을 사용할 수 있습니다.\n\n\n코드\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_text_splitters import CharacterTextSplitter\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_upstage import UpstageEmbeddings\n\n# TextLoader를 사용하여 파일을 로드합니다.\nloader = TextLoader(\"./data/appendix-keywords.txt\")\n\n# 문서를 로드합니다.\ndocuments = loader.load()\n\n# 문자 기반으로 텍스트를 분할하는 CharacterTextSplitter를 생성합니다. 청크 크기는 300이고 청크 간 중복은 없습니다.\ntext_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n\n# 로드된 문서를 분할합니다.\nsplit_docs = text_splitter.split_documents(documents)\n\n# Upstage 임베딩을 생성합니다. 문서용 모델을 사용합니다.\ndoc_embedder = UpstageEmbeddings(model=\"solar-embedding-1-large-passage\")\n\n# 분할된 텍스트와 임베딩을 사용하여 FAISS 벡터 데이터베이스를 생성합니다.\ndb = FAISS.from_documents(split_docs, doc_embedder)\n\n\n아래는 쿼리용 Upstage 임베딩을 생성하고, 쿼리 문장을 벡터로 변환하여 벡터 유사도 검색을 수행하는 예시입니다.\n\n\n코드\n# 쿼리용 Upstage 임베딩을 생성합니다. 쿼리용 모델을 사용합니다.\nquery_embedder = UpstageEmbeddings(model=\"solar-embedding-1-large-query\")\n\n# 쿼리 문장을 벡터로 변환합니다.\nquery_vector = query_embedder.embed_query(\"임베딩(Embedding)은 무엇인가요?\")\n\n# 벡터 유사도 검색을 수행하여 가장 유사한 2개의 문서를 반환합니다.\ndb.similarity_search_by_vector(query_vector, k=2)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/07-MultiVectorRetriever.html",
    "href": "docs/blog/posts/RAG/10-Retriever/07-MultiVectorRetriever.html",
    "title": "다중 벡터저장소 검색기(MultiVectorRetriever)",
    "section": "",
    "text": "LangChain에서는 문서를 다양한 상황에서 효율적으로 쿼리할 수 있는 특별한 기능, 바로 MultiVectorRetriever를 제공합니다. 이 기능을 사용하면 문서를 여러 벡터로 저장하고 관리할 수 있어, 정보 검색의 정확도와 효율성을 대폭 향상시킬 수 있습니다.\nMultiVectorRetriever를 활용해 문서당 여러 벡터를 생성하는 몇 가지 방법을 살펴보겠습니다.\n문서당 여러 벡터 생성 방법 소개"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/07-MultiVectorRetriever.html#실습에-활용한-문서",
    "href": "docs/blog/posts/RAG/10-Retriever/07-MultiVectorRetriever.html#실습에-활용한-문서",
    "title": "다중 벡터저장소 검색기(MultiVectorRetriever)",
    "section": "1 실습에 활용한 문서",
    "text": "1 실습에 활용한 문서\n소프트웨어정책연구소(SPRi) - 2023년 12월호\n\n저자: 유재흥(AI정책연구실 책임연구원), 이지수(AI정책연구실 위촉연구원)\n링크: https://spri.kr/posts/view/23669\n파일명: SPRI_AI_Brief_2023년12월호_F.pdf\n\n참고: 위의 파일은 data 폴더 내에 다운로드 받으세요\n\n\n코드\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n\n\n\n\n코드\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH10-Retriever\")\n\n\n텍스트 파일에서 데이터를 로드하고, 로드된 문서들을 지정된 크기로 분할하는 전처리 과정을 수행합니다.\n분할된 문서들은 추후 벡터화 및 검색 등의 작업에 사용될 수 있습니다.\n\n\n코드\nfrom langchain_community.document_loaders import PyMuPDFLoader\n\nloader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\ndocs = loader.load()\n\n\n데이터로부터 로드한 원본 도큐먼트는 docs 변수에 담았습니다.\n\n\n코드\nprint(docs[5].page_content[:500])"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/07-MultiVectorRetriever.html#chunk-원본-문서-검색",
    "href": "docs/blog/posts/RAG/10-Retriever/07-MultiVectorRetriever.html#chunk-원본-문서-검색",
    "title": "다중 벡터저장소 검색기(MultiVectorRetriever)",
    "section": "2 Chunk + 원본 문서 검색",
    "text": "2 Chunk + 원본 문서 검색\n대용량 정보를 검색하는 경우, 더 작은 단위로 정보를 임베딩하는 것이 유용할 수 있습니다.\nMultiVectorRetriever 를 통해 문서를 여러 벡터로 저장하고 관리할 수 있습니다.\ndocstore 에 원본 문서를 저장하고, vectorstore 에 임베딩된 문서를 저장합니다.\n이로써 문서를 더 작은 단위로 나누어 더 정확한 검색이 가능해집니다. 때에 따라서는 원본 문서의 내용을 조회할 수 있습니다.\n\n\n코드\n# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소\nimport uuid\nfrom langchain.storage import InMemoryStore\nfrom langchain_chroma import Chroma\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain.retrievers.multi_vector import MultiVectorRetriever\n\nvectorstore = Chroma(\n    collection_name=\"small_bigger_chunks\",\n    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n)\n# 부모 문서의 저장소 계층\nstore = InMemoryStore()\n\nid_key = \"doc_id\"\n\n# 검색기 (시작 시 비어 있음)\nretriever = MultiVectorRetriever(\n    vectorstore=vectorstore,\n    byte_store=store,\n    id_key=id_key,\n)\n\n# 문서 ID를 생성합니다.\ndoc_ids = [str(uuid.uuid4()) for _ in docs]\n\n# 두개의 생성된 id를 확인합니다.\ndoc_ids\n\n\n여기서 큰 청크로 분할하기 위한 parent_text_splitter\n더 작은 청크로 분할하기 위한 child_text_splitter 를 정의합니다.\n\n\n코드\n# RecursiveCharacterTextSplitter 객체를 생성합니다.\nparent_text_splitter = RecursiveCharacterTextSplitter(chunk_size=600)\n\n# 더 작은 청크를 생성하는 데 사용할 분할기\nchild_text_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n\n\n더 큰 Chunk인 Parent 문서를 생성합니다.\n\n\n코드\nparent_docs = []\n\nfor i, doc in enumerate(docs):\n    # 현재 문서의 ID를 가져옵니다.\n    _id = doc_ids[i]\n    # 현재 문서를 하위 문서로 분할\n    parent_doc = parent_text_splitter.split_documents([doc])\n\n    for _doc in parent_doc:\n        # metadata에 문서 ID 를 저장\n        _doc.metadata[id_key] = _id\n    parent_docs.extend(parent_doc)\n\n\nparent_docs 에 기입된 doc_id 를 확인합니다.\n\n\n코드\n# 생성된 Parent 문서의 메타데이터를 확인합니다.\nparent_docs[0].metadata\n\n\n상대적으로 더 작은 Chunk인 Child 문서를 생성합니다.\n\n\n코드\nchild_docs = []\nfor i, doc in enumerate(docs):\n    # 현재 문서의 ID를 가져옵니다.\n    _id = doc_ids[i]\n    # 현재 문서를 하위 문서로 분할\n    child_doc = child_text_splitter.split_documents([doc])\n    for _doc in child_doc:\n        # metadata에 문서 ID 를 저장\n        _doc.metadata[id_key] = _id\n    child_docs.extend(child_doc)\n\n\nchild_docs 에 기입된 doc_id 를 확인합니다.\n\n\n코드\n# 생성된 Child 문서의 메타데이터를 확인합니다.\nchild_docs[0].metadata\n\n\n각각 분할된 청크의 수를 확인합니다.\n\n\n코드\nprint(f\"분할된 parent_docs의 개수: {len(parent_docs)}\")\nprint(f\"분할된 child_docs의 개수: {len(child_docs)}\")\n\n\n벡터저장소에 새롭게 생성한 작게 쪼개진 하위문서 집합을 추가합니다.\n다음으로는 상위 문서는 생성한 UUID 와 맵핑하여 docstore 에 추가합니다.\n\nmset() 메서드를 통해 문서 ID와 문서 내용을 key-value 쌍으로 문서 저장소에 저장합니다.\n\n\n\n코드\n# 벡터 저장소에 parent + child 문서를 추가\nretriever.vectorstore.add_documents(parent_docs)\nretriever.vectorstore.add_documents(child_docs)\n\n# docstore 에 원본 문서를 저장\nretriever.docstore.mset(list(zip(doc_ids, docs)))\n\n\n유사도 검색을 수행합니다. 가장 유사도가 높은 첫 번째 문서 조각을 출력합니다.\n여기서 retriever.vectorstore.similarity_search 메서드는 child + parent 문서 chunk 내에서 검색을 수행합니다.\n\n\n코드\n# vectorstore의 유사도 검색을 수행합니다.\nrelevant_chunks = retriever.vectorstore.similarity_search(\n    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n)\nprint(f\"검색된 문서의 개수: {len(relevant_chunks)}\")\n\n\n\n\n코드\nfor chunk in relevant_chunks:\n    print(chunk.page_content, end=\"\\n\\n\")\n    print(\"&gt;\" * 100, end=\"\\n\\n\")\n\n\n이번에는 retriever.invoke() 메서드를 사용하여 쿼리를 실행합니다.\nretriever.invoke() 메서드는 원본 문서의 전체 내용을 검색합니다.\n\n\n코드\nrelevant_docs = retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")\nprint(f\"검색된 문서의 개수: {len(relevant_docs)}\", end=\"\\n\\n\")\nprint(\"=\" * 100, end=\"\\n\\n\")\nprint(relevant_docs[0].page_content)\n\n\n리트리버(retriever)가 벡터 데이터베이스에서 기본적으로 수행하는 검색 유형은 유사도 검색입니다.\nLangChain Vector Stores는 Max Marginal Relevance를 통한 검색도 지원하므로, 이를 대신 사용하고 싶다면 다음과 같이 search_type 속성을 설정하면 됩니다.\n\nretriever 객체의 search_type 속성을 SearchType.mmr로 설정합니다.\n\n이는 검색 시 MMR(Maximal Marginal Relevance) 알고리즘을 사용하도록 지정하는 것입니다.\n\n\n\n\n코드\nfrom langchain.retrievers.multi_vector import SearchType\n\n# 검색 유형을 MMR(Maximal Marginal Relevance)로 설정\nretriever.search_type = SearchType.mmr\n\n# 관련 문서 전체를 검색\nprint(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")[0].page_content)\n\n\n\n\n코드\nfrom langchain.retrievers.multi_vector import SearchType\n\n# 검색 유형을 similarity_score_threshold로 설정\nretriever.search_type = SearchType.similarity_score_threshold\nretriever.search_kwargs = {\"score_threshold\": 0.3}\n\n# 관련 문서 전체를 검색\nprint(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")[0].page_content)\n\n\n\n\n코드\nfrom langchain.retrievers.multi_vector import SearchType\n\n# 검색 유형을 similarity로 설정, k값을 1로 설정\nretriever.search_type = SearchType.similarity\nretriever.search_kwargs = {\"k\": 1}\n\n# 관련 문서 전체를 검색\nprint(len(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")))"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/07-MultiVectorRetriever.html#요약본summary을-벡터저장소에-저장",
    "href": "docs/blog/posts/RAG/10-Retriever/07-MultiVectorRetriever.html#요약본summary을-벡터저장소에-저장",
    "title": "다중 벡터저장소 검색기(MultiVectorRetriever)",
    "section": "3 요약본(summary)을 벡터저장소에 저장",
    "text": "3 요약본(summary)을 벡터저장소에 저장\n요약은 종종 청크(chunk)의 내용을 보다 정확하게 추출할 수 있어 더 나은 검색 결과를 얻을 수 있습니다.\n여기서는 요약을 생성하는 방법과 이를 임베딩하는 방법에 대해 설명합니다.\n\n\n코드\n# PDF 파일을 로드하고 텍스트를 분할하기 위한 라이브러리 임포트\nfrom langchain_community.document_loaders import PyMuPDFLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\n# PDF 파일 로더 초기화\nloader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n\n# 텍스트 분할\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=50)\n\n# PDF 파일 로드 및 텍스트 분할 실행\nsplit_docs = loader.load_and_split(text_splitter)\n\n# 분할된 문서의 개수 출력\nprint(f\"분할된 문서의 개수: {len(split_docs)}\")\n\n\n\n\n코드\nfrom langchain_core.documents import Document\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n\nsummary_chain = (\n    {\"doc\": lambda x: x.page_content}\n    # 문서 요약을 위한 프롬프트 템플릿 생성\n    | ChatPromptTemplate.from_messages(\n        [\n            (\"system\", \"You are an expert in summarizing documents in Korean.\"),\n            (\n                \"user\",\n                \"Summarize the following documents in 3 sentences in bullet points format.\\n\\n{doc}\",\n            ),\n        ]\n    )\n    # OpenAI의 ChatGPT 모델을 사용하여 요약 생성\n    | ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n    | StrOutputParser()\n)\n\n\nchain.batch 메서드를 사용하여 docs 리스트의 문서들을 일괄 요약합니다. - 여기서 max_concurrency 매개변수를 10 으로 설정하여 최대 10개의 문서를 동시에 처리할 수 있도록 합니다.\n\n\n코드\n# 문서 배치 처리\nsummaries = summary_chain.batch(split_docs, {\"max_concurrency\": 10})\n\n\n\n\n코드\nlen(summaries)\n\n\n요약된 내용을 출력하여 결과를 확인합니다.\n\n\n코드\n# 원본 문서의 내용을 출력합니다.\nprint(split_docs[33].page_content, end=\"\\n\\n\")\n# 요약을 출력합니다.\nprint(\"[요약]\")\nprint(summaries[33])\n\n\nChroma 벡터 저장소를 초기화하여 자식 청크(child chunks)를 인덱싱합니다. 이때 OpenAIEmbeddings를 임베딩 함수로 사용합니다.\n\n문서 ID를 나타내는 키로 \"doc_id\"를 사용합니다.\n\n\n\n코드\nimport uuid\n\n# 요약 정보를 저장할 벡터 저장소를 생성합니다.\nsummary_vectorstore = Chroma(\n    collection_name=\"summaries\",\n    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n)\n\n# 부모 문서를 저장할 저장소를 생성합니다.\nstore = InMemoryStore()\n\n# 문서 ID를 저장할 키 이름을 지정합니다.\nid_key = \"doc_id\"\n\n# 검색기를 초기화합니다. (시작 시 비어 있음)\nretriever = MultiVectorRetriever(\n    vectorstore=summary_vectorstore,  # 벡터 저장소\n    byte_store=store,  # 바이트 저장소\n    id_key=id_key,  # 문서 ID 키\n)\n# 문서 ID를 생성합니다.\ndoc_ids = [str(uuid.uuid4()) for _ in split_docs]\n\n\n요약된 문서와 메타데이터(여기서는 생성한 요약본에 대한 Document ID 입니다)를 저장합니다.\n\n\n코드\nsummary_docs = [\n    # 요약된 내용을 페이지 콘텐츠로 하고, 문서 ID를 메타데이터로 포함하는 Document 객체를 생성합니다.\n    Document(page_content=s, metadata={id_key: doc_ids[i]})\n    for i, s in enumerate(summaries)\n]\n\n\n요약본의 문서의 개수는 원본 문서의 개수와 일치합니다.\n\n\n코드\n# 요약본의 문서의 개수\nlen(summary_docs)\n\n\n\nretriever.vectorstore.add_documents(summary_docs)를 통해 summary_docs를 벡터 저장소에 추가합니다.\nretriever.docstore.mset(list(zip(doc_ids, docs)))를 사용하여 doc_ids와 docs를 매핑하여 문서 저장소에 저장합니다.\n\n\n\n코드\nretriever.vectorstore.add_documents(\n    summary_docs\n)  # 요약된 문서를 벡터 저장소에 추가합니다.\n\n# 문서 ID와 문서를 매핑하여 문서 저장소에 저장합니다.\nretriever.docstore.mset(list(zip(doc_ids, split_docs)))\n\n\nvectorstore 객체의 similarity_search 메서드를 사용하여 유사도 검색을 수행합니다.\n\n\n코드\n# 유사도 검색을 수행합니다.\nresult_docs = summary_vectorstore.similarity_search(\n    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n)\n\n\n\n\n코드\n# 1개의 결과 문서를 출력합니다.\nprint(result_docs[0].page_content)\n\n\nretriever 객체의 invoke() 사용하여 질문과 관련된 문서를 검색합니다.\n\n\n코드\n# 관련된 문서를 검색하여 가져옵니다.\nretrieved_docs = retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")\nprint(retrieved_docs[0].page_content)"
  },
  {
    "objectID": "docs/blog/posts/RAG/10-Retriever/07-MultiVectorRetriever.html#가설-쿼리hypothetical-queries-를-활용하여-문서-내용-탐색",
    "href": "docs/blog/posts/RAG/10-Retriever/07-MultiVectorRetriever.html#가설-쿼리hypothetical-queries-를-활용하여-문서-내용-탐색",
    "title": "다중 벡터저장소 검색기(MultiVectorRetriever)",
    "section": "4 가설 쿼리(Hypothetical Queries) 를 활용하여 문서 내용 탐색",
    "text": "4 가설 쿼리(Hypothetical Queries) 를 활용하여 문서 내용 탐색\nLLM은 특정 문서에 대해 가정할 수 있는 질문 목록을 생성하는 데에도 사용될 수 있습니다.\n이렇게 생성된 질문들은 임베딩(embedding)될 수 있으며, 이를 통해 문서의 내용을 더욱 깊이 있게 탐색하고 이해할 수 있습니다.\n가정 질문 생성은 문서의 주요 주제와 개념을 파악하는 데 도움이 되며, 독자들이 문서 내용에 대해 더 많은 궁금증을 갖도록 유도할 수 있습니다.\n아래는 Function Calling 을 활용하여 가설 질문을 생성하는 예제입니다.\n\n\n코드\nfunctions = [\n    {\n        \"name\": \"hypothetical_questions\",  # 함수의 이름을 지정합니다.\n        \"description\": \"Generate hypothetical questions\",  # 함수에 대한 설명을 작성합니다.\n        \"parameters\": {  # 함수의 매개변수를 정의합니다.\n            \"type\": \"object\",  # 매개변수의 타입을 객체로 지정합니다.\n            \"properties\": {  # 객체의 속성을 정의합니다.\n                \"questions\": {  # 'questions' 속성을 정의합니다.\n                    \"type\": \"array\",  # 'questions'의 타입을 배열로 지정합니다.\n                    \"items\": {\n                        \"type\": \"string\"\n                    },  # 배열의 요소 타입을 문자열로 지정합니다.\n                },\n            },\n            \"required\": [\"questions\"],  # 필수 매개변수로 'questions'를 지정합니다.\n        },\n    }\n]\n\n\nChatPromptTemplate을 사용하여 주어진 문서를 기반으로 3개의 가상 질문을 생성하는 프롬프트 템플릿을 정의합니다.\n\nfunctions와 function_call을 설정하여 가상 질문 생성 함수를 호출합니다.\nJsonKeyOutputFunctionsParser를 사용하여 생성된 가상 질문을 파싱하고, questions 키에 해당하는 값을 추출합니다.\n\n\n\n코드\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\nfrom langchain_openai import ChatOpenAI\n\nhypothetical_query_chain = (\n    {\"doc\": lambda x: x.page_content}\n    # 아래 문서를 사용하여 답변할 수 있는 가상의 질문을 정확히 3개 생성하도록 요청합니다. 이 숫자는 조정될 수 있습니다.\n    | ChatPromptTemplate.from_template(\n        \"Generate a list of exactly 3 hypothetical questions that the below document could be used to answer. \"\n        \"Potential users are those interested in the AI industry. Create questions that they would be interested in. \"\n        \"Output should be written in Korean:\\n\\n{doc}\"\n    )\n    | ChatOpenAI(max_retries=0, model=\"gpt-4o-mini\").bind(\n        functions=functions, function_call={\"name\": \"hypothetical_questions\"}\n    )\n    # 출력에서 \"questions\" 키에 해당하는 값을 추출합니다.\n    | JsonKeyOutputFunctionsParser(key_name=\"questions\")\n)\n\n\n문서에 대한 답변을 출력합니다.\n\n출력은 생성한 3개의 가설 쿼리(Hypothetical Queries) 가 담겨 있습니다.\n\n\n\n코드\n# 주어진 문서에 대해 체인을 실행합니다.\nhypothetical_query_chain.invoke(split_docs[33])\n\n\nchain.batch 메서드를 사용하여 split_docs 데이터에 대해 동시에 여러 개의 요청을 처리합니다.\n\n\n코드\n# 문서 목록에 대해 가설 질문을 배치 생성\nhypothetical_questions = hypothetical_query_chain.batch(\n    split_docs, {\"max_concurrency\": 10}\n)\n\n\n\n\n코드\nhypothetical_questions[33]\n\n\n아래는 이전에 진행했던 방식과 동일하게 생성한 가설 쿼리(Hypothetical Queries) 를 벡터저장소에 저장하는 과정입니다.\n\n\n코드\n# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소\nhypothetical_vectorstore = Chroma(\n    collection_name=\"hypo-questions\", embedding_function=OpenAIEmbeddings()\n)\n# 부모 문서의 저장소 계층\nstore = InMemoryStore()\n\nid_key = \"doc_id\"\n# 검색기 (시작 시 비어 있음)\nretriever = MultiVectorRetriever(\n    vectorstore=hypothetical_vectorstore,\n    byte_store=store,\n    id_key=id_key,\n)\ndoc_ids = [str(uuid.uuid4()) for _ in split_docs]  # 문서 ID 생성\n\n\nquestion_docs 리스트에 메타데이터(문서 ID) 를 추가합니다.\n\n\n코드\nquestion_docs = []\n# hypothetical_questions 저장\nfor i, question_list in enumerate(hypothetical_questions):\n    question_docs.extend(\n        # 질문 리스트의 각 질문에 대해 Document 객체를 생성하고, 메타데이터에 해당 질문의 문서 ID를 포함시킵니다.\n        [Document(page_content=s, metadata={id_key: doc_ids[i]}) for s in question_list]\n    )\n\n\n가설 쿼리를 문서에 추가하고, 원본 문서를 docstore 에 추가합니다.\n\n\n코드\n# hypothetical_questions 문서를 벡터 저장소에 추가합니다.\nretriever.vectorstore.add_documents(question_docs)\n\n# 문서 ID와 문서를 매핑하여 문서 저장소에 저장합니다.\nretriever.docstore.mset(list(zip(doc_ids, split_docs)))\n\n\nvectorstore 객체의 similarity_search 메서드를 사용하여 유사도 검색을 수행합니다.\n\n\n코드\n# 유사한 문서를 벡터 저장소에서 검색합니다.\nresult_docs = hypothetical_vectorstore.similarity_search(\n    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n)\n\n\n아래는 유사도 검색 결과입니다.\n여기서는 생성한 가설 쿼리만 추가해 놓은 상태이기 때문에, 생성한 가설 쿼리 중 유사도가 가장 높은 문서를 반환합니다.\n\n\n코드\n# 유사도 검색 결과를 출력합니다.\nfor doc in result_docs:\n    print(doc.page_content)\n    print(doc.metadata)\n\n\nretriever 객체의 invoke 메서드를 사용하여 쿼리와 관련된 문서를 검색합니다.\n\n\n코드\n# 관련된 문서를 검색하여 가져옵니다.\nretrieved_docs = retriever.invoke(result_docs[1].page_content)\n\n# 검색된 문서를 출력합니다.\nfor doc in retrieved_docs:\n    print(doc.page_content)"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "",
    "text": "문자의 발명 → 인류의 기록 정확도 향상\n인쇄술 → 지식 대중화\n전화·라디오·TV → 즉각적인 원격 소통\n인터넷·모바일 → 실시간 대화\n생성형 AI → 인간-기계 상호작용 고도화\n\n\n\n\n\nPromptus(나타내다/생산하다)에서 유래\n현재 의미: 행동을 유도하는 신호\nAI에서: 모델에게 답변을 생성하도록 입력하는 문장\n\n\n\n\n\n\n\n\n\n\n\n\n항목\n프롬프트\n프롬프트 엔지니어링\n\n\n\n\n목적\n응답 생성 요청\n원하는 형태로 정확한 응답을 얻기 위한 설계\n\n\n필요성\n기본 입력\n모델 작동 방식·언어적 맥락 이해 필요\n\n\n예시\n“용에 대한 이야기 해줘”\n“용감한 용이 마을을 구하는 5문장 이야기 생성해줘. 대화 포함.”"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#인간-컴퓨터-상호작용의-변화",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#인간-컴퓨터-상호작용의-변화",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "",
    "text": "문자의 발명 → 인류의 기록 정확도 향상\n인쇄술 → 지식 대중화\n전화·라디오·TV → 즉각적인 원격 소통\n인터넷·모바일 → 실시간 대화\n생성형 AI → 인간-기계 상호작용 고도화"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#프롬프트의-정의",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#프롬프트의-정의",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "",
    "text": "Promptus(나타내다/생산하다)에서 유래\n현재 의미: 행동을 유도하는 신호\nAI에서: 모델에게 답변을 생성하도록 입력하는 문장"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#프롬프트-vs-프롬프트-엔지니어링",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#프롬프트-vs-프롬프트-엔지니어링",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "",
    "text": "항목\n프롬프트\n프롬프트 엔지니어링\n\n\n\n\n목적\n응답 생성 요청\n원하는 형태로 정확한 응답을 얻기 위한 설계\n\n\n필요성\n기본 입력\n모델 작동 방식·언어적 맥락 이해 필요\n\n\n예시\n“용에 대한 이야기 해줘”\n“용감한 용이 마을을 구하는 5문장 이야기 생성해줘. 대화 포함.”"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#개념",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#개념",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "2.1 2.1 개념",
    "text": "2.1 2.1 개념\n\n방대한 데이터 기반 사전학습 모델\nAutoregression: 이전 토큰 기반으로 다음 단어 예측\n기반 기술: Transformer 구조(셀프 어텐션)"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#주요-모델-패밀리",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#주요-모델-패밀리",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "2.2 2.2 주요 모델 패밀리",
    "text": "2.2 2.2 주요 모델 패밀리\n\nOpenAI – GPT-4o: 멀티모달·실시간 처리\nAnthropic – Claude 3: 안전성 중점, 헌법적 AI\nGoogle – Gemini / BERT / T5: 다중 모달 처리"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#모델-튜닝-방식",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#모델-튜닝-방식",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "2.3 2.3 모델 튜닝 방식",
    "text": "2.3 2.3 모델 튜닝 방식\n\nFine-Tuning\nPrompt Engineering\nFeature-Tuning(특징 공간 해석 기반 제어)"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#필수-4요소",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#필수-4요소",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "3.1 3.1 필수 4요소",
    "text": "3.1 3.1 필수 4요소\n\nInstruction: 어떤 작업을 해야 하는가\nContext: 배경 정보\nInput Data: 처리 대상 데이터\nOutput Indicator: 출력 형식 규정"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#프롬프트-타입-구조type-ad",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#프롬프트-타입-구조type-ad",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "3.2 3.2 프롬프트 타입 구조(Type A–D)",
    "text": "3.2 3.2 프롬프트 타입 구조(Type A–D)\n\nA: 지시문 + 출력문\nB: 지시문 + 맥락 + 출력문\nC: 지시문 + 맥락 + 예시 + 출력문\nD: 지시문 + 입력값 + 출력문\n\n예시와 함께 구조적으로 프롬프트를 설계하면 LLM이 더 안정적으로 원하는 출력 생성."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#대-원칙",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#대-원칙",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "4.1 4.1 4대 원칙",
    "text": "4.1 4.1 4대 원칙\n\n범용성: 다양한 상황에서도 동작\n목적 지향성: 특정 사용자 목적 반영\n일관성: 반복 실행해도 동일 품질\n경제성: API 비용 절감"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#scaffolding-prompting",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#scaffolding-prompting",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "4.2 4.2 Scaffolding Prompting",
    "text": "4.2 4.2 Scaffolding Prompting\n\n인간의 학습 이론(ZPD)을 적용\nUnderstand → Ideation → Analysis → Apply → Evaluate → Generalize\n단계적 사고구조 유도"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#핵심-5-tips",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#핵심-5-tips",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "4.3 4.3 핵심 5 Tips",
    "text": "4.3 4.3 핵심 5 Tips\n\n4.3.1 Tip1. 최신 모델 사용\n\n\n4.3.2 Tip2. 명확한 동사로 지시\n예: 분석해, 정리해, 요약해, 작성해 등\n\n\n4.3.3 Tip 3. 프롬프트를 구조화하자\n프롬프트를 구조화하면 LLM이 입력을 더 명확하게 해석할 수 있고,\n작업 목적·규칙·입력 데이터·출력 형식을 혼동 없이 처리할 수 있다.\n구조화를 위한 핵심 기법은 Markdown, 코드 프롬프트, XML 태그이다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#markdown-구조화-headers-lists-emphasis",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#markdown-구조화-headers-lists-emphasis",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "4.4 3.1 Markdown 구조화 (Headers, Lists, Emphasis)",
    "text": "4.4 3.1 Markdown 구조화 (Headers, Lists, Emphasis)\nMarkdown은 LLM이 가장 잘 해석하는 구조적 문법 중 하나이다.\n섹션을 명확히 나누고, 각 부분을 시각적으로 구분해줌으로써\n모델의 오류를 줄이고 반복 작업 시 유지보수성이 높아진다.\n\n4.4.1 1) 헤더(Headers) 활용\n헤더는 프롬프트의 구성을 크게 나누는 데 사용한다.\n# 역할(Role)\n너는 스포츠 기사 분석 엔진이다.\n\n## 작업(Task)\n아래 텍스트에서 장소(도시, 국가, 축구 클럽)를 모두 추출해라.\n\n## 출력 형식(Format)\n- \"장소: A, B, C\" 형태의 한 줄 출력\n- 설명 금지\n\n## 텍스트(Text)\n{{TEXT}}\n\n\n4.4.2 2) 목록(Lists) 활용\n절차, 규칙, 조건을 번호 목록으로 정리하면 LLM이 하나씩 적용하기 쉽다.\n다음 규칙을 따라 작업을 수행해라.\n1. 사람 이름은 제외한다.\n2. 축구 클럽은 장소로 포함한다.\n3. 결과는 쉼표로 구분한다.\n4. 설명 문장은 쓰지 않는다.\n\n\n4.4.3 3) 강조(Emphasis) 사용\n중요 조건을 굵게 또는 기울임으로 표시해 모델의 우선순위를 높인다.\n- 반드시 **한국어**로 작성하라.\n- 출력은 **한 줄**로만 작성한다.\n- *설명 문장은 포함하지 않는다.*"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#코드-프롬프트code-prompting",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#코드-프롬프트code-prompting",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "4.5 3.2 코드 프롬프트(Code Prompting)",
    "text": "4.5 3.2 코드 프롬프트(Code Prompting)\n자연어 대신 코드 형식으로 의도를 명세하면 애매함이 줄어들고 LLM이 구조적으로 이해해 할루시네이션이 감소한다.\n# 역할 정의\nrole = \"정보 추출 엔진\"\n\n# 작업 정의\ntask = \"텍스트에서 '장소명'을 추출해 정렬된 리스트로 반환\"\n\n# 출력 형식 정의\noutput = {\n    \"places\": [\"string\"]\n}\n코드 방식의 장점:\n\n논리 구조가 명확하게 표현됨\n조건과 출력 형식이 혼동되지 않음\n정형화된 포맷을 자주 재사용 가능"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#xml-태그-기반-구조화-claude-최적화",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#xml-태그-기반-구조화-claude-최적화",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "4.6 3.3 XML 태그 기반 구조화 (Claude 최적화)",
    "text": "4.6 3.3 XML 태그 기반 구조화 (Claude 최적화)\nXML 태그는 텍스트 내 특정 영역을 명확히 구분해 Claude뿐 아니라 대부분의 LLM에서 구조적 파싱을 돕는 강력한 방식이다.\n\n4.6.1 1) 태그로 영역 지정\n&lt;email&gt;\nShow up at 6AM because I say so.\n&lt;/email&gt;\n\nMake this email more polite.\nLLM은 &lt;email&gt;...&lt;/email&gt; 내부 텍스트만 변환하면 된다는 것을 명확히 인식한다.\n\n\n4.6.2 2) 데이터 템플릿 예시\n&lt;animal&gt;{{ANIMAL}}&lt;/animal&gt;\n입력만 바꿔 여러 데이터를 동일한 템플릿에 적용할 수 있다.\n예:\n&lt;animal&gt;Cow&lt;/animal&gt;\n&lt;animal&gt;Dog&lt;/animal&gt;\n&lt;animal&gt;Seal&lt;/animal&gt;\n장점:\n\n구역별 의미가 명확\n반복 작업에서 수정이 쉽고 안정적\n모델이 태그 단위로 파싱하기 때문에 오류 감소"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#구조화-기법이-필요한-이유",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#구조화-기법이-필요한-이유",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "4.7 3.4 구조화 기법이 필요한 이유",
    "text": "4.7 3.4 구조화 기법이 필요한 이유\n\n명령어, 입력 데이터, 출력 형식을 명확히 구분해 모델의 해석 오류를 줄인다.\n규칙을 시각적으로 구분하여 작업 수행 품질의 일관성과 재현성을 높인다.\n재사용 가능한 템플릿이 되어 프롬프트 제작 비용과 시간 절감에 기여한다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#구조화-적용-사례-장소명-추출",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#구조화-적용-사례-장소명-추출",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "4.8 3.5 구조화 적용 사례 (장소명 추출)",
    "text": "4.8 3.5 구조화 적용 사례 (장소명 추출)\n# 역할(Role)\n너는 텍스트에서 장소명을 추출하는 엔진이다.\n\n## 작업(Task)\n텍스트 내 도시, 국가, 축구 클럽 이름을 모두 \"장소\"로 간주하고 추출해라.\n\n## 출력 형식(Format)\n- 한 줄로만 출력한다.\n- 형식: `장소: A, B, C`\n- 설명 문장 금지.\n\n## 텍스트(Text)\n음바페는 26일 쿠프 드 프랑스 프랑스컵 올랭피크 리옹과의\n결승전에서 풀타임을 뛰며 2-1로 팀 승리를 도왔다.\n3년 만에 대회 정상에 오른 PSG는 역대 최다 15회 우승으로\n2위 마르세유(10회)를 멀찍이 따돌렸다.\n음바페는 이날 PSG에서의 커리어를 마무리했다.\n\n4.8.1 Tip4. 단문 중심\n\n한국어는 짧고 명확하게 작성\n톤·형식·분량을 구체적으로 지시\n\n\n\n4.8.2 Tip5. 하지 말 것(X) → 할 것(O)\n\n부정 지시보다 긍정적 행동 지시가 안정적"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#llm-한계",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#llm-한계",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "5.1 5.1 LLM 한계",
    "text": "5.1 5.1 LLM 한계\n\n할루시네이션\n편향성\n근거 없는 출처 생성\n수학 및 추론 한계\nPrompt Injection(프롬프트 해킹)"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#프롬프트-엔지니어링이-필요한-이유",
    "href": "docs/blog/posts/Prompt_Engineering/01-Prompt-Structure/01-Prompt-Structure.html#프롬프트-엔지니어링이-필요한-이유",
    "title": "Part 1 — 프롬프트 구조와 기능 탐구",
    "section": "5.2 5.2 프롬프트 엔지니어링이 필요한 이유",
    "text": "5.2 5.2 프롬프트 엔지니어링이 필요한 이유\n\n정확성 향상\n오류 및 편향 감소\n모델 행동 제어\n사용자 경험 개선\n비용 절감"
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html",
    "title": "Part 2 — 사용자 언어 읽기(프롬프트 구조와 유형)",
    "section": "",
    "text": "이 장을 통해 다음을 학습할 수 있습니다:\n\n내가 쓰는 프롬프트가 어떤 스타일인지 파악: 5가지 프롬프트 유형을 이해하고 자신이 주로 사용하는 스타일을 확인할 수 있습니다.\n보완할 수 있는 요소 파악: 현재 프롬프트에 부족한 요소들을 확인하고, 어떤 부분을 보완할 수 있는지에 대한 아이디어를 얻을 수 있습니다.\n\n프롬프트 작문 유형은 사용자가 AI에게 요청하는 방식에 따라 크게 5가지로 분류할 수 있습니다. 각 유형은 고유한 특징과 사용 목적을 가지고 있으며, 상황에 맞는 유형을 선택하는 것이 효과적인 프롬프트 작성의 핵심입니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html#명령청유형",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html#명령청유형",
    "title": "Part 2 — 사용자 언어 읽기(프롬프트 구조와 유형)",
    "section": "2.1 명령/청유형",
    "text": "2.1 명령/청유형\n\n2.1.1 특징\n\n직접적이고 명확한 지시나 요청을 하는 유형\n“~해줘”, “~알려줘”, “~말해” 등의 명령형/청유형 문장 사용\n구체적인 작업 수행을 요구\n\n\n\n2.1.2 예시\n\n“업장에 산학 실습을 가는데 실습개요와 목표를 알려줘”\n“우아한 거짓말 독후감 써줘”\n“봉은사역에서 메가박스가는 길 말해”\n“Rtx4090 가장 싸게 사는 방법 알려줘봐”\n“저는 이전에는 없던 창업 아이디어를 찾고 있는데, 어떤 분야를 추천 주시겠어요?”\n\n\n\n2.1.3 프롬프트 작성 실습\n실습 문제\n중요한 회의 일정을 변경해야 하는 상황입니다. 팀원에게 보낼 정중하고 간결한 이메일을 작성하는 프롬프트를 제작해보세요.\n잘 만들어진 프롬프트 예시\n중요한 회의 일정을 변경해야해.\n팀원들에게 보내는 정중하고 간결한 이메일을 작성해.\n다음 사항을 반드시 포함해.\n\n1. 회의 일정 변경 사유: 부득이한 개인 사정으로 연차\n2. 변경된 새로운 회의 일정 알림: 8/7일 오후 2시에서 8/12일 오후 2시, 3A 회의룸으로 변경\n3. 회의 참여를 독려하는 문구 추가\n4. 회의 준비 사항\n5. 마무리 인사말\n\n💡 팁: 이 프롬프트는 명령/청유형의 특징을 잘 보여주는 예시입니다. 명확한 작업 지시와 포함해야 할 항목을 번호로 구분하여 제시하고 있습니다.\n\n결과\n프롬프트를 실행하면 다음과 같은 이메일이 생성됩니다:\n제목: 회의 일정 변경 안내\n\n안녕하세요, 팀원 여러분.\n\n부득이한 개인 사정으로 인해 원래 예정된 회의 일정을 변경하게 되었습니다. 변경된 새로운 회의 일정은 아래와 같습니다.\n\n• 변경 전: 8/7일 오후 2시\n• 변경 후: 8/12일 오후 2시\n• 장소: 3A 회의룸\n\n회의 준비를 위해 관련 자료를 미리 검토해 주시고, 참석 가능 여부를 확인해 주시면 감사하겠습니다. 모든 팀원들의 참여를 부탁드립니다.\n\n추가로 궁금한 점이나 문제가 있으면 언제든지 저에게 연락해 주십시오.\n\n감사합니다.\n\n[귀하의 이름]\n\n\n2.1.4 핵심 포인트\n그래서 명령/청유형 프롬프트의 핵심 포인트는 다음과 같습니다:\n\n명확한 작업 지시: “이메일을 작성해”, “알려줘”처럼 AI가 수행할 작업을 명확하게 지시합니다.\n포함해야 할 항목을 번호로 구분하여 제시: 번호나 불릿 포인트로 포함할 내용을 구조화하여 제시하면 AI가 빠짐없이 처리할 수 있습니다.\n구체적인 정보 제공: 날짜, 시간, 장소 등 구체적인 정보를 포함하면 더 정확한 결과를 얻을 수 있습니다.\n커스텀 영역은 상황에 맞게 직접 입력: 변경 가능한 부분은 대괄호나 명시적 표시로 구분하여 사용자가 상황에 맞게 수정할 수 있도록 합니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html#역할-지정",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html#역할-지정",
    "title": "Part 2 — 사용자 언어 읽기(프롬프트 구조와 유형)",
    "section": "2.2 역할 지정",
    "text": "2.2 역할 지정\n\n2.2.1 특징\n\nAI에게 특정 역할이나 페르소나를 부여하는 유형\n“너는 ~야”, “당신은 ~입니다” 등의 표현 사용\n역할에 맞는 전문성과 톤을 요구\n\n\n\n2.2.2 예시\n\n“너는 고객서비스 상담사처럼 행동해. 고객의 감정에 최대한 공감할 수 있는 표현을 사용해.”\n“너는 헤르만 헤세야. 헤르만 헤세의 작품을 통해 인간의 감정과 사회적 이슈를 알고 싶은 독자를 위해 상세하게 설명해줘.”\n“당신은 파이썬을 잘하는 프로그래머 입니다. 만약 내가 코드 만들어줘라고 하면 코드를 만들어 주면 됩니다.”\n“당신은 평가자입니다. 6학년 초등학생의 평가 결과를 개조식으로 알려줘야 합니다.”\n\n\n\n2.2.3 프롬프트 작성 실습\n실습 문제\n당신은 신생 친환경 스타트업의 마케팅 책임자입니다. Z세대를 타겟으로 한 소셜 미디어 마케팅 전략 5가지를 제안하는 프롬프트를 작성해보세요.\n잘 만들어진 프롬프트 예시\n당신은 신생 친환경 스타트업의 마케팅 책임자입니다.\nZ세대를 타겟으로 한 소셜 미디어 마케팅 전략 5가지를 제안해주세요.\n&lt;인플루언서 협업&gt;을 소재로 해주세요.\n\n- 각 전략의 구체적인 설명\n- 전략이 효과적인 이유\n- 실행 방법\n- 기대되는 결과\n- 성공 여부를 평가하는 방법\n결과\n프롬프트를 실행하면 다음과 같은 마케팅 전략이 생성됩니다:\n1. 친환경 인플루언서와의 제품 리뷰\n\n구체적인 설명: 친환경 인플루언서에게 제품을 제공하여 그들의 채널에서 제품을 리뷰하게 하고, 제품의 장점을 강조하고 실제 사용 경험을 공유하도록 합니다.\n전략이 효과적인 이유: Z세대는 진정성을 중시하며 인플루언서 리뷰를 신뢰합니다. 친환경 인플루언서와의 협업은 자연스럽게 제품의 가치를 전달할 수 있습니다.\n실행 방법: 관련 인플루언서를 찾아 연락하고, 제품을 제공하여 리뷰를 요청합니다. 콘텐츠 제작을 모니터링하고 필요시 적극적으로 지원합니다.\n기대되는 결과: 제품에 대한 긍정적인 인식 증가, 브랜드 인지도 향상, 초기 구매자 증가\n성공 여부를 평가하는 방법: 인플루언서 게시물 조회수, 좋아요, 댓글 수를 모니터링하고, 리뷰 이후 판매 증가를 추적합니다.\n\n2. 인플루언서 주최 온라인 이벤트\n\n구체적인 설명: 인플루언서가 주최하는 온라인 이벤트를 통해 제품을 홍보합니다. 예를 들어, Q&A 세션, 사용법 튜토리얼, 라이브 스트리밍 등을 통해 실시간으로 사용자와 소통하며 제품을 소개합니다.\n전략이 효과적인 이유: 실시간 소통은 Z세대의 높은 참여를 유도하며, 인터랙티브한 이벤트는 긍정적인 브랜드 이미지를 구축합니다.\n실행 방법: 인플루언서와 협력하여 이벤트 주제와 일정을 결정하고, 소셜 미디어 광고와 게시물로 홍보합니다. 이벤트 당일 기술 지원과 상품을 준비하여 참여를 독려합니다.\n기대되는 결과: 브랜드 참여도 증가, 제품 인지도 향상, 사용자와의 직접적인 소통 강화\n성공 여부를 평가하는 방법: 이벤트 참여자 수, 실시간 시청자 수, 이벤트 이후 제품 판매량, 이벤트 관련 소셜 미디어 언급량을 분석합니다.\n\n3. 소셜 미디어 챌린지\n\n구체적인 설명: 인플루언서가 주도하는 소셜 미디어 챌린지를 기획하여 친환경 제품 사용에 대한 자발적인 참여를 유도합니다.\n전략이 효과적인 이유: Z세대는 트렌디한 챌린지에 참여하는 것을 즐기며, 챌린지는 바이럴 효과를 낼 수 있습니다.\n실행 방법: 인플루언서와 협력하여 챌린지 콘텐츠를 기획하고, 참여 방법과 해시태그를 홍보합니다. 참여자에게 소정의 상품을 제공하거나 우승자에게 특별 혜택을 제공합니다.\n기대되는 결과: 높은 소셜 미디어 참여도, 제품 인지도 향상, 긍정적인 브랜드 이미지 형성\n성공 여부를 평가하는 방법: 챌린지 참여 게시물 수, 관련 해시태그 사용 빈도, 소셜 미디어 언급량, 제품 판매량 변화를 추적합니다.\n\n4. 인플루언서와의 공동 콘텐츠 제작\n\n구체적인 설명: 친환경 라이프스타일을 주제로 인플루언서와 함께 콘텐츠를 제작합니다. 예를 들어, 친환경 제품을 활용한 DIY 프로젝트나 지속 가능한 생활 팁에 대한 영상/게시물을 만듭니다.\n전략이 효과적인 이유: 공동 콘텐츠는 자연스럽게 브랜드와 제품을 노출시키며, 인플루언서의 팬들은 이 콘텐츠를 통해 제품에 관심을 갖게 됩니다.\n실행 방법: 인플루언서와 콘텐츠 아이디어를 논의하고, 제작 및 편집 과정에 협력합니다. 콘텐츠가 게시되면 소셜 미디어 채널을 통해 적극적으로 홍보합니다.\n기대되는 결과: 브랜드 인지도 증가, 콘텐츠를 통한 긍정적인 브랜드 이미지 형성, 신규 고객 확보\n성공 여부를 평가하는 방법: 콘텐츠 조회수, 좋아요, 댓글 수를 분석하고, 콘텐츠 관련 판매 증가를 추적합니다.\n\n5. 인플루언서와의 지속 가능한 캠페인\n\n구체적인 설명: 인플루언서와 함께 장기적인 친환경 캠페인을 기획합니다. 예를 들어, 한 달간 플라스틱 사용 줄이기나 일주일간 비건 식단 도전과 같은 지속 가능한 라이프스타일을 홍보합니다.\n전략이 효과적인 이유: 장기적인 캠페인은 Z세대에게 깊은 인상을 남기며, 지속 가능한 생활 실천에 대한 관심을 높이는 데 효과적입니다.\n실행 방법: 인플루언서와 캠페인 주제와 기간을 설정하고, 소셜 미디어에 캠페인 콘텐츠를 지속적으로 게시합니다. 참여자에게 인센티브를 제공하고 캠페인 진행 상황을 정기적으로 업데이트합니다.\n기대되는 결과: 브랜드의 지속 가능성에 대한 인식 강화, 장기적인 브랜드 로열티 형성, 지속 가능한 라이프스타일 실천 문화 확산\n성공 여부를 평가하는 방법: 캠페인 기간 동안의 참여자 수, 소셜 미디어 참여도, 브랜드 인지도 변화, 장기적인 판매 추세를 분석합니다.\n\n\n\n2.2.4 핵심 포인트\n위의 잘 만들어진 프롬프트 예시를 통해 역할 지정 프롬프트의 핵심 포인트를 살펴보겠습니다:\n\n명확한 역할 정의: 프롬프트 첫 줄에서 “당신은 신생 친환경 스타트업의 마케팅 책임자입니다”라고 명확하게 역할을 정의했습니다. 이렇게 구체적인 역할을 부여하면 AI가 해당 전문가의 지식과 경험을 활용하여 답변할 수 있습니다.\n대상과 맥락 명시: “Z세대를 타겟으로 한”이라는 표현으로 답변의 대상과 맥락을 명확히 했습니다. 이를 통해 역할이 특정 대상에 맞는 전략을 제안할 수 있습니다.\n구체적인 소재나 방향 제시: “&lt;인플루언서 협업&gt;을 소재로 해주세요”처럼 구체적인 소재나 방향을 제시하면 AI가 더 집중된 답변을 생성할 수 있습니다.\n구체적인 출력 형식 지정: 불릿 포인트로 각 전략의 설명, 효과적인 이유, 실행 방법, 기대되는 결과, 평가 방법을 요구했습니다. 이렇게 구조화된 형식을 지정하면 더 체계적이고 실용적인 결과를 얻을 수 있습니다.\n역할에 맞는 전문성과 관점 요구: 마케팅 책임자라는 역할을 부여함으로써, AI는 마케팅 전문가의 관점에서 실무 경험과 업계 지식을 바탕으로 답변하게 됩니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html#상황극형",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html#상황극형",
    "title": "Part 2 — 사용자 언어 읽기(프롬프트 구조와 유형)",
    "section": "2.3 상황극형",
    "text": "2.3 상황극형\n\n2.3.1 특징\n\n특정 상황이나 맥락을 설정하여 대화를 진행하는 유형\n“지금 ~에 있어”, “우리는 ~하고 있어” 등의 상황 설정 표현 사용\n역할극이나 시뮬레이션 형태\n\n\n\n2.3.2 예시\n\n“너는 지금 곰하고 같이 있어. 곰을 따라하는 게 너의 역할이야. 크앙, 그르렁, Grrr…., 울음소리로만 대화해야해.”\n“나는 지금 돈이 2만원 밖에 없어. 그런데 번역레포트를 제출해야하는데. 전문가를 구할 돈이 없어. 너가 대신 내 번역물을 프루프 리딩을 해줘.”\n“우리는 지금 심리상담 센터에 같이 있어. 너는 인공지능이야. 말 시작할 때 흐음 으로 항상 시작하면서 심리상담을 해주길 바래.”\n\n\n\n2.3.3 프롬프트 작성 실습\n실습 문제\nChatGPT의 GPTs를 이용하여, 🐻 곰과의 대화 페르소나 챗봇을 만들어보세요.\n잘 만들어진 프롬프트 예시\n너는 지금 곰하고 같이 있어. 곰을 따라하는 게 너의 역할이야.\n\"크앙\", \"그르렁\", \"Grrr ....\", 울음소리로만 대화해야해.\n최대한 곰처럼 흉내내. 말은 너무 길게 하지마.\n곰은 대체로 간결하게 말해.\n다 말하고나서는 ( ) 사용해서, 곰의 언어를 통역해줘.\n대화를 이어갈 수 있도록.\n결과\n\n\n\n2.3.4 핵심 포인트\n위의 잘 만들어진 프롬프트 예시를 통해 상황극형 프롬프트의 핵심 포인트를 살펴보겠습니다:\n\n구체적인 상황과 맥락 설정: 프롬프트 첫 줄에서 “너는 지금 곰하고 같이 있어”라고 현재 상황을 명확하게 설정했습니다. 이렇게 구체적인 상황을 제시하면 AI가 그 맥락 안에서 행동할 수 있습니다.\n역할과 행동 방식 명시: “곰을 따라하는 게 너의 역할이야”로 역할을 명시하고, “크앙”, “그르렁”, “Grrr ….”, 울음소리로만 대화해야 한다고 행동 방식을 구체적으로 지정했습니다.\n스타일과 톤 지정: “최대한 곰처럼 흉내내”, “말은 너무 길게 하지마”, “곰은 대체로 간결하게 말해”처럼 캐릭터에 맞는 스타일과 톤을 명시했습니다.\n대화 형식이나 출력 방식 지정: “다 말하고나서는 ( ) 사용해서, 곰의 언어를 통역해줘”로 대화를 이어갈 수 있도록 통역 형식을 지정했습니다. 이를 통해 사용자가 곰의 언어를 이해하고 대화를 지속할 수 있습니다.\n대화 지속성 고려: “대화를 이어갈 수 있도록”이라는 지시로 단순한 일회성 응답이 아닌 지속적인 대화가 가능하도록 했습니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html#설명형",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html#설명형",
    "title": "Part 2 — 사용자 언어 읽기(프롬프트 구조와 유형)",
    "section": "2.4 설명형",
    "text": "2.4 설명형\n\n2.4.1 특징\n\n특정 주제나 개념에 대한 상세한 설명을 요구하는 유형\n명령/청유형보다 더 구체적인 요구사항을 포함하는 유형\n뭐뭐를 해 달라고 하는 데에 있어서 좀더 구체적이게 작성\n출력물의 형식, 구조, 포함 요소, 분량 등을 상세하게 지정\n\n\n\n2.4.2 예시\n\n“2023년 알뜰교통카드 신청 안내 - 대중교통비 최대 30까지 절감할 수 있는 교통카드”\n“전문 블로거로써, 키워드와 연관 키워드를 포함해서 제목을 추천하고, 밑에는 메타설명은 키워드를 포함해서 작성해줘.”\n“마크다운 형식의 3000자 내외의 블로그 글로 작성해줘.”\n“SEO 제목의 앞 부분에서 포커스 키워드와 숫자를 추가해 주세요.”\n코딩 문제 설명 및 해결 방법 요청\n\n\n\n2.4.3 프롬프트 작성 실습\n실습 문제\n클라우드 컴퓨팅의 개념과 장점을 기술에 익숙하지 않은 경영진에게 설명하는 A4 1장 이내 분량의 보고서를 작성하는 프롬프트를 제작해보세요.\n잘 만들어진 프롬프트 예시\n설명형은 명령/청유형보다 더 구체적인 요구사항을 포함하므로, 프롬프트를 자세하게 작성하는 것이 중요합니다.\n클라우드 컴퓨팅의 개념과 장점을 A4 이내의 분량으로 작성해줘.\n보고서를 읽을 대상은 기술 개념을 이해하기 어려워하는 경영진이야.\n작성 내용은 아래의 지시를 따라줘.\n\n중심 내용: 클라우드 컴퓨팅의 정의, 기본 원리, 주요 장점\n문장 스타일: 경영진이 이해할 수 있도록 하는 쉬운 예시나 비유를 사용\n\n참고 텍스트를 사용해서 내용을 상세하게 써줘.\n참고 텍스트\n클라우드 컴퓨팅의 여러 이점 https://cloud.google.com/learn/advantages-of-cloud-computing 중 하나는 사용한 만큼만 비용을 지불하면 된다는 것입니다. 따라서 조직은 자체 물리적 데이터 센터와 서버를 구매하고 유지관리할 필요 없이 더 빠르고 효율적으로 확장할 수 있습니다. 간단히 말해 클라우드 컴퓨팅은 네트워크(대부분 인터넷)를 사용하여 사용자를 클라우드 플랫폼에 연결하고 임대된 컴퓨팅 서비스를 요청하고 액세스합니다. 중앙 서버는 클라이언트 기기와 서버 간의 모든 통신을 처리하여 데이터 교환을 용이하게 합니다. 보안 및 개인 정보 보호 기능은 이러한 정보를 안전하게 보호하기 위한 일반적인 구성요소입니다. 클라우드 컴퓨팅 아키텍처를 채택할 때 일률적인 해결책은 없습니다. 다른 회사에 효과적인 해결책이 본인의 비즈니스 요구사항에 맞지 않을 수 있습니다. 사실 이러한 유연성과 다기능성은 클라우드의 대표적 특징 중 하나로, 기업은 변화하는 시장 또는 측정항목에 빠르게 적응할 수 있습니다. 클라우드 컴퓨팅 배포 모델은 퍼블릭 클라우드, 프라이빗 클라우드, 하이브리드 클라우드로 3가지가 있습니다.\n결과\n프롬프트를 실행하면 다음과 같은 보고서가 생성됩니다:\n클라우드 컴퓨팅: 경영진을 위한 이해\n\n1. 클라우드 컴퓨팅의 정의와 기본 원리\n\n클라우드 컴퓨팅은 인터넷을 통해 다양한 IT 리소스(서버, 저장소, 데이터베이스, 네트워킹, 소프트웨어 등)를 제공하는 서비스입니다. 전기나 수도처럼 필요할 때만 사용한 만큼 비용을 지불하는 방식과 비슷하다고 볼 수 있습니다. 클라우드 컴퓨팅을 사용하는 기업은 물리적 서버를 직접 소유하거나 관리할 필요가 없으며, 필요한 만큼 IT 리소스에 접근하여 사용할 수 있습니다. 이러한 리소스는 서비스 제공업체가 원격 서버에 저장하고 있으며, 사용자는 인터넷을 통해 접근합니다.\n\n2. 비즈니스 효과\n\n클라우드 컴퓨팅을 도입하면 기업은 비용 절감, 운영 효율성 향상, 유연한 비즈니스 확장, 원격 근무 지원, 최신 기술 도입 용이 등의 효과를 얻을 수 있습니다. 이를 통해 기업은 경쟁력을 유지하고 변화하는 시장 상황에 빠르게 대응할 수 있습니다. 클라우드 컴퓨팅은 단순한 IT 인프라 변화가 아니라 기업의 전체적인 비즈니스 전략을 혁신하는 중요한 요소입니다. 기업이 더 효율적이고 유연하게 운영할 수 있게 하여, 궁극적으로 더 높은 수익성과 경쟁력을 확보할 수 있게 합니다.\n\n3. 주요 장점\n\n3.1 비용 절감\n클라우드 컴퓨팅 도입 시 초기 자본 지출을 크게 줄일 수 있습니다. IT 인프라 구매 및 유지관리와 관련된 비용을 절감할 수 있으며, 기업은 사용한 리소스에 대해서만 비용을 지불합니다. 예를 들어, 성수기에는 더 많은 리소스를 사용하고 비수기에는 적게 사용할 수 있습니다.\n\n3.2 운영 효율성 향상\n클라우드 컴퓨팅은 자동화된 관리 도구와 효율적인 리소스 할당을 제공합니다. 이를 통해 IT 팀이 더 중요한 업무에 집중할 수 있어 기업 전체의 생산성이 향상됩니다.\n\n3.3 비즈니스 확장의 유연성\n기업이 비즈니스 확장 필요에 빠르게 대응할 수 있습니다. 예를 들어, 새로운 시장 진입이나 신제품 출시 시 필요한 IT 리소스를 빠르게 추가할 수 있습니다. 변화하는 시장 수요에 빠르게 적응하는 데 도움이 됩니다.\n\n3.4 원격 근무 지원\n직원들이 어디서나 업무를 수행할 수 있게 합니다. 특히 재택근무나 원격 근무 시나리오에 유용합니다. 직원들은 인터넷 연결만 있으면 회사의 IT 리소스에 접근할 수 있어 업무 효율성이 증가합니다.\n\n3.5 최신 기술 도입 용이\n클라우드 서비스 제공업체는 최신 기술과 보안 업데이트를 제공합니다. 기업은 추가 비용 없이 최첨단 IT 환경을 유지할 수 있으며, 기술적 경쟁력을 유지하는 데 크게 도움이 됩니다.\n\n\n2.4.4 핵심 포인트\n위의 잘 만들어진 프롬프트 예시를 통해 설명형 프롬프트의 핵심 포인트를 살펴보겠습니다:\n\n명확한 지시문 제공: 프롬프트에서 “작성 내용은 아래의 지시를 따라줘”라고 명시하여 무엇을 해야 하는지 명확하게 지시했습니다. 이렇게 지시문을 명확히 하면 AI가 정확한 방향으로 작업을 수행할 수 있습니다.\n대상 독자 명시: “보고서를 읽을 대상은 기술 개념을 이해하기 어려워하는 경영진이야”라고 명시했습니다. 이렇게 대상 독자를 구체적으로 명시하면 AI가 그에 맞는 수준과 톤으로 내용을 작성할 수 있습니다.\n형식과 분량 지정: “A4 이내의 분량으로 작성해줘”처럼 구체적인 형식과 분량을 지정했습니다. 이를 통해 원하는 길이와 형식의 결과를 얻을 수 있습니다.\n하위항목으로 상세 지침 제공: “중심 내용: 클라우드 컴퓨팅의 정의, 기본 원리, 주요 장점”과 “문장 스타일: 경영진이 이해할 수 있도록 하는 쉬운 예시나 비유를 사용”처럼 하위항목으로 더 구체적인 지침을 제공했습니다. 이렇게 하면 AI가 각 항목을 빠짐없이 처리할 수 있습니다.\n참고 텍스트를 추가하여 필요 정보 제공: “참고 텍스트를 사용해서 내용을 상세하게 써줘”라고 지시하고 실제 참고 텍스트를 제공했습니다. 이렇게 참고 자료를 추가하면 AI가 더 정확하고 상세한 내용을 생성할 수 있습니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html#간단형",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html#간단형",
    "title": "Part 2 — 사용자 언어 읽기(프롬프트 구조와 유형)",
    "section": "2.5 간단형",
    "text": "2.5 간단형\n\n2.5.1 특징\n\n짧고 간결한 요청을 하는 유형\n문장을 쓰지 않고 단어만, 구를 입력하는 유형\n굉장히 많은 사용 사례를 가진 유형\n최소한의 단어로 의도 전달\n빠른 답변이나 아이디어 생성에 적합\n\n\n\n2.5.2 예시\n\n“강남맛집”\n“5분 자기소개”\n“멋있는 강아지 이름”\n“비오는 날 카톡 멘트”\n“청렴 뜻”\n\n\n\n2.5.3 프롬프트 작성 실습\n실습 문제\n원격 근무 팀의 협업을 증진시킬 수 있는 창의적인 방법 8가지를 제시하는 프롬프트를 작성해보세요.\n잘 만들어진 프롬프트 예시\n원격 근무 팀의 협업을 증진시킬 수 있는 창의적인 방법 8가지 제시\n결과\n프롬프트를 실행하면 다음과 같은 협업 방법들이 제시됩니다:\n원격 근무 팀의 협업을 증진시키기 위한 창의적인 방법을 아래와 같이 제시합니다:\n\n1. 버추얼 오피스 도입\n버추얼 오피스 플랫폼을 활용하여 팀원들이 온라인에서 실제 오피스처럼 소통하고 협업할 수 있도록 합니다. 예를 들어, 팀원들이 가상 공간에서 자신의 아바타로 모이고, 회의실, 라운지 등 다양한 공간에서 자연스럽게 대화할 수 있습니다.\n\n2. 테마별 온라인 워크숍 개최\n팀원들의 전문성을 향상시키기 위해 다양한 주제의 온라인 워크숍을 정기적으로 개최합니다. 이 워크숍은 팀원들이 서로의 아이디어를 공유하고 협력하는 기회를 제공합니다.\n\n3. 공동 프로젝트 플랫폼 사용\nTrello, Asana, Notion 등의 협업 도구를 활용하여 팀원들이 실시간으로 프로젝트를 관리하고, 진행 상황을 공유할 수 있도록 합니다. 이를 통해 모든 팀원이 프로젝트의 진행 상황을 쉽게 파악할 수 있습니다.\n\n4. 정기적인 버추얼 커피 브레이크\n비공식적인 온라인 커피 브레이크 시간을 마련하여 팀원들이 업무와 관련 없는 대화를 나누며 친목을 도모할 수 있도록 합니다. 이는 팀원들 간의 유대감을 강화하는 데 도움이 됩니다.\n\n5. 온라인 게임 및 이벤트\n팀 빌딩을 위한 온라인 게임이나 이벤트를 정기적으로 개최합니다. 예를 들어, 퀴즈 대회, 온라인 방 탈출 게임, 가상 요리 클래스 등을 통해 팀원들이 즐겁게 협업할 수 있는 기회를 제공합니다.\n\n6. 비디오 기반 소통 장려\n이메일이나 채팅 대신 비디오 메시지나 비디오 콜을 통해 소통하는 문화를 장려합니다. 비디오를 통해 더욱 생생하게 의견을 전달하고, 팀원들 간의 이해를 높일 수 있습니다.\n\n7. 피드백 루프 구축\n주기적으로 팀원들 간의 피드백을 주고받는 시스템을 구축합니다. 예를 들어, 월간 피드백 세션을 통해 팀원들이 서로의 업무에 대해 건설적인 피드백을 주고받으며 성장할 수 있는 기회를 제공합니다.\n\n\n2.5.4 핵심 포인트\n위의 잘 만들어진 프롬프트 예시를 통해 간단형 프롬프트의 핵심 포인트를 살펴보겠습니다:\n\n간결하고 명확한 요청: 프롬프트에서 “원격 근무 팀의 협업을 증진시킬 수 있는 창의적인 방법 8가지 제시”처럼 최소한의 단어로 핵심 의도만 전달합니다. 문장을 쓰지 않고 단어나 구로 요청하는 것이 특징입니다.\n구체적인 개수나 형식 지정 가능: “8가지”처럼 구체적인 수치를 포함하면 더 정확한 결과를 얻을 수 있습니다. 예를 들어 “5분”, “10개” 등 구체적인 수치를 명시할 수 있습니다.\n빠른 응답에 적합: 복잡한 설명이나 상세한 지침 없이 빠르게 아이디어나 정보를 얻고 싶을 때 사용합니다. 간단형은 굉장히 많은 사용 사례를 가진 유형입니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html#프롬프트의-공통적인-특징",
    "href": "docs/blog/posts/Prompt_Engineering/02-프롬프트의_이해/02-사용자언어읽기.html#프롬프트의-공통적인-특징",
    "title": "Part 2 — 사용자 언어 읽기(프롬프트 구조와 유형)",
    "section": "2.6 프롬프트의 공통적인 특징",
    "text": "2.6 프롬프트의 공통적인 특징\n효과적인 프롬프트는 다음 7가지 요소를 포함합니다:\n\nTask Description (작업 설명): 수행할 작업의 명확한 설명\nSpecific Instructions (구체적인 지침): 작업 수행 방법에 대한 상세 지침\nContent Elements (내용 요소): 포함해야 할 내용이나 정보\nAudience and Role Specification (청중 및 역할 지침): 대상 독자나 AI의 역할 정의\nLanguage and Style Guidelines (언어 및 스타일 지침): 사용할 언어와 문체\nFormat or Structure Guidelines (형식 또는 구조 지침): 출력 형식이나 구조\nWord or Character Limits (단어 또는 문자 제한): 분량 제한\n\n이러한 요소들을 조합하여 사용자의 의도를 정확히 전달하고, 원하는 결과를 얻을 수 있습니다."
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/index.html",
    "href": "docs/blog/posts/Prompt_Engineering/index.html",
    "title": "Prompt_Engineering",
    "section": "",
    "text": "01-프롬프트 구조(1)\n02-프롬프트 구조(2)\n\n\n\n\n\n01-프롬프트 분석의 필요성과 가치\n02-사용자 언어 읽기(프롬프트 구조와 유형)\n03-대화 분석(사용자-AI 상호작용 매커니즘)",
    "crumbs": [
      "Blog",
      "Blog Posts",
      "Prompt_Engineering"
    ]
  },
  {
    "objectID": "docs/blog/posts/Prompt_Engineering/index.html#prompt_engineering",
    "href": "docs/blog/posts/Prompt_Engineering/index.html#prompt_engineering",
    "title": "Prompt_Engineering",
    "section": "",
    "text": "01-프롬프트 구조(1)\n02-프롬프트 구조(2)\n\n\n\n\n\n01-프롬프트 분석의 필요성과 가치\n02-사용자 언어 읽기(프롬프트 구조와 유형)\n03-대화 분석(사용자-AI 상호작용 매커니즘)",
    "crumbs": [
      "Blog",
      "Blog Posts",
      "Prompt_Engineering"
    ]
  }
]